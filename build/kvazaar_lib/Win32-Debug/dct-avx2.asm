; Listing generated by Microsoft (R) Optimizing Compiler Version 19.26.28806.0 

	TITLE	F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
	.686P
	.XMM
	include listing.inc
	.model	flat

INCLUDELIB MSVCRTD
INCLUDELIB OLDNAMES

PUBLIC	??_C@_0P@FIMIKDEG@array_checksum@		; `string'
PUBLIC	??_C@_09INHMEIKP@array_md5@			; `string'
PUBLIC	??_C@_07DDJKLCAH@reg_sad@			; `string'
PUBLIC	??_C@_07CCGEEBAL@sad_4x4@			; `string'
PUBLIC	??_C@_07MEAHLBLP@sad_8x8@			; `string'
PUBLIC	??_C@_09CIFGAEGF@sad_16x16@			; `string'
PUBLIC	??_C@_09PHPGBCME@sad_32x32@			; `string'
PUBLIC	??_C@_09HIOKBDLK@sad_64x64@			; `string'
PUBLIC	??_C@_08GDBJPAOD@satd_4x4@			; `string'
PUBLIC	??_C@_08IFHKAAFH@satd_8x8@			; `string'
PUBLIC	??_C@_0L@CJHLPOG@satd_16x16@			; `string'
PUBLIC	??_C@_0L@NNDHKJEH@satd_32x32@			; `string'
PUBLIC	??_C@_0L@FCCLKIDJ@satd_64x64@			; `string'
PUBLIC	??_C@_0O@FHJAMJMP@satd_any_size@		; `string'
PUBLIC	??_C@_0N@PBMCJFCI@sad_4x4_dual@			; `string'
PUBLIC	??_C@_0N@NAFGAMEI@sad_8x8_dual@			; `string'
PUBLIC	??_C@_0P@KGAKCNHP@sad_16x16_dual@		; `string'
PUBLIC	??_C@_0P@EBOHBHKK@sad_32x32_dual@		; `string'
PUBLIC	??_C@_0P@BGJOPAPB@sad_64x64_dual@		; `string'
PUBLIC	??_C@_0O@PJODLFIO@satd_4x4_dual@		; `string'
PUBLIC	??_C@_0O@NIHHCMOO@satd_8x8_dual@		; `string'
PUBLIC	??_C@_0BA@GFDJBOPJ@satd_16x16_dual@		; `string'
PUBLIC	??_C@_0BA@ICNECECM@satd_32x32_dual@		; `string'
PUBLIC	??_C@_0BA@NFKNMDHH@satd_64x64_dual@		; `string'
PUBLIC	??_C@_0BD@EFOGIBKC@satd_any_size_quad@		; `string'
PUBLIC	??_C@_0BA@BPDFDAFM@pixels_calc_ssd@		; `string'
PUBLIC	??_C@_0P@FIKELBGI@bipred_average@		; `string'
PUBLIC	??_C@_0BC@IMILIHON@get_optimized_sad@		; `string'
PUBLIC	??_C@_07OEMLCPNF@ver_sad@			; `string'
PUBLIC	??_C@_07CJIKFDIC@hor_sad@			; `string'
PUBLIC	??_C@_09GDPKBOJB@pixel_var@			; `string'
PUBLIC	??_C@_0BF@BJKPGPEP@fast_forward_dst_4x4@	; `string'
PUBLIC	??_C@_07MAFDGKIL@dct_4x4@			; `string'
PUBLIC	??_C@_07CGDAJKDP@dct_8x8@			; `string'
PUBLIC	??_C@_09LPGJIHFJ@dct_16x16@			; `string'
PUBLIC	??_C@_09GAMJJBPI@dct_32x32@			; `string'
PUBLIC	??_C@_0BF@LGIDMEOF@fast_inverse_dst_4x4@	; `string'
PUBLIC	??_C@_08LDLIJGLD@idct_4x4@			; `string'
PUBLIC	??_C@_08FFNLGGAH@idct_8x8@			; `string'
PUBLIC	??_C@_0L@BMPNPGHO@idct_16x16@			; `string'
PUBLIC	??_C@_0L@MDFNOANP@idct_32x32@			; `string'
PUBLIC	??_C@_0CA@KBMGLOML@filter_hpel_blocks_hor_ver_luma@ ; `string'
PUBLIC	??_C@_0BN@LGIFMJCD@filter_hpel_blocks_diag_luma@ ; `string'
PUBLIC	??_C@_0CA@HAFBJKBM@filter_qpel_blocks_hor_ver_luma@ ; `string'
PUBLIC	??_C@_0BN@LBBJMBKC@filter_qpel_blocks_diag_luma@ ; `string'
PUBLIC	??_C@_0BH@DGLFPIPB@sample_quarterpel_luma@	; `string'
PUBLIC	??_C@_0BF@HOLGGLNK@sample_octpel_chroma@	; `string'
PUBLIC	??_C@_0BK@LCPNGAOF@sample_quarterpel_luma_hi@	; `string'
PUBLIC	??_C@_0BI@EFIAEBMP@sample_octpel_chroma_hi@	; `string'
PUBLIC	??_C@_0BD@MPANGNDO@get_extended_block@		; `string'
PUBLIC	??_C@_05DFPBCFDJ@quant@				; `string'
PUBLIC	??_C@_0BC@MPMPMGJB@quantize_residual@		; `string'
PUBLIC	??_C@_07GMDOJGPA@dequant@			; `string'
PUBLIC	??_C@_0O@ECIHPEON@coeff_abs_sum@		; `string'
PUBLIC	??_C@_0BA@HMNKAKOO@fast_coeff_cost@		; `string'
PUBLIC	??_C@_0N@NMFCEONC@angular_pred@			; `string'
PUBLIC	??_C@_0BC@KPOCLILL@intra_pred_planar@		; `string'
PUBLIC	??_C@_0BH@EAOLFJGL@intra_pred_filtered_dc@	; `string'
PUBLIC	??_C@_0BF@LGILOHOJ@sao_edge_ddistortion@	; `string'
PUBLIC	??_C@_0BC@OCNKGNNI@calc_sao_edge_dir@		; `string'
PUBLIC	??_C@_0BG@IJPOOFFG@sao_reconstruct_color@	; `string'
PUBLIC	??_C@_0BF@HDNLAKN@sao_band_ddistortion@		; `string'
PUBLIC	??_C@_0BB@GDIDDFDB@encode_coeff_nxn@		; `string'
EXTRN	_kvz_array_checksum:DWORD
EXTRN	_kvz_array_md5:DWORD
EXTRN	_kvz_reg_sad:DWORD
EXTRN	_kvz_sad_4x4:DWORD
EXTRN	_kvz_sad_8x8:DWORD
EXTRN	_kvz_sad_16x16:DWORD
EXTRN	_kvz_sad_32x32:DWORD
EXTRN	_kvz_sad_64x64:DWORD
EXTRN	_kvz_satd_4x4:DWORD
EXTRN	_kvz_satd_8x8:DWORD
EXTRN	_kvz_satd_16x16:DWORD
EXTRN	_kvz_satd_32x32:DWORD
EXTRN	_kvz_satd_64x64:DWORD
EXTRN	_kvz_satd_any_size:DWORD
EXTRN	_kvz_sad_4x4_dual:DWORD
EXTRN	_kvz_sad_8x8_dual:DWORD
EXTRN	_kvz_sad_16x16_dual:DWORD
EXTRN	_kvz_sad_32x32_dual:DWORD
EXTRN	_kvz_sad_64x64_dual:DWORD
EXTRN	_kvz_satd_4x4_dual:DWORD
EXTRN	_kvz_satd_8x8_dual:DWORD
EXTRN	_kvz_satd_16x16_dual:DWORD
EXTRN	_kvz_satd_32x32_dual:DWORD
EXTRN	_kvz_satd_64x64_dual:DWORD
EXTRN	_kvz_satd_any_size_quad:DWORD
EXTRN	_kvz_pixels_calc_ssd:DWORD
EXTRN	_kvz_bipred_average:DWORD
EXTRN	_kvz_get_optimized_sad:DWORD
EXTRN	_kvz_ver_sad:DWORD
EXTRN	_kvz_hor_sad:DWORD
EXTRN	_kvz_pixel_var:DWORD
EXTRN	_kvz_fast_forward_dst_4x4:DWORD
EXTRN	_kvz_dct_4x4:DWORD
EXTRN	_kvz_dct_8x8:DWORD
EXTRN	_kvz_dct_16x16:DWORD
EXTRN	_kvz_dct_32x32:DWORD
EXTRN	_kvz_fast_inverse_dst_4x4:DWORD
EXTRN	_kvz_idct_4x4:DWORD
EXTRN	_kvz_idct_8x8:DWORD
EXTRN	_kvz_idct_16x16:DWORD
EXTRN	_kvz_idct_32x32:DWORD
EXTRN	_kvz_filter_hpel_blocks_hor_ver_luma:DWORD
EXTRN	_kvz_filter_hpel_blocks_diag_luma:DWORD
EXTRN	_kvz_filter_qpel_blocks_hor_ver_luma:DWORD
EXTRN	_kvz_filter_qpel_blocks_diag_luma:DWORD
EXTRN	_kvz_get_extended_block:DWORD
EXTRN	_kvz_sample_quarterpel_luma:DWORD
EXTRN	_kvz_sample_octpel_chroma:DWORD
EXTRN	_kvz_sample_quarterpel_luma_hi:DWORD
EXTRN	_kvz_sample_octpel_chroma_hi:DWORD
EXTRN	_kvz_quant:DWORD
EXTRN	_kvz_quantize_residual:DWORD
EXTRN	_kvz_dequant:DWORD
EXTRN	_kvz_coeff_abs_sum:DWORD
EXTRN	_kvz_fast_coeff_cost:DWORD
EXTRN	_kvz_angular_pred:DWORD
EXTRN	_kvz_intra_pred_planar:DWORD
EXTRN	_kvz_intra_pred_filtered_dc:DWORD
EXTRN	_kvz_sao_edge_ddistortion:DWORD
EXTRN	_kvz_calc_sao_edge_dir:DWORD
EXTRN	_kvz_sao_reconstruct_color:DWORD
EXTRN	_kvz_sao_band_ddistortion:DWORD
EXTRN	_kvz_encode_coeff_nxn:DWORD
msvcjmc	SEGMENT
__ED9CC025_corecrt_memcpy_s@h DB 01H
__875914C9_corecrt_wstring@h DB 01H
__731387C4_string@h DB 01H
__1850469A_corecrt_stdio_config@h DB 01H
__01D10305_corecrt_wstdio@h DB 01H
__9FF75F13_stdio@h DB 01H
__614D3496_malloc@h DB 01H
__4DF1518D_xmmintrin@h DB 01H
__6C65A336_cu@h DB 01H
__E2865EBA_corecrt_math@h DB 01H
__546CF5FC_crypto@h DB 01H
__6BE1C69C_encoderstate@h DB 01H
__56A71F03_dct-avx2@c DB 01H
msvcjmc	ENDS
;	COMDAT ??_C@_0BB@GDIDDFDB@encode_coeff_nxn@
CONST	SEGMENT
??_C@_0BB@GDIDDFDB@encode_coeff_nxn@ DB 'encode_coeff_nxn', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BF@HDNLAKN@sao_band_ddistortion@
CONST	SEGMENT
??_C@_0BF@HDNLAKN@sao_band_ddistortion@ DB 'sao_band_ddistortion', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BG@IJPOOFFG@sao_reconstruct_color@
CONST	SEGMENT
??_C@_0BG@IJPOOFFG@sao_reconstruct_color@ DB 'sao_reconstruct_color', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BC@OCNKGNNI@calc_sao_edge_dir@
CONST	SEGMENT
??_C@_0BC@OCNKGNNI@calc_sao_edge_dir@ DB 'calc_sao_edge_dir', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BF@LGILOHOJ@sao_edge_ddistortion@
CONST	SEGMENT
??_C@_0BF@LGILOHOJ@sao_edge_ddistortion@ DB 'sao_edge_ddistortion', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BH@EAOLFJGL@intra_pred_filtered_dc@
CONST	SEGMENT
??_C@_0BH@EAOLFJGL@intra_pred_filtered_dc@ DB 'intra_pred_filtered_dc', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BC@KPOCLILL@intra_pred_planar@
CONST	SEGMENT
??_C@_0BC@KPOCLILL@intra_pred_planar@ DB 'intra_pred_planar', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0N@NMFCEONC@angular_pred@
CONST	SEGMENT
??_C@_0N@NMFCEONC@angular_pred@ DB 'angular_pred', 00H	; `string'
CONST	ENDS
;	COMDAT ??_C@_0BA@HMNKAKOO@fast_coeff_cost@
CONST	SEGMENT
??_C@_0BA@HMNKAKOO@fast_coeff_cost@ DB 'fast_coeff_cost', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0O@ECIHPEON@coeff_abs_sum@
CONST	SEGMENT
??_C@_0O@ECIHPEON@coeff_abs_sum@ DB 'coeff_abs_sum', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_07GMDOJGPA@dequant@
CONST	SEGMENT
??_C@_07GMDOJGPA@dequant@ DB 'dequant', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_0BC@MPMPMGJB@quantize_residual@
CONST	SEGMENT
??_C@_0BC@MPMPMGJB@quantize_residual@ DB 'quantize_residual', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_05DFPBCFDJ@quant@
CONST	SEGMENT
??_C@_05DFPBCFDJ@quant@ DB 'quant', 00H			; `string'
CONST	ENDS
;	COMDAT ??_C@_0BD@MPANGNDO@get_extended_block@
CONST	SEGMENT
??_C@_0BD@MPANGNDO@get_extended_block@ DB 'get_extended_block', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BI@EFIAEBMP@sample_octpel_chroma_hi@
CONST	SEGMENT
??_C@_0BI@EFIAEBMP@sample_octpel_chroma_hi@ DB 'sample_octpel_chroma_hi', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BK@LCPNGAOF@sample_quarterpel_luma_hi@
CONST	SEGMENT
??_C@_0BK@LCPNGAOF@sample_quarterpel_luma_hi@ DB 'sample_quarterpel_luma_'
	DB	'hi', 00H					; `string'
CONST	ENDS
;	COMDAT ??_C@_0BF@HOLGGLNK@sample_octpel_chroma@
CONST	SEGMENT
??_C@_0BF@HOLGGLNK@sample_octpel_chroma@ DB 'sample_octpel_chroma', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BH@DGLFPIPB@sample_quarterpel_luma@
CONST	SEGMENT
??_C@_0BH@DGLFPIPB@sample_quarterpel_luma@ DB 'sample_quarterpel_luma', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BN@LBBJMBKC@filter_qpel_blocks_diag_luma@
CONST	SEGMENT
??_C@_0BN@LBBJMBKC@filter_qpel_blocks_diag_luma@ DB 'filter_qpel_blocks_d'
	DB	'iag_luma', 00H				; `string'
CONST	ENDS
;	COMDAT ??_C@_0CA@HAFBJKBM@filter_qpel_blocks_hor_ver_luma@
CONST	SEGMENT
??_C@_0CA@HAFBJKBM@filter_qpel_blocks_hor_ver_luma@ DB 'filter_qpel_block'
	DB	's_hor_ver_luma', 00H			; `string'
CONST	ENDS
;	COMDAT ??_C@_0BN@LGIFMJCD@filter_hpel_blocks_diag_luma@
CONST	SEGMENT
??_C@_0BN@LGIFMJCD@filter_hpel_blocks_diag_luma@ DB 'filter_hpel_blocks_d'
	DB	'iag_luma', 00H				; `string'
CONST	ENDS
;	COMDAT ??_C@_0CA@KBMGLOML@filter_hpel_blocks_hor_ver_luma@
CONST	SEGMENT
??_C@_0CA@KBMGLOML@filter_hpel_blocks_hor_ver_luma@ DB 'filter_hpel_block'
	DB	's_hor_ver_luma', 00H			; `string'
CONST	ENDS
;	COMDAT ??_C@_0L@MDFNOANP@idct_32x32@
CONST	SEGMENT
??_C@_0L@MDFNOANP@idct_32x32@ DB 'idct_32x32', 00H	; `string'
CONST	ENDS
;	COMDAT ??_C@_0L@BMPNPGHO@idct_16x16@
CONST	SEGMENT
??_C@_0L@BMPNPGHO@idct_16x16@ DB 'idct_16x16', 00H	; `string'
CONST	ENDS
;	COMDAT ??_C@_08FFNLGGAH@idct_8x8@
CONST	SEGMENT
??_C@_08FFNLGGAH@idct_8x8@ DB 'idct_8x8', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_08LDLIJGLD@idct_4x4@
CONST	SEGMENT
??_C@_08LDLIJGLD@idct_4x4@ DB 'idct_4x4', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_0BF@LGIDMEOF@fast_inverse_dst_4x4@
CONST	SEGMENT
??_C@_0BF@LGIDMEOF@fast_inverse_dst_4x4@ DB 'fast_inverse_dst_4x4', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_09GAMJJBPI@dct_32x32@
CONST	SEGMENT
??_C@_09GAMJJBPI@dct_32x32@ DB 'dct_32x32', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_09LPGJIHFJ@dct_16x16@
CONST	SEGMENT
??_C@_09LPGJIHFJ@dct_16x16@ DB 'dct_16x16', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_07CGDAJKDP@dct_8x8@
CONST	SEGMENT
??_C@_07CGDAJKDP@dct_8x8@ DB 'dct_8x8', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_07MAFDGKIL@dct_4x4@
CONST	SEGMENT
??_C@_07MAFDGKIL@dct_4x4@ DB 'dct_4x4', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_0BF@BJKPGPEP@fast_forward_dst_4x4@
CONST	SEGMENT
??_C@_0BF@BJKPGPEP@fast_forward_dst_4x4@ DB 'fast_forward_dst_4x4', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_09GDPKBOJB@pixel_var@
CONST	SEGMENT
??_C@_09GDPKBOJB@pixel_var@ DB 'pixel_var', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_07CJIKFDIC@hor_sad@
CONST	SEGMENT
??_C@_07CJIKFDIC@hor_sad@ DB 'hor_sad', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_07OEMLCPNF@ver_sad@
CONST	SEGMENT
??_C@_07OEMLCPNF@ver_sad@ DB 'ver_sad', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_0BC@IMILIHON@get_optimized_sad@
CONST	SEGMENT
??_C@_0BC@IMILIHON@get_optimized_sad@ DB 'get_optimized_sad', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0P@FIKELBGI@bipred_average@
CONST	SEGMENT
??_C@_0P@FIKELBGI@bipred_average@ DB 'bipred_average', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BA@BPDFDAFM@pixels_calc_ssd@
CONST	SEGMENT
??_C@_0BA@BPDFDAFM@pixels_calc_ssd@ DB 'pixels_calc_ssd', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BD@EFOGIBKC@satd_any_size_quad@
CONST	SEGMENT
??_C@_0BD@EFOGIBKC@satd_any_size_quad@ DB 'satd_any_size_quad', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BA@NFKNMDHH@satd_64x64_dual@
CONST	SEGMENT
??_C@_0BA@NFKNMDHH@satd_64x64_dual@ DB 'satd_64x64_dual', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BA@ICNECECM@satd_32x32_dual@
CONST	SEGMENT
??_C@_0BA@ICNECECM@satd_32x32_dual@ DB 'satd_32x32_dual', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0BA@GFDJBOPJ@satd_16x16_dual@
CONST	SEGMENT
??_C@_0BA@GFDJBOPJ@satd_16x16_dual@ DB 'satd_16x16_dual', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0O@NIHHCMOO@satd_8x8_dual@
CONST	SEGMENT
??_C@_0O@NIHHCMOO@satd_8x8_dual@ DB 'satd_8x8_dual', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0O@PJODLFIO@satd_4x4_dual@
CONST	SEGMENT
??_C@_0O@PJODLFIO@satd_4x4_dual@ DB 'satd_4x4_dual', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0P@BGJOPAPB@sad_64x64_dual@
CONST	SEGMENT
??_C@_0P@BGJOPAPB@sad_64x64_dual@ DB 'sad_64x64_dual', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0P@EBOHBHKK@sad_32x32_dual@
CONST	SEGMENT
??_C@_0P@EBOHBHKK@sad_32x32_dual@ DB 'sad_32x32_dual', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0P@KGAKCNHP@sad_16x16_dual@
CONST	SEGMENT
??_C@_0P@KGAKCNHP@sad_16x16_dual@ DB 'sad_16x16_dual', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0N@NAFGAMEI@sad_8x8_dual@
CONST	SEGMENT
??_C@_0N@NAFGAMEI@sad_8x8_dual@ DB 'sad_8x8_dual', 00H	; `string'
CONST	ENDS
;	COMDAT ??_C@_0N@PBMCJFCI@sad_4x4_dual@
CONST	SEGMENT
??_C@_0N@PBMCJFCI@sad_4x4_dual@ DB 'sad_4x4_dual', 00H	; `string'
CONST	ENDS
;	COMDAT ??_C@_0O@FHJAMJMP@satd_any_size@
CONST	SEGMENT
??_C@_0O@FHJAMJMP@satd_any_size@ DB 'satd_any_size', 00H ; `string'
CONST	ENDS
;	COMDAT ??_C@_0L@FCCLKIDJ@satd_64x64@
CONST	SEGMENT
??_C@_0L@FCCLKIDJ@satd_64x64@ DB 'satd_64x64', 00H	; `string'
CONST	ENDS
;	COMDAT ??_C@_0L@NNDHKJEH@satd_32x32@
CONST	SEGMENT
??_C@_0L@NNDHKJEH@satd_32x32@ DB 'satd_32x32', 00H	; `string'
CONST	ENDS
;	COMDAT ??_C@_0L@CJHLPOG@satd_16x16@
CONST	SEGMENT
??_C@_0L@CJHLPOG@satd_16x16@ DB 'satd_16x16', 00H	; `string'
CONST	ENDS
;	COMDAT ??_C@_08IFHKAAFH@satd_8x8@
CONST	SEGMENT
??_C@_08IFHKAAFH@satd_8x8@ DB 'satd_8x8', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_08GDBJPAOD@satd_4x4@
CONST	SEGMENT
??_C@_08GDBJPAOD@satd_4x4@ DB 'satd_4x4', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_09HIOKBDLK@sad_64x64@
CONST	SEGMENT
??_C@_09HIOKBDLK@sad_64x64@ DB 'sad_64x64', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_09PHPGBCME@sad_32x32@
CONST	SEGMENT
??_C@_09PHPGBCME@sad_32x32@ DB 'sad_32x32', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_09CIFGAEGF@sad_16x16@
CONST	SEGMENT
??_C@_09CIFGAEGF@sad_16x16@ DB 'sad_16x16', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_07MEAHLBLP@sad_8x8@
CONST	SEGMENT
??_C@_07MEAHLBLP@sad_8x8@ DB 'sad_8x8', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_07CCGEEBAL@sad_4x4@
CONST	SEGMENT
??_C@_07CCGEEBAL@sad_4x4@ DB 'sad_4x4', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_07DDJKLCAH@reg_sad@
CONST	SEGMENT
??_C@_07DDJKLCAH@reg_sad@ DB 'reg_sad', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_09INHMEIKP@array_md5@
CONST	SEGMENT
??_C@_09INHMEIKP@array_md5@ DB 'array_md5', 00H		; `string'
CONST	ENDS
;	COMDAT ??_C@_0P@FIMIKDEG@array_checksum@
CONST	SEGMENT
??_C@_0P@FIMIKDEG@array_checksum@ DB 'array_checksum', 00H ; `string'
CONST	ENDS
CONST	SEGMENT
_cbf_masks DW	01fH
	DW	0fH
	DW	07H
	DW	03H
	DW	01H
	ORG $+6
_default_fast_coeff_cost_wts DD 03e282e88r	; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e26c094r			; 0.162844
	DD	04081ca43r			; 4.05594
	DD	04064203ar			; 3.56447
	DD	040db915ar			; 6.86149
	DD	03e03d189r			; 0.128729
	DD	04089fbafr			; 4.31197
	DD	0407c5771r			; 3.94284
	DD	040ddeed2r			; 6.9354
	DD	03de33ce6r			; 0.110956
	DD	0408ddcb1r			; 4.43319
	DD	0407c8738r			; 3.94575
	DD	040dc1618r			; 6.8777
	DD	03dc29cfer			; 0.095026
	DD	0408f7938r			; 4.48355
	DD	0408636aar			; 4.19417
	DD	040d90260r			; 6.78154
	DD	03d99b1b8r			; 0.075046
	DD	04094474cr			; 4.6337
	DD	04082b1b6r			; 4.08419
	DD	040d65aeer			; 6.6986
	DD	03d56bca5r			; 0.052426
	DD	0409ef37er			; 4.96722
	DD	04080dee8r			; 4.02721
	DD	040d19306r			; 6.5492
	DD	03d24bcaer			; 0.040219
	DD	040a489car			; 5.14182
	DD	0407ee3bdr			; 3.98265
	DD	040cec513r			; 6.46156
	DD	03d0fba88r			; 0.03509
	DD	040a628e7r			; 5.19249
	DD	040752e49r			; 3.83095
	DD	040cd642ar			; 6.41848
	DD	03cf47d80r			; 0.029845
	DD	040a6c5d0r			; 5.21165
	DD	040743073r			; 3.81546
	DD	040cb0dd8r			; 6.34544
	DD	03cc0b136r			; 0.023522
	DD	040aa4f92r			; 5.32221
	DD	040744224r			; 3.81654
	DD	040cb8aaar			; 6.36068
	DD	03cae87d3r			; 0.021305
	DD	040a73ac3r			; 5.22592
	DD	04075eeccr			; 3.8427
	DD	040ca6cd9r			; 6.32579
	DD	03c821294r			; 0.015878
	DD	040a5dbe0r			; 5.18309
	DD	0407d2f27r			; 3.956
	DD	040ca8cbdr			; 6.32968
	DD	03c2ae297r			; 0.01043
	DD	040a32ce4r			; 5.09923
	DD	04085a85fr			; 4.1768
	DD	040c9c5d6r			; 6.3054
	DD	03c0a2a91r			; 0.008433
	DD	040a0f7der			; 5.03026
	DD	040879a50r			; 4.23759
	DD	040c8a4eer			; 6.27013
	DD	03bd4fdf4r			; 0.0065
	DD	0409f0412r			; 4.96925
	DD	0408adc57r			; 4.3394
	DD	040c6f870r			; 6.21783
	DD	03ba18373r			; 0.004929
	DD	0409d8d50r			; 4.9235
	DD	0408e283fr			; 4.44241
	DD	040c5df6cr			; 6.18352
	DD	03b73775cr			; 0.003715
	DD	0409d4c75r			; 4.91558
	DD	0408dbb1br			; 4.42909
	DD	040c4029fr			; 6.12532
	DD	03b4a70d2r			; 0.003089
	DD	0409c48f7r			; 4.88391
	DD	040920260r			; 4.56279
	DD	040c5019dr			; 6.15645
	DD	03b219c9dr			; 0.002466
	DD	0409c31abr			; 4.88106
	DD	040942800r			; 4.62988
	DD	040c49088r			; 6.14264
	DD	03b0e25c8r			; 0.002169
	DD	0409c3d62r			; 4.88249
	DD	04094ae99r			; 4.64631
	DD	040c415d1r			; 6.12766
	DD	03b26dacbr			; 0.002546
	DD	040996304r			; 4.79334
	DD	0409acc16r			; 4.83741
	DD	040c6606br			; 6.19927
	DD	03aac3a86r			; 0.001314
	DD	04099e220r			; 4.80885
	DD	0409a81bdr			; 4.82834
	DD	040c7ca3cr			; 6.24344
	DD	03a9741d1r			; 0.001154
	DD	0409b9a72r			; 4.8626
	DD	0409b19aar			; 4.84688
	DD	040c693a5r			; 6.20552
	DD	03a80f990r			; 0.000984
	DD	0409bb993r			; 4.8664
	DD	0409b7fa2r			; 4.85933
	DD	040c7b565r			; 6.24089
	DD	03a551f82r			; 0.000813
	DD	0409b698ar			; 4.85663
	DD	0409d95bar			; 4.92453
	DD	040c963a4r			; 6.29341
	DD	03a91c087r			; 0.001112
	DD	04099419er			; 4.78926
	DD	040a050f0r			; 5.00988
	DD	040cddf8fr			; 6.43354
	DD	03a10b418r			; 0.000552
	DD	04098580ar			; 4.76075
	DD	040a2e4f1r			; 5.09045
	DD	040d32e1fr			; 6.59938
	DD	039ccff22r			; 0.000391
	DD	0409ec42cr			; 4.96145
	DD	040a38d95r			; 5.11103
	DD	040d8342fr			; 6.75637
	DD	039ae1049r			; 0.000332
	DD	0409f63f8r			; 4.98095
	DD	040a46b89r			; 5.13813
	DD	040dbc1e8r			; 6.86742
	DD	03952c387r			; 0.000201
	DD	040a5d297r			; 5.18196
	DD	04097af64r			; 4.74016
	DD	040cec07dr			; 6.461
	DD	0397ba882r			; 0.00024
	DD	040a5eeb7r			; 5.18539
	DD	0409bfeb0r			; 4.87484
	DD	040da3603r			; 6.81909
	DD	03908509cr			; 0.00013
	DD	040a8a6b5r			; 5.27035
	DD	040977eacr			; 4.73421
	DD	040da708fr			; 6.82624
	DD	038da1a93r			; 0.000104
	DD	040abe6e8r			; 5.37194
	DD	040930af4r			; 4.59509
	DD	040d5189ar			; 6.65925
	DD	038ae1049r			; 8.3e-05
	DD	040ab9581r			; 5.362
	DD	04093c250r			; 4.61747
	DD	040dacf03r			; 6.83777
	DD	03890b418r			; 6.9e-05
	DD	040a926e3r			; 5.286
	DD	0409828e7r			; 4.75499
	DD	040e516e1r			; 7.15904
	DD	0384d8559r			; 4.9e-05
	DD	040afa18cr			; 5.48847
	DD	0408cace9r			; 4.39611
	DD	040d74682r			; 6.72736
	DD	038734507r			; 5.8e-05
	DD	0409eafa3r			; 4.95894
	DD	040929321r			; 4.58046
	DD	040cf49a5r			; 6.47774
	DD	037eae18br			; 2.8e-05
	DD	040b0ae1br			; 5.52125
	DD	0408e1885r			; 4.44049
	DD	040e68f80r			; 7.20502
	DD	000000000r			; 0
	DD	000000000r			; 0
	DD	000000000r			; 0
	DD	000000000r			; 0
	DD	0379f6230r			; 1.9e-05
	DD	040b9f5d8r			; 5.81126
	DD	0408cc582r			; 4.39911
	DD	040eac30dr			; 7.33631
_g_sig_last_scan_8x8 DD 00H
	DD	02H
	DD	01H
	DD	03H
	DD	00H
	DD	01H
	DD	02H
	DD	03H
	DD	00H
	DD	02H
	DD	01H
	DD	03H
_g_sig_last_scan_16x16 DD 00H
	DD	04H
	DD	01H
	DD	08H
	DD	05H
	DD	02H
	DD	0cH
	DD	09H
	DD	06H
	DD	03H
	DD	0dH
	DD	0aH
	DD	07H
	DD	0eH
	DD	0bH
	DD	0fH
_g_sig_last_scan_32x32 DD 00H
	DD	08H
	DD	01H
	DD	010H
	DD	09H
	DD	02H
	DD	018H
	DD	011H
	DD	0aH
	DD	03H
	DD	020H
	DD	019H
	DD	012H
	DD	0bH
	DD	04H
	DD	028H
	DD	021H
	DD	01aH
	DD	013H
	DD	0cH
	DD	05H
	DD	030H
	DD	029H
	DD	022H
	DD	01bH
	DD	014H
	DD	0dH
	DD	06H
	DD	038H
	DD	031H
	DD	02aH
	DD	023H
	DD	01cH
	DD	015H
	DD	0eH
	DD	07H
	DD	039H
	DD	032H
	DD	02bH
	DD	024H
	DD	01dH
	DD	016H
	DD	0fH
	DD	03aH
	DD	033H
	DD	02cH
	DD	025H
	DD	01eH
	DD	017H
	DD	03bH
	DD	034H
	DD	02dH
	DD	026H
	DD	01fH
	DD	03cH
	DD	035H
	DD	02eH
	DD	027H
	DD	03dH
	DD	036H
	DD	02fH
	DD	03eH
	DD	037H
	DD	03fH
_g_sig_last_scan_cg DD FLAT:_g_sig_last_scan_8x8
	DD	FLAT:_g_sig_last_scan_8x8+16
	DD	FLAT:_g_sig_last_scan_8x8+32
	DD	FLAT:_g_sig_last_scan_8x8
	DD	FLAT:_g_sig_last_scan_8x8+16
	DD	FLAT:_g_sig_last_scan_8x8+32
	DD	FLAT:_g_sig_last_scan_16x16
	DD	00H
	DD	00H
	DD	FLAT:_g_sig_last_scan_32x32
	DD	00H
	DD	00H
_g_group_idx DB	00H
	DB	01H
	DB	02H
	DB	03H
	DB	04H
	DB	04H
	DB	05H
	DB	05H
	DB	06H
	DB	06H
	DB	06H
	DB	06H
	DB	07H
	DB	07H
	DB	07H
	DB	07H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
_g_min_in_group DB 00H
	DB	01H
	DB	02H
	DB	03H
	DB	04H
	DB	06H
	DB	08H
	DB	0cH
	DB	010H
	DB	018H
	ORG $+6
_g_sao_edge_offsets DD 0ffffffffH
	DD	00H
	DD	01H
	DD	00H
	DD	00H
	DD	0ffffffffH
	DD	00H
	DD	01H
	DD	0ffffffffH
	DD	0ffffffffH
	DD	01H
	DD	01H
	DD	01H
	DD	0ffffffffH
	DD	0ffffffffH
	DD	01H
_strategies_to_select DD FLAT:??_C@_0P@FIMIKDEG@array_checksum@
	DD	FLAT:_kvz_array_checksum
	DD	FLAT:??_C@_09INHMEIKP@array_md5@
	DD	FLAT:_kvz_array_md5
	DD	FLAT:??_C@_07DDJKLCAH@reg_sad@
	DD	FLAT:_kvz_reg_sad
	DD	FLAT:??_C@_07CCGEEBAL@sad_4x4@
	DD	FLAT:_kvz_sad_4x4
	DD	FLAT:??_C@_07MEAHLBLP@sad_8x8@
	DD	FLAT:_kvz_sad_8x8
	DD	FLAT:??_C@_09CIFGAEGF@sad_16x16@
	DD	FLAT:_kvz_sad_16x16
	DD	FLAT:??_C@_09PHPGBCME@sad_32x32@
	DD	FLAT:_kvz_sad_32x32
	DD	FLAT:??_C@_09HIOKBDLK@sad_64x64@
	DD	FLAT:_kvz_sad_64x64
	DD	FLAT:??_C@_08GDBJPAOD@satd_4x4@
	DD	FLAT:_kvz_satd_4x4
	DD	FLAT:??_C@_08IFHKAAFH@satd_8x8@
	DD	FLAT:_kvz_satd_8x8
	DD	FLAT:??_C@_0L@CJHLPOG@satd_16x16@
	DD	FLAT:_kvz_satd_16x16
	DD	FLAT:??_C@_0L@NNDHKJEH@satd_32x32@
	DD	FLAT:_kvz_satd_32x32
	DD	FLAT:??_C@_0L@FCCLKIDJ@satd_64x64@
	DD	FLAT:_kvz_satd_64x64
	DD	FLAT:??_C@_0O@FHJAMJMP@satd_any_size@
	DD	FLAT:_kvz_satd_any_size
	DD	FLAT:??_C@_0N@PBMCJFCI@sad_4x4_dual@
	DD	FLAT:_kvz_sad_4x4_dual
	DD	FLAT:??_C@_0N@NAFGAMEI@sad_8x8_dual@
	DD	FLAT:_kvz_sad_8x8_dual
	DD	FLAT:??_C@_0P@KGAKCNHP@sad_16x16_dual@
	DD	FLAT:_kvz_sad_16x16_dual
	DD	FLAT:??_C@_0P@EBOHBHKK@sad_32x32_dual@
	DD	FLAT:_kvz_sad_32x32_dual
	DD	FLAT:??_C@_0P@BGJOPAPB@sad_64x64_dual@
	DD	FLAT:_kvz_sad_64x64_dual
	DD	FLAT:??_C@_0O@PJODLFIO@satd_4x4_dual@
	DD	FLAT:_kvz_satd_4x4_dual
	DD	FLAT:??_C@_0O@NIHHCMOO@satd_8x8_dual@
	DD	FLAT:_kvz_satd_8x8_dual
	DD	FLAT:??_C@_0BA@GFDJBOPJ@satd_16x16_dual@
	DD	FLAT:_kvz_satd_16x16_dual
	DD	FLAT:??_C@_0BA@ICNECECM@satd_32x32_dual@
	DD	FLAT:_kvz_satd_32x32_dual
	DD	FLAT:??_C@_0BA@NFKNMDHH@satd_64x64_dual@
	DD	FLAT:_kvz_satd_64x64_dual
	DD	FLAT:??_C@_0BD@EFOGIBKC@satd_any_size_quad@
	DD	FLAT:_kvz_satd_any_size_quad
	DD	FLAT:??_C@_0BA@BPDFDAFM@pixels_calc_ssd@
	DD	FLAT:_kvz_pixels_calc_ssd
	DD	FLAT:??_C@_0P@FIKELBGI@bipred_average@
	DD	FLAT:_kvz_bipred_average
	DD	FLAT:??_C@_0BC@IMILIHON@get_optimized_sad@
	DD	FLAT:_kvz_get_optimized_sad
	DD	FLAT:??_C@_07OEMLCPNF@ver_sad@
	DD	FLAT:_kvz_ver_sad
	DD	FLAT:??_C@_07CJIKFDIC@hor_sad@
	DD	FLAT:_kvz_hor_sad
	DD	FLAT:??_C@_09GDPKBOJB@pixel_var@
	DD	FLAT:_kvz_pixel_var
	DD	FLAT:??_C@_0BF@BJKPGPEP@fast_forward_dst_4x4@
	DD	FLAT:_kvz_fast_forward_dst_4x4
	DD	FLAT:??_C@_07MAFDGKIL@dct_4x4@
	DD	FLAT:_kvz_dct_4x4
	DD	FLAT:??_C@_07CGDAJKDP@dct_8x8@
	DD	FLAT:_kvz_dct_8x8
	DD	FLAT:??_C@_09LPGJIHFJ@dct_16x16@
	DD	FLAT:_kvz_dct_16x16
	DD	FLAT:??_C@_09GAMJJBPI@dct_32x32@
	DD	FLAT:_kvz_dct_32x32
	DD	FLAT:??_C@_0BF@LGIDMEOF@fast_inverse_dst_4x4@
	DD	FLAT:_kvz_fast_inverse_dst_4x4
	DD	FLAT:??_C@_08LDLIJGLD@idct_4x4@
	DD	FLAT:_kvz_idct_4x4
	DD	FLAT:??_C@_08FFNLGGAH@idct_8x8@
	DD	FLAT:_kvz_idct_8x8
	DD	FLAT:??_C@_0L@BMPNPGHO@idct_16x16@
	DD	FLAT:_kvz_idct_16x16
	DD	FLAT:??_C@_0L@MDFNOANP@idct_32x32@
	DD	FLAT:_kvz_idct_32x32
	DD	FLAT:??_C@_0CA@KBMGLOML@filter_hpel_blocks_hor_ver_luma@
	DD	FLAT:_kvz_filter_hpel_blocks_hor_ver_luma
	DD	FLAT:??_C@_0BN@LGIFMJCD@filter_hpel_blocks_diag_luma@
	DD	FLAT:_kvz_filter_hpel_blocks_diag_luma
	DD	FLAT:??_C@_0CA@HAFBJKBM@filter_qpel_blocks_hor_ver_luma@
	DD	FLAT:_kvz_filter_qpel_blocks_hor_ver_luma
	DD	FLAT:??_C@_0BN@LBBJMBKC@filter_qpel_blocks_diag_luma@
	DD	FLAT:_kvz_filter_qpel_blocks_diag_luma
	DD	FLAT:??_C@_0BH@DGLFPIPB@sample_quarterpel_luma@
	DD	FLAT:_kvz_sample_quarterpel_luma
	DD	FLAT:??_C@_0BF@HOLGGLNK@sample_octpel_chroma@
	DD	FLAT:_kvz_sample_octpel_chroma
	DD	FLAT:??_C@_0BK@LCPNGAOF@sample_quarterpel_luma_hi@
	DD	FLAT:_kvz_sample_quarterpel_luma_hi
	DD	FLAT:??_C@_0BI@EFIAEBMP@sample_octpel_chroma_hi@
	DD	FLAT:_kvz_sample_octpel_chroma_hi
	DD	FLAT:??_C@_0BD@MPANGNDO@get_extended_block@
	DD	FLAT:_kvz_get_extended_block
	DD	FLAT:??_C@_05DFPBCFDJ@quant@
	DD	FLAT:_kvz_quant
	DD	FLAT:??_C@_0BC@MPMPMGJB@quantize_residual@
	DD	FLAT:_kvz_quantize_residual
	DD	FLAT:??_C@_07GMDOJGPA@dequant@
	DD	FLAT:_kvz_dequant
	DD	FLAT:??_C@_0O@ECIHPEON@coeff_abs_sum@
	DD	FLAT:_kvz_coeff_abs_sum
	DD	FLAT:??_C@_0BA@HMNKAKOO@fast_coeff_cost@
	DD	FLAT:_kvz_fast_coeff_cost
	DD	FLAT:??_C@_0N@NMFCEONC@angular_pred@
	DD	FLAT:_kvz_angular_pred
	DD	FLAT:??_C@_0BC@KPOCLILL@intra_pred_planar@
	DD	FLAT:_kvz_intra_pred_planar
	DD	FLAT:??_C@_0BH@EAOLFJGL@intra_pred_filtered_dc@
	DD	FLAT:_kvz_intra_pred_filtered_dc
	DD	FLAT:??_C@_0BF@LGILOHOJ@sao_edge_ddistortion@
	DD	FLAT:_kvz_sao_edge_ddistortion
	DD	FLAT:??_C@_0BC@OCNKGNNI@calc_sao_edge_dir@
	DD	FLAT:_kvz_calc_sao_edge_dir
	DD	FLAT:??_C@_0BG@IJPOOFFG@sao_reconstruct_color@
	DD	FLAT:_kvz_sao_reconstruct_color
	DD	FLAT:??_C@_0BF@HDNLAKN@sao_band_ddistortion@
	DD	FLAT:_kvz_sao_band_ddistortion
	DD	FLAT:??_C@_0BB@GDIDDFDB@encode_coeff_nxn@
	DD	FLAT:_kvz_encode_coeff_nxn
	DD	00H
	DD	00H
CONST	ENDS
PUBLIC	_kvz_strategy_register_dct_avx2
PUBLIC	__JustMyCode_Default
PUBLIC	??_C@_04GEEJMEMG@avx2@				; `string'
PUBLIC	__xmm@0f0e07060d0c05040b0a030209080100
PUBLIC	__ymm@0000000100000001ffffffffffffffffffffffffffffffff0000000100000001
PUBLIC	__ymm@0100010009080908090809080100010001000100090809080908090801000100
PUBLIC	__ymm@090801000b0a03020f0e07060d0c05040d0c05040f0e07060b0a030209080100
PUBLIC	__ymm@090801000d0c0504090801000d0c05040d0c0504090801000d0c050409080100
PUBLIC	__ymm@09080b0a0d0c0f0e01000302050407060f0e0d0c0b0a09080706050403020100
PUBLIC	__ymm@0d0c05040d0c05040d0c05040d0c05040d0c05040d0c05040d0c05040d0c0504
PUBLIC	__ymm@0f0e0b0a070603020f0e0b0a070603020f0e0b0a070603020f0e0b0a07060302
PUBLIC	__ymm@1d1c1f1e19181b1a15141716111013120f0e0d0c0b0a09080706050403020100
PUBLIC	__ymm@ffffffffffffffffffffffffffffffff00000001000000010000000100000001
PUBLIC	__ymm@ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
EXTRN	_kvz_strategyselector_register:PROC
EXTRN	@_RTC_CheckStackVars@8:PROC
EXTRN	@__CheckForDebuggerJustMyCode@4:PROC
EXTRN	@__security_check_cookie@4:PROC
EXTRN	__RTC_CheckEsp:PROC
EXTRN	__RTC_InitBase:PROC
EXTRN	__RTC_Shutdown:PROC
EXTRN	__chkstk:PROC
EXTRN	_memset:PROC
EXTRN	_kvz_g_convert_to_bit:BYTE
EXTRN	_kvz_g_dst_4:BYTE
EXTRN	_kvz_g_dct_4:BYTE
EXTRN	_kvz_g_dct_8:BYTE
EXTRN	_kvz_g_dct_16:BYTE
EXTRN	_kvz_g_dct_32:BYTE
EXTRN	_kvz_g_dst_4_t:BYTE
EXTRN	_kvz_g_dct_4_t:BYTE
EXTRN	_kvz_g_dct_8_t:BYTE
EXTRN	_kvz_g_dct_16_t:BYTE
EXTRN	_kvz_g_dct_32_t:BYTE
EXTRN	___security_cookie:DWORD
;	COMDAT __ymm@ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
CONST	SEGMENT
__ymm@ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff DB 0ffH
	DB	0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH
	DB	0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH
	DB	0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH
CONST	ENDS
;	COMDAT __ymm@ffffffffffffffffffffffffffffffff00000001000000010000000100000001
CONST	SEGMENT
__ymm@ffffffffffffffffffffffffffffffff00000001000000010000000100000001 DB 01H
	DB	00H, 00H, 00H, 01H, 00H, 00H, 00H, 01H, 00H, 00H, 00H, 01H, 00H
	DB	00H, 00H, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH
	DB	0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH
CONST	ENDS
;	COMDAT __ymm@1d1c1f1e19181b1a15141716111013120f0e0d0c0b0a09080706050403020100
CONST	SEGMENT
__ymm@1d1c1f1e19181b1a15141716111013120f0e0d0c0b0a09080706050403020100 DB 00H
	DB	01H, 02H, 03H, 04H, 05H, 06H, 07H, 08H, 09H, 0aH, 0bH, 0cH, 0dH
	DB	0eH, 0fH, 012H, 013H, 010H, 011H, 016H, 017H, 014H, 015H, 01aH
	DB	01bH, 018H, 019H, 01eH, 01fH, 01cH, 01dH
CONST	ENDS
;	COMDAT __ymm@0f0e0b0a070603020f0e0b0a070603020f0e0b0a070603020f0e0b0a07060302
CONST	SEGMENT
__ymm@0f0e0b0a070603020f0e0b0a070603020f0e0b0a070603020f0e0b0a07060302 DB 02H
	DB	03H, 06H, 07H, 0aH, 0bH, 0eH, 0fH, 02H, 03H, 06H, 07H, 0aH, 0bH
	DB	0eH, 0fH, 02H, 03H, 06H, 07H, 0aH, 0bH, 0eH, 0fH, 02H, 03H, 06H
	DB	07H, 0aH, 0bH, 0eH, 0fH
CONST	ENDS
;	COMDAT __ymm@0d0c05040d0c05040d0c05040d0c05040d0c05040d0c05040d0c05040d0c0504
CONST	SEGMENT
__ymm@0d0c05040d0c05040d0c05040d0c05040d0c05040d0c05040d0c05040d0c0504 DB 04H
	DB	05H, 0cH, 0dH, 04H, 05H, 0cH, 0dH, 04H, 05H, 0cH, 0dH, 04H, 05H
	DB	0cH, 0dH, 04H, 05H, 0cH, 0dH, 04H, 05H, 0cH, 0dH, 04H, 05H, 0cH
	DB	0dH, 04H, 05H, 0cH, 0dH
CONST	ENDS
;	COMDAT __ymm@09080b0a0d0c0f0e01000302050407060f0e0d0c0b0a09080706050403020100
CONST	SEGMENT
__ymm@09080b0a0d0c0f0e01000302050407060f0e0d0c0b0a09080706050403020100 DB 00H
	DB	01H, 02H, 03H, 04H, 05H, 06H, 07H, 08H, 09H, 0aH, 0bH, 0cH, 0dH
	DB	0eH, 0fH, 06H, 07H, 04H, 05H, 02H, 03H, 00H, 01H, 0eH, 0fH, 0cH
	DB	0dH, 0aH, 0bH, 08H, 09H
CONST	ENDS
;	COMDAT __ymm@090801000d0c0504090801000d0c05040d0c0504090801000d0c050409080100
CONST	SEGMENT
__ymm@090801000d0c0504090801000d0c05040d0c0504090801000d0c050409080100 DB 00H
	DB	01H, 08H, 09H, 04H, 05H, 0cH, 0dH, 00H, 01H, 08H, 09H, 04H, 05H
	DB	0cH, 0dH, 04H, 05H, 0cH, 0dH, 00H, 01H, 08H, 09H, 04H, 05H, 0cH
	DB	0dH, 00H, 01H, 08H, 09H
CONST	ENDS
;	COMDAT __ymm@090801000b0a03020f0e07060d0c05040d0c05040f0e07060b0a030209080100
CONST	SEGMENT
__ymm@090801000b0a03020f0e07060d0c05040d0c05040f0e07060b0a030209080100 DB 00H
	DB	01H, 08H, 09H, 02H, 03H, 0aH, 0bH, 06H, 07H, 0eH, 0fH, 04H, 05H
	DB	0cH, 0dH, 04H, 05H, 0cH, 0dH, 06H, 07H, 0eH, 0fH, 02H, 03H, 0aH
	DB	0bH, 00H, 01H, 08H, 09H
CONST	ENDS
;	COMDAT __ymm@0100010009080908090809080100010001000100090809080908090801000100
CONST	SEGMENT
__ymm@0100010009080908090809080100010001000100090809080908090801000100 DB 00H
	DB	01H, 00H, 01H, 08H, 09H, 08H, 09H, 08H, 09H, 08H, 09H, 00H, 01H
	DB	00H, 01H, 00H, 01H, 00H, 01H, 08H, 09H, 08H, 09H, 08H, 09H, 08H
	DB	09H, 00H, 01H, 00H, 01H
CONST	ENDS
;	COMDAT __ymm@0000000100000001ffffffffffffffffffffffffffffffff0000000100000001
CONST	SEGMENT
__ymm@0000000100000001ffffffffffffffffffffffffffffffff0000000100000001 DB 01H
	DB	00H, 00H, 00H, 01H, 00H, 00H, 00H, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH
	DB	0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH, 0ffH
	DB	01H, 00H, 00H, 00H, 01H, 00H, 00H, 00H
CONST	ENDS
;	COMDAT __xmm@0f0e07060d0c05040b0a030209080100
CONST	SEGMENT
__xmm@0f0e07060d0c05040b0a030209080100 DB 00H, 01H, 08H, 09H, 02H, 03H, 0aH
	DB	0bH, 04H, 05H, 0cH, 0dH, 06H, 07H, 0eH, 0fH
CONST	ENDS
;	COMDAT rtc$TMZ
rtc$TMZ	SEGMENT
__RTC_Shutdown.rtc$TMZ DD FLAT:__RTC_Shutdown
rtc$TMZ	ENDS
;	COMDAT rtc$IMZ
rtc$IMZ	SEGMENT
__RTC_InitBase.rtc$IMZ DD FLAT:__RTC_InitBase
rtc$IMZ	ENDS
;	COMDAT ??_C@_04GEEJMEMG@avx2@
CONST	SEGMENT
??_C@_04GEEJMEMG@avx2@ DB 'avx2', 00H			; `string'
CONST	ENDS
; Function compile flags: /Odt
;	COMDAT __JustMyCode_Default
_TEXT	SEGMENT
__JustMyCode_Default PROC				; COMDAT
	push	ebp
	mov	ebp, esp
	pop	ebp
	ret	0
__JustMyCode_Default ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_idct_32x32_avx2
_TEXT	SEGMENT
_dct$ = -2136						; size = 4
_tdct$ = -2124						; size = 4
_tmp$ = -2112						; size = 2048
_shift_2nd$ = -24					; size = 4
_shift_1st$ = -12					; size = 4
__$ArrayPad$ = -4					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_idct_32x32_avx2 PROC				; COMDAT

; 939  : ITRANSFORM(dct, 32);

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -64				; ffffffc0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 3128				; 00000c38H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-3128]
	mov	ecx, 782				; 0000030eH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4
	mov	DWORD PTR _shift_1st$[ebp], 7
	movsx	eax, BYTE PTR _bitdepth$[ebx]
	sub	eax, 8
	mov	ecx, 12					; 0000000cH
	sub	ecx, eax
	mov	DWORD PTR _shift_2nd$[ebp], ecx
	mov	eax, 64					; 00000040H
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_32_t[ecx+eax]
	mov	DWORD PTR _tdct$[ebp], ecx
	mov	eax, 64					; 00000040H
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_32[ecx+eax]
	mov	DWORD PTR _dct$[ebp], ecx
	mov	eax, DWORD PTR _shift_1st$[ebp]
	push	eax
	lea	ecx, DWORD PTR _tmp$[ebp]
	push	ecx
	mov	edx, DWORD PTR _input$[ebx]
	push	edx
	mov	eax, DWORD PTR _tdct$[ebp]
	push	eax
	call	_mul_clip_matrix_32x32_avx2
	add	esp, 16					; 00000010H
	mov	eax, DWORD PTR _shift_2nd$[ebp]
	push	eax
	mov	ecx, DWORD PTR _output$[ebx]
	push	ecx
	mov	edx, DWORD PTR _dct$[ebp]
	push	edx
	lea	eax, DWORD PTR _tmp$[ebp]
	push	eax
	call	_mul_clip_matrix_32x32_avx2
	add	esp, 16					; 00000010H
	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN5@matrix_idc
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	2
$LN5@matrix_idc:
	DD	1
	DD	$LN4@matrix_idc
$LN4@matrix_idc:
	DD	-2112					; fffff7c0H
	DD	2048					; 00000800H
	DD	$LN3@matrix_idc
$LN3@matrix_idc:
	DB	116					; 00000074H
	DB	109					; 0000006dH
	DB	112					; 00000070H
	DB	0
_matrix_idct_32x32_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_dct_32x32_avx2
_TEXT	SEGMENT
_dct$ = -2136						; size = 4
_tdct$ = -2124						; size = 4
_tmp$ = -2112						; size = 2048
_shift_2nd$ = -24					; size = 4
_shift_1st$ = -12					; size = 4
__$ArrayPad$ = -4					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_dct_32x32_avx2 PROC				; COMDAT

; 938  : TRANSFORM(dct, 32);

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -64				; ffffffc0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 3128				; 00000c38H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-3128]
	mov	ecx, 782				; 0000030eH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4
	mov	eax, 1
	shl	eax, 5
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	movsx	edx, BYTE PTR _bitdepth$[ebx]
	lea	eax, DWORD PTR [ecx+edx-7]
	mov	DWORD PTR _shift_1st$[ebp], eax
	mov	eax, 1
	shl	eax, 5
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	add	ecx, 8
	mov	DWORD PTR _shift_2nd$[ebp], ecx
	mov	eax, 64					; 00000040H
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_32_t[ecx+eax]
	mov	DWORD PTR _tdct$[ebp], ecx
	mov	eax, 64					; 00000040H
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_32[ecx+eax]
	mov	DWORD PTR _dct$[ebp], ecx
	mov	eax, DWORD PTR _shift_1st$[ebp]
	push	eax
	lea	ecx, DWORD PTR _tmp$[ebp]
	push	ecx
	mov	edx, DWORD PTR _tdct$[ebp]
	push	edx
	mov	eax, DWORD PTR _input$[ebx]
	push	eax
	call	_mul_clip_matrix_32x32_avx2
	add	esp, 16					; 00000010H
	mov	eax, DWORD PTR _shift_2nd$[ebp]
	push	eax
	mov	ecx, DWORD PTR _output$[ebx]
	push	ecx
	lea	edx, DWORD PTR _tmp$[ebp]
	push	edx
	mov	eax, DWORD PTR _dct$[ebp]
	push	eax
	call	_mul_clip_matrix_32x32_avx2
	add	esp, 16					; 00000010H
	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN5@matrix_dct
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	3
$LN5@matrix_dct:
	DD	1
	DD	$LN4@matrix_dct
$LN4@matrix_dct:
	DD	-2112					; fffff7c0H
	DD	2048					; 00000800H
	DD	$LN3@matrix_dct
$LN3@matrix_dct:
	DB	116					; 00000074H
	DB	109					; 0000006dH
	DB	112					; 00000070H
	DB	0
_matrix_dct_32x32_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _mul_clip_matrix_32x32_avx2
_TEXT	SEGMENT
_h23$1 = -6048						; size = 32
_h01$2 = -5984						; size = 32
_q3$3 = -5920						; size = 32
_q2$4 = -5856						; size = 32
_q1$5 = -5792						; size = 32
_q0$6 = -5728						; size = 32
_dst_base$7 = -5688					; size = 4
_acc_base$8 = -5676					; size = 4
_p_o3$9 = -5664						; size = 32
_p_o2$10 = -5600					; size = 32
_p_o1$11 = -5536					; size = 32
_p_o0$12 = -5472					; size = 32
_p_e3$13 = -5408					; size = 32
_p_e2$14 = -5344					; size = 32
_p_e1$15 = -5280					; size = 32
_p_e0$16 = -5216					; size = 32
_odd$17 = -5152						; size = 32
_even$18 = -5088					; size = 32
_curr_o$19 = -5028					; size = 4
_curr_e$20 = -5016					; size = 4
_acc_base$21 = -5004					; size = 4
_r13_8f$22 = -4992					; size = 32
_r13_07$23 = -4928					; size = 32
_r02_8f$24 = -4864					; size = 32
_r02_07$25 = -4800					; size = 32
_r13h$26 = -4736					; size = 32
_r13l$27 = -4672					; size = 32
_r02h$28 = -4608					; size = 32
_r02l$29 = -4544					; size = 32
_r3$30 = -4480						; size = 32
_r2$31 = -4416						; size = 32
_r1$32 = -4352						; size = 32
_r0$33 = -4288						; size = 32
_j$ = -4248						; size = 4
_i$ = -4236						; size = 4
_accu$ = -4224						; size = 4096
_dst_v$ = -100						; size = 4
_r_v$ = -88						; size = 4
_l_32$ = -76						; size = 4
_debias$ = -64						; size = 32
_add$ = -12						; size = 4
__$ArrayPad$ = -4					; size = 4
_left$ = 8						; size = 4
_right$ = 12						; size = 4
_dst$ = 16						; size = 4
_shift$ = 20						; size = 4
_mul_clip_matrix_32x32_avx2 PROC			; COMDAT

; 816  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	mov	eax, 7608				; 00001db8H
	call	__chkstk
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-7608]
	mov	ecx, 1902				; 0000076eH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 817  :   const int32_t add    = 1 << (shift - 1);

	mov	eax, DWORD PTR _shift$[ebx]
	sub	eax, 1
	mov	ecx, 1
	shlx	edx, ecx, eax
	mov	DWORD PTR _add$[ebp], edx

; 818  :   const __m256i debias = _mm256_set1_epi32(add);

	vmovd	xmm0, DWORD PTR _add$[ebp]
	vpbroadcastd ymm0, xmm0
	vmovdqu	YMMWORD PTR _debias$[ebp], ymm0

; 819  : 
; 820  :   const uint32_t *l_32  = (const uint32_t *)left;

	mov	eax, DWORD PTR _left$[ebx]
	mov	DWORD PTR _l_32$[ebp], eax

; 821  :   const __m256i  *r_v   = (const __m256i *)right;

	mov	eax, DWORD PTR _right$[ebx]
	mov	DWORD PTR _r_v$[ebp], eax

; 822  :         __m256i  *dst_v = (      __m256i *)dst;

	mov	eax, DWORD PTR _dst$[ebx]
	mov	DWORD PTR _dst_v$[ebp], eax

; 823  : 
; 824  :   __m256i accu[128] = {_mm256_setzero_si256()};

	vpxor	xmm0, xmm0, xmm0
	vmovdqu	YMMWORD PTR _accu$[ebp], ymm0
	push	4064					; 00000fe0H
	push	0
	lea	eax, DWORD PTR _accu$[ebp+32]
	push	eax
	call	_memset
	add	esp, 12					; 0000000cH

; 825  :   size_t i, j;
; 826  : 
; 827  :   for (j = 0; j < 64; j += 4) {

	mov	DWORD PTR _j$[ebp], 0
	jmp	SHORT $LN4@mul_clip_m
$LN2@mul_clip_m:
	mov	eax, DWORD PTR _j$[ebp]
	add	eax, 4
	mov	DWORD PTR _j$[ebp], eax
$LN4@mul_clip_m:
	cmp	DWORD PTR _j$[ebp], 64			; 00000040H
	jae	$LN3@mul_clip_m

; 828  :     const __m256i r0 = r_v[j + 0];

	mov	eax, DWORD PTR _j$[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _r_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _r0$33[ebp], ymm0

; 829  :     const __m256i r1 = r_v[j + 1];

	mov	eax, DWORD PTR _j$[ebp]
	add	eax, 1
	shl	eax, 5
	add	eax, DWORD PTR _r_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _r1$32[ebp], ymm0

; 830  :     const __m256i r2 = r_v[j + 2];

	mov	eax, DWORD PTR _j$[ebp]
	add	eax, 2
	shl	eax, 5
	add	eax, DWORD PTR _r_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _r2$31[ebp], ymm0

; 831  :     const __m256i r3 = r_v[j + 3];

	mov	eax, DWORD PTR _j$[ebp]
	add	eax, 3
	shl	eax, 5
	add	eax, DWORD PTR _r_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _r3$30[ebp], ymm0

; 832  : 
; 833  :     __m256i r02l   = _mm256_unpacklo_epi16(r0, r2);

	vmovdqu	ymm0, YMMWORD PTR _r0$33[ebp]
	vpunpcklwd ymm0, ymm0, YMMWORD PTR _r2$31[ebp]
	vmovdqu	YMMWORD PTR _r02l$29[ebp], ymm0

; 834  :     __m256i r02h   = _mm256_unpackhi_epi16(r0, r2);

	vmovdqu	ymm0, YMMWORD PTR _r0$33[ebp]
	vpunpckhwd ymm0, ymm0, YMMWORD PTR _r2$31[ebp]
	vmovdqu	YMMWORD PTR _r02h$28[ebp], ymm0

; 835  :     __m256i r13l   = _mm256_unpacklo_epi16(r1, r3);

	vmovdqu	ymm0, YMMWORD PTR _r1$32[ebp]
	vpunpcklwd ymm0, ymm0, YMMWORD PTR _r3$30[ebp]
	vmovdqu	YMMWORD PTR _r13l$27[ebp], ymm0

; 836  :     __m256i r13h   = _mm256_unpackhi_epi16(r1, r3);

	vmovdqu	ymm0, YMMWORD PTR _r1$32[ebp]
	vpunpckhwd ymm0, ymm0, YMMWORD PTR _r3$30[ebp]
	vmovdqu	YMMWORD PTR _r13h$26[ebp], ymm0

; 837  : 
; 838  :     __m256i r02_07 = _mm256_permute2x128_si256(r02l, r02h, 0x20);

	vmovdqu	ymm0, YMMWORD PTR _r02l$29[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _r02h$28[ebp], 32 ; 00000020H
	vmovdqu	YMMWORD PTR _r02_07$25[ebp], ymm0

; 839  :     __m256i r02_8f = _mm256_permute2x128_si256(r02l, r02h, 0x31);

	vmovdqu	ymm0, YMMWORD PTR _r02l$29[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _r02h$28[ebp], 49 ; 00000031H
	vmovdqu	YMMWORD PTR _r02_8f$24[ebp], ymm0

; 840  : 
; 841  :     __m256i r13_07 = _mm256_permute2x128_si256(r13l, r13h, 0x20);

	vmovdqu	ymm0, YMMWORD PTR _r13l$27[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _r13h$26[ebp], 32 ; 00000020H
	vmovdqu	YMMWORD PTR _r13_07$23[ebp], ymm0

; 842  :     __m256i r13_8f = _mm256_permute2x128_si256(r13l, r13h, 0x31);

	vmovdqu	ymm0, YMMWORD PTR _r13l$27[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _r13h$26[ebp], 49 ; 00000031H
	vmovdqu	YMMWORD PTR _r13_8f$22[ebp], ymm0

; 843  : 
; 844  :     for (i = 0; i < 32; i += 2) {

	mov	DWORD PTR _i$[ebp], 0
	jmp	SHORT $LN7@mul_clip_m
$LN5@mul_clip_m:
	mov	eax, DWORD PTR _i$[ebp]
	add	eax, 2
	mov	DWORD PTR _i$[ebp], eax
$LN7@mul_clip_m:
	cmp	DWORD PTR _i$[ebp], 32			; 00000020H
	jae	$LN6@mul_clip_m

; 845  :       size_t acc_base = i << 2;

	mov	eax, DWORD PTR _i$[ebp]
	shl	eax, 2
	mov	DWORD PTR _acc_base$21[ebp], eax

; 846  : 
; 847  :       uint32_t curr_e    = l_32[(i + 0) * (32 / 2) + (j >> 2)];

	mov	eax, DWORD PTR _i$[ebp]
	shl	eax, 4
	mov	ecx, DWORD PTR _j$[ebp]
	shr	ecx, 2
	add	eax, ecx
	mov	edx, DWORD PTR _l_32$[ebp]
	mov	eax, DWORD PTR [edx+eax*4]
	mov	DWORD PTR _curr_e$20[ebp], eax

; 848  :       uint32_t curr_o    = l_32[(i + 1) * (32 / 2) + (j >> 2)];

	mov	eax, DWORD PTR _i$[ebp]
	add	eax, 1
	shl	eax, 4
	mov	ecx, DWORD PTR _j$[ebp]
	shr	ecx, 2
	add	eax, ecx
	mov	edx, DWORD PTR _l_32$[ebp]
	mov	eax, DWORD PTR [edx+eax*4]
	mov	DWORD PTR _curr_o$19[ebp], eax

; 849  : 
; 850  :       __m256i even       = _mm256_set1_epi32(curr_e);

	vmovd	xmm0, DWORD PTR _curr_e$20[ebp]
	vpbroadcastd ymm0, xmm0
	vmovdqu	YMMWORD PTR _even$18[ebp], ymm0

; 851  :       __m256i odd        = _mm256_set1_epi32(curr_o);

	vmovd	xmm0, DWORD PTR _curr_o$19[ebp]
	vpbroadcastd ymm0, xmm0
	vmovdqu	YMMWORD PTR _odd$17[ebp], ymm0

; 852  : 
; 853  :       __m256i p_e0       = _mm256_madd_epi16(even, r02_07);

	vmovdqu	ymm0, YMMWORD PTR _even$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _r02_07$25[ebp]
	vmovdqu	YMMWORD PTR _p_e0$16[ebp], ymm0

; 854  :       __m256i p_e1       = _mm256_madd_epi16(even, r02_8f);

	vmovdqu	ymm0, YMMWORD PTR _even$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _r02_8f$24[ebp]
	vmovdqu	YMMWORD PTR _p_e1$15[ebp], ymm0

; 855  :       __m256i p_e2       = _mm256_madd_epi16(even, r13_07);

	vmovdqu	ymm0, YMMWORD PTR _even$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _r13_07$23[ebp]
	vmovdqu	YMMWORD PTR _p_e2$14[ebp], ymm0

; 856  :       __m256i p_e3       = _mm256_madd_epi16(even, r13_8f);

	vmovdqu	ymm0, YMMWORD PTR _even$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _r13_8f$22[ebp]
	vmovdqu	YMMWORD PTR _p_e3$13[ebp], ymm0

; 857  : 
; 858  :       __m256i p_o0       = _mm256_madd_epi16(odd,  r02_07);

	vmovdqu	ymm0, YMMWORD PTR _odd$17[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _r02_07$25[ebp]
	vmovdqu	YMMWORD PTR _p_o0$12[ebp], ymm0

; 859  :       __m256i p_o1       = _mm256_madd_epi16(odd,  r02_8f);

	vmovdqu	ymm0, YMMWORD PTR _odd$17[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _r02_8f$24[ebp]
	vmovdqu	YMMWORD PTR _p_o1$11[ebp], ymm0

; 860  :       __m256i p_o2       = _mm256_madd_epi16(odd,  r13_07);

	vmovdqu	ymm0, YMMWORD PTR _odd$17[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _r13_07$23[ebp]
	vmovdqu	YMMWORD PTR _p_o2$10[ebp], ymm0

; 861  :       __m256i p_o3       = _mm256_madd_epi16(odd,  r13_8f);

	vmovdqu	ymm0, YMMWORD PTR _odd$17[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _r13_8f$22[ebp]
	vmovdqu	YMMWORD PTR _p_o3$9[ebp], ymm0

; 862  : 
; 863  :       accu[acc_base + 0] = _mm256_add_epi32 (p_e0, accu[acc_base + 0]);

	mov	eax, DWORD PTR _acc_base$21[ebp]
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _p_e0$16[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _accu$[ebp+eax]
	mov	ecx, DWORD PTR _acc_base$21[ebp]
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _accu$[ebp+ecx], ymm0

; 864  :       accu[acc_base + 1] = _mm256_add_epi32 (p_e1, accu[acc_base + 1]);

	mov	eax, DWORD PTR _acc_base$21[ebp]
	add	eax, 1
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _p_e1$15[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _accu$[ebp+eax]
	mov	ecx, DWORD PTR _acc_base$21[ebp]
	add	ecx, 1
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _accu$[ebp+ecx], ymm0

; 865  :       accu[acc_base + 2] = _mm256_add_epi32 (p_e2, accu[acc_base + 2]);

	mov	eax, DWORD PTR _acc_base$21[ebp]
	add	eax, 2
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _p_e2$14[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _accu$[ebp+eax]
	mov	ecx, DWORD PTR _acc_base$21[ebp]
	add	ecx, 2
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _accu$[ebp+ecx], ymm0

; 866  :       accu[acc_base + 3] = _mm256_add_epi32 (p_e3, accu[acc_base + 3]);

	mov	eax, DWORD PTR _acc_base$21[ebp]
	add	eax, 3
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _p_e3$13[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _accu$[ebp+eax]
	mov	ecx, DWORD PTR _acc_base$21[ebp]
	add	ecx, 3
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _accu$[ebp+ecx], ymm0

; 867  : 
; 868  :       accu[acc_base + 4] = _mm256_add_epi32 (p_o0, accu[acc_base + 4]);

	mov	eax, DWORD PTR _acc_base$21[ebp]
	add	eax, 4
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _p_o0$12[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _accu$[ebp+eax]
	mov	ecx, DWORD PTR _acc_base$21[ebp]
	add	ecx, 4
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _accu$[ebp+ecx], ymm0

; 869  :       accu[acc_base + 5] = _mm256_add_epi32 (p_o1, accu[acc_base + 5]);

	mov	eax, DWORD PTR _acc_base$21[ebp]
	add	eax, 5
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _p_o1$11[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _accu$[ebp+eax]
	mov	ecx, DWORD PTR _acc_base$21[ebp]
	add	ecx, 5
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _accu$[ebp+ecx], ymm0

; 870  :       accu[acc_base + 6] = _mm256_add_epi32 (p_o2, accu[acc_base + 6]);

	mov	eax, DWORD PTR _acc_base$21[ebp]
	add	eax, 6
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _p_o2$10[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _accu$[ebp+eax]
	mov	ecx, DWORD PTR _acc_base$21[ebp]
	add	ecx, 6
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _accu$[ebp+ecx], ymm0

; 871  :       accu[acc_base + 7] = _mm256_add_epi32 (p_o3, accu[acc_base + 7]);

	mov	eax, DWORD PTR _acc_base$21[ebp]
	add	eax, 7
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _p_o3$9[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _accu$[ebp+eax]
	mov	ecx, DWORD PTR _acc_base$21[ebp]
	add	ecx, 7
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _accu$[ebp+ecx], ymm0

; 872  :     }

	jmp	$LN5@mul_clip_m
$LN6@mul_clip_m:

; 873  :   }

	jmp	$LN2@mul_clip_m
$LN3@mul_clip_m:

; 874  : 
; 875  :   for (i = 0; i < 32; i++) {

	mov	DWORD PTR _i$[ebp], 0
	jmp	SHORT $LN10@mul_clip_m
$LN8@mul_clip_m:
	mov	eax, DWORD PTR _i$[ebp]
	add	eax, 1
	mov	DWORD PTR _i$[ebp], eax
$LN10@mul_clip_m:
	cmp	DWORD PTR _i$[ebp], 32			; 00000020H
	jae	$LN1@mul_clip_m

; 876  :     size_t acc_base = i << 2;

	mov	eax, DWORD PTR _i$[ebp]
	shl	eax, 2
	mov	DWORD PTR _acc_base$8[ebp], eax

; 877  :     size_t dst_base = i << 1;

	mov	eax, DWORD PTR _i$[ebp]
	shl	eax, 1
	mov	DWORD PTR _dst_base$7[ebp], eax

; 878  : 
; 879  :     __m256i q0  = truncate_avx2(accu[acc_base + 0], debias, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	mov	ecx, DWORD PTR _acc_base$8[ebp]
	shl	ecx, 5
	vmovdqu	ymm0, YMMWORD PTR _accu$[ebp+ecx]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _q0$6[ebp], ymm0

; 880  :     __m256i q1  = truncate_avx2(accu[acc_base + 1], debias, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	mov	ecx, DWORD PTR _acc_base$8[ebp]
	add	ecx, 1
	shl	ecx, 5
	vmovdqu	ymm0, YMMWORD PTR _accu$[ebp+ecx]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _q1$5[ebp], ymm0

; 881  :     __m256i q2  = truncate_avx2(accu[acc_base + 2], debias, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	mov	ecx, DWORD PTR _acc_base$8[ebp]
	add	ecx, 2
	shl	ecx, 5
	vmovdqu	ymm0, YMMWORD PTR _accu$[ebp+ecx]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _q2$4[ebp], ymm0

; 882  :     __m256i q3  = truncate_avx2(accu[acc_base + 3], debias, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	mov	ecx, DWORD PTR _acc_base$8[ebp]
	add	ecx, 3
	shl	ecx, 5
	vmovdqu	ymm0, YMMWORD PTR _accu$[ebp+ecx]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _q3$3[ebp], ymm0

; 883  : 
; 884  :     __m256i h01 = _mm256_packs_epi32(q0, q1);

	vmovdqu	ymm0, YMMWORD PTR _q0$6[ebp]
	vpackssdw ymm0, ymm0, YMMWORD PTR _q1$5[ebp]
	vmovdqu	YMMWORD PTR _h01$2[ebp], ymm0

; 885  :     __m256i h23 = _mm256_packs_epi32(q2, q3);

	vmovdqu	ymm0, YMMWORD PTR _q2$4[ebp]
	vpackssdw ymm0, ymm0, YMMWORD PTR _q3$3[ebp]
	vmovdqu	YMMWORD PTR _h23$1[ebp], ymm0

; 886  : 
; 887  :             h01 = _mm256_permute4x64_epi64(h01, _MM_SHUFFLE(3, 1, 2, 0));

	vpermq	ymm0, YMMWORD PTR _h01$2[ebp], 216	; 000000d8H
	vmovdqu	YMMWORD PTR _h01$2[ebp], ymm0

; 888  :             h23 = _mm256_permute4x64_epi64(h23, _MM_SHUFFLE(3, 1, 2, 0));

	vpermq	ymm0, YMMWORD PTR _h23$1[ebp], 216	; 000000d8H
	vmovdqu	YMMWORD PTR _h23$1[ebp], ymm0

; 889  : 
; 890  :     _mm256_store_si256(dst_v + dst_base + 0, h01);

	vmovdqu	ymm0, YMMWORD PTR _h01$2[ebp]
	mov	eax, DWORD PTR _dst_base$7[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _dst_v$[ebp]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 891  :     _mm256_store_si256(dst_v + dst_base + 1, h23);

	vmovdqu	ymm0, YMMWORD PTR _h23$1[ebp]
	mov	eax, DWORD PTR _dst_base$7[ebp]
	shl	eax, 5
	mov	ecx, DWORD PTR _dst_v$[ebp]
	vmovdqu	YMMWORD PTR [ecx+eax+32], ymm0

; 892  :   }

	jmp	$LN8@mul_clip_m
$LN1@mul_clip_m:

; 893  : }

	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN14@mul_clip_m
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
$LN14@mul_clip_m:
	DD	1
	DD	$LN13@mul_clip_m
$LN13@mul_clip_m:
	DD	-4224					; ffffef80H
	DD	4096					; 00001000H
	DD	$LN12@mul_clip_m
$LN12@mul_clip_m:
	DB	97					; 00000061H
	DB	99					; 00000063H
	DB	99					; 00000063H
	DB	117					; 00000075H
	DB	0
_mul_clip_matrix_32x32_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_dct_16x16_avx2
_TEXT	SEGMENT
_tmp$ = -608						; size = 512
_o_v$ = -72						; size = 4
_i_v$ = -60						; size = 4
_d_v$ = -48						; size = 4
_dct$ = -36						; size = 4
_shift_2nd$ = -24					; size = 4
_shift_1st$ = -12					; size = 4
__$ArrayPad$ = -4					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_dct_16x16_avx2 PROC				; COMDAT

; 779  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 1016				; 000003f8H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-1016]
	mov	ecx, 254				; 000000feH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 780  :   int32_t shift_1st = kvz_g_convert_to_bit[16] + 1 + (bitdepth - 8);

	mov	eax, 1
	shl	eax, 4
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	movsx	edx, BYTE PTR _bitdepth$[ebx]
	lea	eax, DWORD PTR [ecx+edx-7]
	mov	DWORD PTR _shift_1st$[ebp], eax

; 781  :   int32_t shift_2nd = kvz_g_convert_to_bit[16] + 8;

	mov	eax, 1
	shl	eax, 4
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	add	ecx, 8
	mov	DWORD PTR _shift_2nd$[ebp], ecx

; 782  : 
; 783  :   const int16_t *dct  = &kvz_g_dct_16[0][0];

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_16[ecx+eax]
	mov	DWORD PTR _dct$[ebp], ecx

; 784  : 
; 785  :   /*
; 786  :    * Multiply input by the tranpose of DCT matrix into tmpres, and DCT matrix
; 787  :    * by tmpres - this is then our output matrix
; 788  :    *
; 789  :    * It's easier to implement an AVX2 matrix multiplication if you can multiply
; 790  :    * the left term with the transpose of the right term. Here things are stored
; 791  :    * row-wise, not column-wise, so we can effectively read DCT_T column-wise
; 792  :    * into YMM registers by reading DCT row-wise. Also because of this, the
; 793  :    * first multiplication is hacked to produce the transpose of the result
; 794  :    * instead, since it will be used in similar fashion as the right operand
; 795  :    * in the second multiplication.
; 796  :    */
; 797  : 
; 798  :   const __m256i *d_v = (const __m256i *)dct;

	mov	eax, DWORD PTR _dct$[ebp]
	mov	DWORD PTR _d_v$[ebp], eax

; 799  :   const __m256i *i_v = (const __m256i *)input;

	mov	eax, DWORD PTR _input$[ebx]
	mov	DWORD PTR _i_v$[ebp], eax

; 800  :         __m256i *o_v = (      __m256i *)output;

	mov	eax, DWORD PTR _output$[ebx]
	mov	DWORD PTR _o_v$[ebp], eax

; 801  :   __m256i tmp[16];
; 802  : 
; 803  :   // Hack! (A * B^T)^T = B * A^T, so we can dispatch the transpose-produciong
; 804  :   // multiply completely
; 805  :   matmul_16x16_a_bt(d_v, i_v, tmp, shift_1st);

	mov	eax, DWORD PTR _shift_1st$[ebp]
	push	eax
	lea	ecx, DWORD PTR _tmp$[ebp]
	push	ecx
	mov	edx, DWORD PTR _i_v$[ebp]
	push	edx
	mov	eax, DWORD PTR _d_v$[ebp]
	push	eax
	call	_matmul_16x16_a_bt
	add	esp, 16					; 00000010H

; 806  :   matmul_16x16_a_bt(d_v, tmp, o_v, shift_2nd);

	mov	eax, DWORD PTR _shift_2nd$[ebp]
	push	eax
	mov	ecx, DWORD PTR _o_v$[ebp]
	push	ecx
	lea	edx, DWORD PTR _tmp$[ebp]
	push	edx
	mov	eax, DWORD PTR _d_v$[ebp]
	push	eax
	call	_matmul_16x16_a_bt
	add	esp, 16					; 00000010H

; 807  : }

	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN5@matrix_dct
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	3
$LN5@matrix_dct:
	DD	1
	DD	$LN4@matrix_dct
$LN4@matrix_dct:
	DD	-608					; fffffda0H
	DD	512					; 00000200H
	DD	$LN3@matrix_dct
$LN3@matrix_dct:
	DB	116					; 00000074H
	DB	109					; 0000006dH
	DB	112					; 00000070H
	DB	0
_matrix_dct_16x16_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_idct_16x16_avx2
_TEXT	SEGMENT
_tmp$ = -576						; size = 512
_shift_2nd$ = -24					; size = 4
_shift_1st$ = -12					; size = 4
__$ArrayPad$ = -4					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_idct_16x16_avx2 PROC				; COMDAT

; 769  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -64				; ffffffc0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 1016				; 000003f8H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-1016]
	mov	ecx, 254				; 000000feH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 770  :   int32_t shift_1st = 7;

	mov	DWORD PTR _shift_1st$[ebp], 7

; 771  :   int32_t shift_2nd = 12 - (bitdepth - 8);

	movsx	eax, BYTE PTR _bitdepth$[ebx]
	sub	eax, 8
	mov	ecx, 12					; 0000000cH
	sub	ecx, eax
	mov	DWORD PTR _shift_2nd$[ebp], ecx

; 772  :   ALIGNED(64) int16_t tmp[16 * 16];
; 773  : 
; 774  :   partial_butterfly_inverse_16_avx2(input, tmp,    shift_1st);

	mov	eax, DWORD PTR _shift_1st$[ebp]
	push	eax
	lea	ecx, DWORD PTR _tmp$[ebp]
	push	ecx
	mov	edx, DWORD PTR _input$[ebx]
	push	edx
	call	_partial_butterfly_inverse_16_avx2
	add	esp, 12					; 0000000cH

; 775  :   partial_butterfly_inverse_16_avx2(tmp,   output, shift_2nd);

	mov	eax, DWORD PTR _shift_2nd$[ebp]
	push	eax
	mov	ecx, DWORD PTR _output$[ebx]
	push	ecx
	lea	edx, DWORD PTR _tmp$[ebp]
	push	edx
	call	_partial_butterfly_inverse_16_avx2
	add	esp, 12					; 0000000cH

; 776  : }

	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN5@matrix_idc
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	2
$LN5@matrix_idc:
	DD	1
	DD	$LN4@matrix_idc
$LN4@matrix_idc:
	DD	-576					; fffffdc0H
	DD	512					; 00000200H
	DD	$LN3@matrix_idc
$LN3@matrix_idc:
	DB	116					; 00000074H
	DB	109					; 0000006dH
	DB	112					; 00000070H
	DB	0
_matrix_idct_16x16_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _partial_butterfly_inverse_16_avx2
_TEXT	SEGMENT
_final$1 = -3424					; size = 32
_res_16_1$2 = -3360					; size = 32
_res_hi_t$3 = -3296					; size = 32
_res_lo_t$4 = -3232					; size = 32
_res_hi2$5 = -3168					; size = 32
_res_hi$6 = -3104					; size = 32
_res_lo$7 = -3040					; size = 32
_o_hi$8 = -2976						; size = 32
_o_lo$9 = -2912						; size = 32
_o_neg$10 = -2848					; size = 32
_e$11 = -2784						; size = 32
_ee$12 = -2720						; size = 32
_eeo_eeo2$13 = -2656					; size = 32
_eeo_eeo1$14 = -2592					; size = 32
_eee_eee$15 = -2528					; size = 32
_eee_eeo$16 = -2464					; size = 32
_t_db4$17 = -2400					; size = 32
_d_db4$18 = -2336					; size = 32
_eo3$19 = -2272						; size = 32
_eo2$20 = -2208						; size = 32
_eo$21 = -2144						; size = 32
_eo_parts2$22 = -2080					; size = 32
_eo_parts$23 = -2016					; size = 32
_t_db2$24 = -1952					; size = 32
_d_db2$25 = -1888					; size = 32
_o$26 = -1824						; size = 32
_o2367$27 = -1760					; size = 32
_o0145$28 = -1696					; size = 32
_o37$29 = -1632						; size = 32
_o26$30 = -1568						; size = 32
_o15$31 = -1504						; size = 32
_o04$32 = -1440						; size = 32
_odds$33 = -1376					; size = 32
_col$34 = -1312						; size = 32
_j$35 = -1272						; size = 4
_j$36 = -1260						; size = 4
_dct_col_odds$ = -1248					; size = 128
_dct_cols$ = -1088					; size = 256
_final_shufmask$ = -800					; size = 32
_o_signmask$ = -736					; size = 32
_eeo_signmask$ = -672					; size = 32
_eo_signmask$ = -608					; size = 32
_tdct$ = -568						; size = 4
_width$ = -556						; size = 4
_tsrc$ = -544						; size = 512
__$ArrayPad$ = -4					; size = 4
_src$ = 8						; size = 4
_dst$ = 12						; size = 4
_shift$ = 16						; size = 4
_partial_butterfly_inverse_16_avx2 PROC			; COMDAT

; 673  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	mov	eax, 4792				; 000012b8H
	call	__chkstk
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-4792]
	mov	ecx, 1198				; 000004aeH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 674  :   __m256i tsrc[16];
; 675  : 
; 676  :   const uint32_t width = 16;

	mov	DWORD PTR _width$[ebp], 16		; 00000010H

; 677  : 
; 678  :   const int16_t *tdct = &kvz_g_dct_16_t[0][0];

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_16_t[ecx+eax]
	mov	DWORD PTR _tdct$[ebp], ecx

; 679  : 
; 680  :   const __m256i  eo_signmask = _mm256_setr_epi32( 1,  1,  1,  1, -1, -1, -1, -1);

	vmovdqu	ymm0, YMMWORD PTR __ymm@ffffffffffffffffffffffffffffffff00000001000000010000000100000001
	vmovdqu	YMMWORD PTR _eo_signmask$[ebp], ymm0

; 681  :   const __m256i eeo_signmask = _mm256_setr_epi32( 1,  1, -1, -1, -1, -1,  1,  1);

	vmovdqu	ymm0, YMMWORD PTR __ymm@0000000100000001ffffffffffffffffffffffffffffffff0000000100000001
	vmovdqu	YMMWORD PTR _eeo_signmask$[ebp], ymm0

; 682  :   const __m256i   o_signmask = _mm256_set1_epi32(-1);

	vmovdqu	ymm0, YMMWORD PTR __ymm@ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
	vmovdqu	YMMWORD PTR _o_signmask$[ebp], ymm0

; 683  : 
; 684  :   const __m256i final_shufmask = _mm256_setr_epi8( 0,  1,  2,  3,  4,  5,  6,  7,

	vmovdqu	ymm0, YMMWORD PTR __ymm@09080b0a0d0c0f0e01000302050407060f0e0d0c0b0a09080706050403020100
	vmovdqu	YMMWORD PTR _final_shufmask$[ebp], ymm0

; 685  :                                                    8,  9, 10, 11, 12, 13, 14, 15,
; 686  :                                                    6,  7,  4,  5,  2,  3,  0,  1,
; 687  :                                                   14, 15, 12, 13, 10, 11,  8,  9);
; 688  :   transpose_16x16(src, (int16_t *)tsrc);

	lea	eax, DWORD PTR _tsrc$[ebp]
	push	eax
	mov	ecx, DWORD PTR _src$[ebx]
	push	ecx
	call	_transpose_16x16
	add	esp, 8

; 689  : 
; 690  :   const __m256i dct_cols[8] = {

	mov	eax, DWORD PTR _tdct$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_cols$[ebp], ymm0
	mov	eax, DWORD PTR _tdct$[ebp]
	add	eax, 32					; 00000020H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_cols$[ebp+32], ymm0
	mov	eax, DWORD PTR _tdct$[ebp]
	add	eax, 64					; 00000040H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_cols$[ebp+64], ymm0
	mov	eax, DWORD PTR _tdct$[ebp]
	add	eax, 96					; 00000060H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_cols$[ebp+96], ymm0
	mov	eax, DWORD PTR _tdct$[ebp]
	add	eax, 128				; 00000080H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_cols$[ebp+128], ymm0
	mov	eax, DWORD PTR _tdct$[ebp]
	add	eax, 160				; 000000a0H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_cols$[ebp+160], ymm0
	mov	eax, DWORD PTR _tdct$[ebp]
	add	eax, 192				; 000000c0H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_cols$[ebp+192], ymm0
	mov	eax, DWORD PTR _tdct$[ebp]
	add	eax, 224				; 000000e0H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_cols$[ebp+224], ymm0

; 691  :     _mm256_load_si256((const __m256i *)tdct + 0),
; 692  :     _mm256_load_si256((const __m256i *)tdct + 1),
; 693  :     _mm256_load_si256((const __m256i *)tdct + 2),
; 694  :     _mm256_load_si256((const __m256i *)tdct + 3),
; 695  :     _mm256_load_si256((const __m256i *)tdct + 4),
; 696  :     _mm256_load_si256((const __m256i *)tdct + 5),
; 697  :     _mm256_load_si256((const __m256i *)tdct + 6),
; 698  :     _mm256_load_si256((const __m256i *)tdct + 7),
; 699  :   };
; 700  : 
; 701  :   // These contain: D1,0 D3,0 D5,0 D7,0 D9,0 Db,0 Dd,0 Df,0 | D1,4 D3,4 D5,4 D7,4 D9,4 Db,4 Dd,4 Df,4
; 702  :   //                D1,1 D3,1 D5,1 D7,1 D9,1 Db,1 Dd,1 Df,1 | D1,5 D3,5 D5,5 D7,5 D9,5 Db,5 Dd,5 Df,5
; 703  :   //                D1,2 D3,2 D5,2 D7,2 D9,2 Db,2 Dd,2 Df,2 | D1,6 D3,6 D5,6 D7,6 D9,6 Db,6 Dd,6 Df,6
; 704  :   //                D1,3 D3,3 D5,3 D7,3 D9,3 Db,3 Dd,3 Df,3 | D1,7 D3,7 D5,7 D7,7 D9,7 Db,7 Dd,7 Df,7
; 705  :   __m256i dct_col_odds[4];
; 706  :   for (uint32_t j = 0; j < 4; j++) {

	mov	DWORD PTR _j$36[ebp], 0
	jmp	SHORT $LN4@partial_bu
$LN2@partial_bu:
	mov	eax, DWORD PTR _j$36[ebp]
	add	eax, 1
	mov	DWORD PTR _j$36[ebp], eax
$LN4@partial_bu:
	cmp	DWORD PTR _j$36[ebp], 4
	jae	SHORT $LN3@partial_bu

; 707  :     dct_col_odds[j] = extract_combine_odds(dct_cols[j + 0], dct_cols[j + 4]);

	mov	eax, DWORD PTR _j$36[ebp]
	add	eax, 4
	shl	eax, 5
	vmovdqu	ymm1, YMMWORD PTR _dct_cols$[ebp+eax]
	mov	ecx, DWORD PTR _j$36[ebp]
	shl	ecx, 5
	vmovdqu	ymm0, YMMWORD PTR _dct_cols$[ebp+ecx]
	call	_extract_combine_odds
	mov	edx, DWORD PTR _j$36[ebp]
	shl	edx, 5
	vmovdqu	YMMWORD PTR _dct_col_odds$[ebp+edx], ymm0

; 708  :   }

	jmp	SHORT $LN2@partial_bu
$LN3@partial_bu:

; 709  :   for (uint32_t j = 0; j < width; j++) {

	mov	DWORD PTR _j$35[ebp], 0
	jmp	SHORT $LN7@partial_bu
$LN5@partial_bu:
	mov	eax, DWORD PTR _j$35[ebp]
	add	eax, 1
	mov	DWORD PTR _j$35[ebp], eax
$LN7@partial_bu:
	mov	eax, DWORD PTR _j$35[ebp]
	cmp	eax, DWORD PTR _width$[ebp]
	jae	$LN1@partial_bu

; 710  :     __m256i col = tsrc[j];

	mov	eax, DWORD PTR _j$35[ebp]
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _tsrc$[ebp+eax]
	vmovdqu	YMMWORD PTR _col$34[ebp], ymm0

; 711  :     __m256i odds = extract_odds(col);

	vmovdqu	ymm0, YMMWORD PTR _col$34[ebp]
	call	_extract_odds
	vmovdqu	YMMWORD PTR _odds$33[ebp], ymm0

; 712  : 
; 713  :     __m256i o04   = _mm256_madd_epi16           (odds,     dct_col_odds[0]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 0
	vmovdqu	ymm0, YMMWORD PTR _odds$33[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _dct_col_odds$[ebp+ecx]
	vmovdqu	YMMWORD PTR _o04$32[ebp], ymm0

; 714  :     __m256i o15   = _mm256_madd_epi16           (odds,     dct_col_odds[1]);

	mov	eax, 32					; 00000020H
	shl	eax, 0
	vmovdqu	ymm0, YMMWORD PTR _odds$33[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _dct_col_odds$[ebp+eax]
	vmovdqu	YMMWORD PTR _o15$31[ebp], ymm0

; 715  :     __m256i o26   = _mm256_madd_epi16           (odds,     dct_col_odds[2]);

	mov	eax, 32					; 00000020H
	shl	eax, 1
	vmovdqu	ymm0, YMMWORD PTR _odds$33[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _dct_col_odds$[ebp+eax]
	vmovdqu	YMMWORD PTR _o26$30[ebp], ymm0

; 716  :     __m256i o37   = _mm256_madd_epi16           (odds,     dct_col_odds[3]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	vmovdqu	ymm0, YMMWORD PTR _odds$33[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _dct_col_odds$[ebp+ecx]
	vmovdqu	YMMWORD PTR _o37$29[ebp], ymm0

; 717  : 
; 718  :     __m256i o0145 = _mm256_hadd_epi32           (o04,      o15);

	vmovdqu	ymm0, YMMWORD PTR _o04$32[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _o15$31[ebp]
	vmovdqu	YMMWORD PTR _o0145$28[ebp], ymm0

; 719  :     __m256i o2367 = _mm256_hadd_epi32           (o26,      o37);

	vmovdqu	ymm0, YMMWORD PTR _o26$30[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _o37$29[ebp]
	vmovdqu	YMMWORD PTR _o2367$27[ebp], ymm0

; 720  : 
; 721  :     __m256i o     = _mm256_hadd_epi32           (o0145,    o2367);

	vmovdqu	ymm0, YMMWORD PTR _o0145$28[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _o2367$27[ebp]
	vmovdqu	YMMWORD PTR _o$26[ebp], ymm0

; 722  : 
; 723  :     // D0,2 D0,6 D1,2 D1,6 D1,a D1,e D0,a D0,e | D2,2 D2,6 D3,2 D3,6 D3,a D3,e D2,a D2,e
; 724  :     __m256i d_db2 = extract_26ae(dct_cols);

	lea	eax, DWORD PTR _dct_cols$[ebp]
	push	eax
	call	_extract_26ae
	add	esp, 4
	vmovdqu	YMMWORD PTR _d_db2$25[ebp], ymm0

; 725  : 
; 726  :     // 2 6 2 6 a e a e | 2 6 2 6 a e a e
; 727  :     __m256i t_db2 = extract_26ae_vec            (col);

	vmovdqu	ymm0, YMMWORD PTR _col$34[ebp]
	call	_extract_26ae_vec
	vmovdqu	YMMWORD PTR _t_db2$24[ebp], ymm0

; 728  : 
; 729  :     __m256i eo_parts  = _mm256_madd_epi16       (d_db2,    t_db2);

	vmovdqu	ymm0, YMMWORD PTR _d_db2$25[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _t_db2$24[ebp]
	vmovdqu	YMMWORD PTR _eo_parts$23[ebp], ymm0

; 730  :     __m256i eo_parts2 = _mm256_shuffle_epi32    (eo_parts, _MM_SHUFFLE(0, 1, 2, 3));

	vpshufd	ymm0, YMMWORD PTR _eo_parts$23[ebp], 27	; 0000001bH
	vmovdqu	YMMWORD PTR _eo_parts2$22[ebp], ymm0

; 731  : 
; 732  :     // EO0 EO1 EO1 EO0 | EO2 EO3 EO3 EO2
; 733  :     __m256i eo        = _mm256_add_epi32        (eo_parts, eo_parts2);

	vmovdqu	ymm0, YMMWORD PTR _eo_parts$23[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _eo_parts2$22[ebp]
	vmovdqu	YMMWORD PTR _eo$21[ebp], ymm0

; 734  :     __m256i eo2       = _mm256_permute4x64_epi64(eo,       _MM_SHUFFLE(1, 3, 2, 0));

	vpermq	ymm0, YMMWORD PTR _eo$21[ebp], 120	; 00000078H
	vmovdqu	YMMWORD PTR _eo2$20[ebp], ymm0

; 735  :     __m256i eo3       = _mm256_sign_epi32       (eo2,      eo_signmask);

	vmovdqu	ymm0, YMMWORD PTR _eo2$20[ebp]
	vpsignd	ymm0, ymm0, YMMWORD PTR _eo_signmask$[ebp]
	vmovdqu	YMMWORD PTR _eo3$19[ebp], ymm0

; 736  : 
; 737  :     __m256i d_db4     = extract_d048c           (dct_cols);

	lea	eax, DWORD PTR _dct_cols$[ebp]
	push	eax
	call	_extract_d048c
	add	esp, 4
	vmovdqu	YMMWORD PTR _d_db4$18[ebp], ymm0

; 738  :     __m256i t_db4     = extract_d048c_vec       (col);

	vmovdqu	ymm0, YMMWORD PTR _col$34[ebp]
	call	_extract_d048c_vec
	vmovdqu	YMMWORD PTR _t_db4$17[ebp], ymm0

; 739  :     __m256i eee_eeo   = _mm256_madd_epi16       (d_db4,   t_db4);

	vmovdqu	ymm0, YMMWORD PTR _d_db4$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _t_db4$17[ebp]
	vmovdqu	YMMWORD PTR _eee_eeo$16[ebp], ymm0

; 740  : 
; 741  :     __m256i eee_eee   = _mm256_permute4x64_epi64(eee_eeo,  _MM_SHUFFLE(3, 0, 3, 0));

	vpermq	ymm0, YMMWORD PTR _eee_eeo$16[ebp], 204	; 000000ccH
	vmovdqu	YMMWORD PTR _eee_eee$15[ebp], ymm0

; 742  :     __m256i eeo_eeo1  = _mm256_permute4x64_epi64(eee_eeo,  _MM_SHUFFLE(1, 2, 1, 2));

	vpermq	ymm0, YMMWORD PTR _eee_eeo$16[ebp], 102	; 00000066H
	vmovdqu	YMMWORD PTR _eeo_eeo1$14[ebp], ymm0

; 743  : 
; 744  :     __m256i eeo_eeo2  = _mm256_sign_epi32       (eeo_eeo1, eeo_signmask);

	vmovdqu	ymm0, YMMWORD PTR _eeo_eeo1$14[ebp]
	vpsignd	ymm0, ymm0, YMMWORD PTR _eeo_signmask$[ebp]
	vmovdqu	YMMWORD PTR _eeo_eeo2$13[ebp], ymm0

; 745  : 
; 746  :     // EE0 EE1 EE2 EE3 | EE3 EE2 EE1 EE0
; 747  :     __m256i ee        = _mm256_add_epi32        (eee_eee,  eeo_eeo2);

	vmovdqu	ymm0, YMMWORD PTR _eee_eee$15[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _eeo_eeo2$13[ebp]
	vmovdqu	YMMWORD PTR _ee$12[ebp], ymm0

; 748  :     __m256i e         = _mm256_add_epi32        (ee,       eo3);

	vmovdqu	ymm0, YMMWORD PTR _ee$12[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _eo3$19[ebp]
	vmovdqu	YMMWORD PTR _e$11[ebp], ymm0

; 749  : 
; 750  :     __m256i o_neg     = _mm256_sign_epi32       (o,        o_signmask);

	vmovdqu	ymm0, YMMWORD PTR _o$26[ebp]
	vpsignd	ymm0, ymm0, YMMWORD PTR _o_signmask$[ebp]
	vmovdqu	YMMWORD PTR _o_neg$10[ebp], ymm0

; 751  :     __m256i o_lo      = _mm256_blend_epi32      (o,        o_neg, 0xf0); // 1111 0000

	vmovdqu	ymm0, YMMWORD PTR _o$26[ebp]
	vpblendd ymm0, ymm0, YMMWORD PTR _o_neg$10[ebp], 240 ; 000000f0H
	vmovdqu	YMMWORD PTR _o_lo$9[ebp], ymm0

; 752  :     __m256i o_hi      = _mm256_blend_epi32      (o,        o_neg, 0x0f); // 0000 1111

	vmovdqu	ymm0, YMMWORD PTR _o$26[ebp]
	vpblendd ymm0, ymm0, YMMWORD PTR _o_neg$10[ebp], 15 ; 0000000fH
	vmovdqu	YMMWORD PTR _o_hi$8[ebp], ymm0

; 753  : 
; 754  :     __m256i res_lo    = _mm256_add_epi32        (e,        o_lo);

	vmovdqu	ymm0, YMMWORD PTR _e$11[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _o_lo$9[ebp]
	vmovdqu	YMMWORD PTR _res_lo$7[ebp], ymm0

; 755  :     __m256i res_hi    = _mm256_add_epi32        (e,        o_hi);

	vmovdqu	ymm0, YMMWORD PTR _e$11[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _o_hi$8[ebp]
	vmovdqu	YMMWORD PTR _res_hi$6[ebp], ymm0

; 756  :     __m256i res_hi2   = _mm256_permute4x64_epi64(res_hi,   _MM_SHUFFLE(1, 0, 3, 2));

	vpermq	ymm0, YMMWORD PTR _res_hi$6[ebp], 78	; 0000004eH
	vmovdqu	YMMWORD PTR _res_hi2$5[ebp], ymm0

; 757  : 
; 758  :     __m256i res_lo_t  = truncate_inv(res_lo,  shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm0, YMMWORD PTR _res_lo$7[ebp]
	call	_truncate_inv
	add	esp, 4
	vmovdqu	YMMWORD PTR _res_lo_t$4[ebp], ymm0

; 759  :     __m256i res_hi_t  = truncate_inv(res_hi2, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm0, YMMWORD PTR _res_hi2$5[ebp]
	call	_truncate_inv
	add	esp, 4
	vmovdqu	YMMWORD PTR _res_hi_t$3[ebp], ymm0

; 760  : 
; 761  :     __m256i res_16_1  = _mm256_packs_epi32      (res_lo_t, res_hi_t);

	vmovdqu	ymm0, YMMWORD PTR _res_lo_t$4[ebp]
	vpackssdw ymm0, ymm0, YMMWORD PTR _res_hi_t$3[ebp]
	vmovdqu	YMMWORD PTR _res_16_1$2[ebp], ymm0

; 762  :     __m256i final     = _mm256_shuffle_epi8     (res_16_1, final_shufmask);

	vmovdqu	ymm0, YMMWORD PTR _res_16_1$2[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _final_shufmask$[ebp]
	vmovdqu	YMMWORD PTR _final$1[ebp], ymm0

; 763  : 
; 764  :     _mm256_store_si256((__m256i *)dst + j, final);

	vmovdqu	ymm0, YMMWORD PTR _final$1[ebp]
	mov	eax, DWORD PTR _j$35[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _dst$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 765  :   }

	jmp	$LN5@partial_bu
$LN1@partial_bu:

; 766  : }

	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN13@partial_bu
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	1
$LN13@partial_bu:
	DD	3
	DD	$LN12@partial_bu
$LN12@partial_bu:
	DD	-544					; fffffde0H
	DD	512					; 00000200H
	DD	$LN9@partial_bu
	DD	-1088					; fffffbc0H
	DD	256					; 00000100H
	DD	$LN10@partial_bu
	DD	-1248					; fffffb20H
	DD	128					; 00000080H
	DD	$LN11@partial_bu
$LN11@partial_bu:
	DB	100					; 00000064H
	DB	99					; 00000063H
	DB	116					; 00000074H
	DB	95					; 0000005fH
	DB	99					; 00000063H
	DB	111					; 0000006fH
	DB	108					; 0000006cH
	DB	95					; 0000005fH
	DB	111					; 0000006fH
	DB	100					; 00000064H
	DB	100					; 00000064H
	DB	115					; 00000073H
	DB	0
$LN10@partial_bu:
	DB	100					; 00000064H
	DB	99					; 00000063H
	DB	116					; 00000074H
	DB	95					; 0000005fH
	DB	99					; 00000063H
	DB	111					; 0000006fH
	DB	108					; 0000006cH
	DB	115					; 00000073H
	DB	0
$LN9@partial_bu:
	DB	116					; 00000074H
	DB	115					; 00000073H
	DB	114					; 00000072H
	DB	99					; 00000063H
	DB	0
_partial_butterfly_inverse_16_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _extract_d048c_vec
_TEXT	SEGMENT
_final$ = -384						; size = 32
_col_his$ = -320					; size = 32
_col_los$ = -256					; size = 32
_col_db4s$ = -192					; size = 32
_shufmask$ = -128					; size = 32
_col$ = -64						; size = 32
_extract_d048c_vec PROC					; COMDAT
; _col$ = ymm0

; 658  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 600				; 00000258H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-600]
	mov	ecx, 150				; 00000096H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	vmovups	YMMWORD PTR _col$[ebp], ymm0
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 659  :   const __m256i shufmask = _mm256_setr_epi8( 0,  1,  0,  1,  8,  9,  8,  9,

	vmovdqu	ymm0, YMMWORD PTR __ymm@0100010009080908090809080100010001000100090809080908090801000100
	vmovdqu	YMMWORD PTR _shufmask$[ebp], ymm0

; 660  :                                              8,  9,  8,  9,  0,  1,  0,  1,
; 661  :                                              0,  1,  0,  1,  8,  9,  8,  9,
; 662  :                                              8,  9,  8,  9,  0,  1,  0,  1);
; 663  : 
; 664  :   __m256i col_db4s = _mm256_shuffle_epi8     (col, shufmask);

	vmovdqu	ymm0, YMMWORD PTR _col$[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _shufmask$[ebp]
	vmovdqu	YMMWORD PTR _col_db4s$[ebp], ymm0

; 665  :   __m256i col_los  = _mm256_permute4x64_epi64(col_db4s, _MM_SHUFFLE(1, 1, 0, 0));

	vpermq	ymm0, YMMWORD PTR _col_db4s$[ebp], 80	; 00000050H
	vmovdqu	YMMWORD PTR _col_los$[ebp], ymm0

; 666  :   __m256i col_his  = _mm256_permute4x64_epi64(col_db4s, _MM_SHUFFLE(3, 3, 2, 2));

	vpermq	ymm0, YMMWORD PTR _col_db4s$[ebp], 250	; 000000faH
	vmovdqu	YMMWORD PTR _col_his$[ebp], ymm0

; 667  : 
; 668  :   __m256i final    = _mm256_unpacklo_epi16   (col_los,  col_his);

	vmovdqu	ymm0, YMMWORD PTR _col_los$[ebp]
	vpunpcklwd ymm0, ymm0, YMMWORD PTR _col_his$[ebp]
	vmovdqu	YMMWORD PTR _final$[ebp], ymm0

; 669  :   return final;

	vmovdqu	ymm0, YMMWORD PTR _final$[ebp]

; 670  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_extract_d048c_vec ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _extract_d048c
_TEXT	SEGMENT
_final$ = -512						; size = 32
_cmbd3$ = -448						; size = 32
_cmbd2$ = -384						; size = 32
_cmbd$ = -320						; size = 32
_c1_2$ = -256						; size = 32
_c1$ = -192						; size = 32
_c0$ = -128						; size = 32
_final_shuf$ = -64					; size = 32
_tdct$ = 8						; size = 4
_extract_d048c PROC					; COMDAT

; 639  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 920				; 00000398H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-920]
	mov	ecx, 230				; 000000e6H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 640  :   const __m256i final_shuf = _mm256_setr_epi8( 0,  1,  8,  9,  2,  3, 10, 11,

	vmovdqu	ymm0, YMMWORD PTR __ymm@090801000b0a03020f0e07060d0c05040d0c05040f0e07060b0a030209080100
	vmovdqu	YMMWORD PTR _final_shuf$[ebp], ymm0

; 641  :                                                6,  7, 14, 15,  4,  5, 12, 13,
; 642  :                                                4,  5, 12, 13,  6,  7, 14, 15,
; 643  :                                                2,  3, 10, 11,  0,  1,  8,  9);
; 644  :   __m256i c0 = tdct[0];

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 0
	add	ecx, DWORD PTR _tdct$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _c0$[ebp], ymm0

; 645  :   __m256i c1 = tdct[1];

	mov	eax, 32					; 00000020H
	shl	eax, 0
	add	eax, DWORD PTR _tdct$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _c1$[ebp], ymm0

; 646  : 
; 647  :   __m256i c1_2  = _mm256_slli_epi32       (c1,    16);

	vmovdqu	ymm0, YMMWORD PTR _c1$[ebp]
	vpslld	ymm0, ymm0, 16				; 00000010H
	vmovdqu	YMMWORD PTR _c1_2$[ebp], ymm0

; 648  :   __m256i cmbd  = _mm256_blend_epi16      (c0,    c1_2, 0x22); // 0010 0010

	vmovdqu	ymm0, YMMWORD PTR _c0$[ebp]
	vpblendw ymm0, ymm0, YMMWORD PTR _c1_2$[ebp], 34 ; 00000022H
	vmovdqu	YMMWORD PTR _cmbd$[ebp], ymm0

; 649  :   __m256i cmbd2 = _mm256_shuffle_epi32    (cmbd,  _MM_SHUFFLE(2, 0, 2, 0));

	vpshufd	ymm0, YMMWORD PTR _cmbd$[ebp], 136	; 00000088H
	vmovdqu	YMMWORD PTR _cmbd2$[ebp], ymm0

; 650  :   __m256i cmbd3 = _mm256_permute4x64_epi64(cmbd2, _MM_SHUFFLE(3, 1, 2, 0));

	vpermq	ymm0, YMMWORD PTR _cmbd2$[ebp], 216	; 000000d8H
	vmovdqu	YMMWORD PTR _cmbd3$[ebp], ymm0

; 651  :   __m256i final = _mm256_shuffle_epi8     (cmbd3, final_shuf);

	vmovdqu	ymm0, YMMWORD PTR _cmbd3$[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _final_shuf$[ebp]
	vmovdqu	YMMWORD PTR _final$[ebp], ymm0

; 652  : 
; 653  :   return final;

	vmovdqu	ymm0, YMMWORD PTR _final$[ebp]

; 654  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_extract_d048c ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _extract_26ae_vec
_TEXT	SEGMENT
_final$ = -256						; size = 32
_reord$ = -192						; size = 32
_mask_26ae$ = -128					; size = 32
_col$ = -64						; size = 32
_extract_26ae_vec PROC					; COMDAT
; _col$ = ymm0

; 628  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 472				; 000001d8H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-472]
	mov	ecx, 118				; 00000076H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	vmovups	YMMWORD PTR _col$[ebp], ymm0
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 629  :   const __m256i mask_26ae = _mm256_set1_epi32(0x0d0c0504);

	vmovdqu	ymm0, YMMWORD PTR __ymm@0d0c05040d0c05040d0c05040d0c05040d0c05040d0c05040d0c05040d0c0504
	vmovdqu	YMMWORD PTR _mask_26ae$[ebp], ymm0

; 630  : 
; 631  :   // 2 6 2 6 2 6 2 6 | a e a e a e a e
; 632  :   __m256i reord = _mm256_shuffle_epi8     (col,   mask_26ae);

	vmovdqu	ymm0, YMMWORD PTR _col$[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _mask_26ae$[ebp]
	vmovdqu	YMMWORD PTR _reord$[ebp], ymm0

; 633  :   __m256i final = _mm256_permute4x64_epi64(reord, _MM_SHUFFLE(3, 1, 2, 0));

	vpermq	ymm0, YMMWORD PTR _reord$[ebp], 216	; 000000d8H
	vmovdqu	YMMWORD PTR _final$[ebp], ymm0

; 634  :   return  final;

	vmovdqu	ymm0, YMMWORD PTR _final$[ebp]

; 635  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_extract_26ae_vec ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _extract_26ae
_TEXT	SEGMENT
_evens_0123$ = -512					; size = 32
_evens_23$ = -448					; size = 32
_evens_01$ = -384					; size = 32
_cmbd_23$ = -320					; size = 32
_cmbd_01$ = -256					; size = 32
_shufd_2$ = -192					; size = 32
_shufd_0$ = -128					; size = 32
_evens_mask$ = -64					; size = 32
_tdct$ = 8						; size = 4
_extract_26ae PROC					; COMDAT

; 603  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 920				; 00000398H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-920]
	mov	ecx, 230				; 000000e6H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 604  :   // 02 03 22 23 06 07 26 27 | 0a 0b 2a 2b 02 0f 2e 2f
; 605  :   // =>
; 606  :   // 02 06 22 26 02 06 22 26 | 2a 2e 0a 0e 2a 2e 0a 0e
; 607  :   const __m256i evens_mask = _mm256_setr_epi8( 0,  1,  8,  9,  4,  5, 12, 13,

	vmovdqu	ymm0, YMMWORD PTR __ymm@090801000d0c0504090801000d0c05040d0c0504090801000d0c050409080100
	vmovdqu	YMMWORD PTR _evens_mask$[ebp], ymm0

; 608  :                                                0,  1,  8,  9,  4,  5, 12, 13,
; 609  :                                                4,  5, 12, 13,  0,  1,  8,  9,
; 610  :                                                4,  5, 12, 13,  0,  1,  8,  9);
; 611  : 
; 612  :   __m256i shufd_0 = _mm256_shuffle_epi32(tdct[0], _MM_SHUFFLE(2, 3, 0, 1));

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 0
	add	ecx, DWORD PTR _tdct$[ebx]
	vpshufd	ymm0, YMMWORD PTR [ecx], 177		; 000000b1H
	vmovdqu	YMMWORD PTR _shufd_0$[ebp], ymm0

; 613  :   __m256i shufd_2 = _mm256_shuffle_epi32(tdct[2], _MM_SHUFFLE(2, 3, 0, 1));

	mov	eax, 32					; 00000020H
	shl	eax, 1
	add	eax, DWORD PTR _tdct$[ebx]
	vpshufd	ymm0, YMMWORD PTR [eax], 177		; 000000b1H
	vmovdqu	YMMWORD PTR _shufd_2$[ebp], ymm0

; 614  : 
; 615  :   __m256i cmbd_01 = _mm256_blend_epi32(shufd_0, tdct[1], 0xaa); // 1010 1010

	mov	eax, 32					; 00000020H
	shl	eax, 0
	add	eax, DWORD PTR _tdct$[ebx]
	vmovdqu	ymm0, YMMWORD PTR _shufd_0$[ebp]
	vpblendd ymm0, ymm0, YMMWORD PTR [eax], 170	; 000000aaH
	vmovdqu	YMMWORD PTR _cmbd_01$[ebp], ymm0

; 616  :   __m256i cmbd_23 = _mm256_blend_epi32(shufd_2, tdct[3], 0xaa); // 1010 1010

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	add	ecx, DWORD PTR _tdct$[ebx]
	vmovdqu	ymm0, YMMWORD PTR _shufd_2$[ebp]
	vpblendd ymm0, ymm0, YMMWORD PTR [ecx], 170	; 000000aaH
	vmovdqu	YMMWORD PTR _cmbd_23$[ebp], ymm0

; 617  : 
; 618  :   __m256i evens_01 = _mm256_shuffle_epi8(cmbd_01, evens_mask);

	vmovdqu	ymm0, YMMWORD PTR _cmbd_01$[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _evens_mask$[ebp]
	vmovdqu	YMMWORD PTR _evens_01$[ebp], ymm0

; 619  :   __m256i evens_23 = _mm256_shuffle_epi8(cmbd_23, evens_mask);

	vmovdqu	ymm0, YMMWORD PTR _cmbd_23$[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _evens_mask$[ebp]
	vmovdqu	YMMWORD PTR _evens_23$[ebp], ymm0

; 620  : 
; 621  :   __m256i evens_0123 = _mm256_unpacklo_epi64(evens_01, evens_23);

	vmovdqu	ymm0, YMMWORD PTR _evens_01$[ebp]
	vpunpcklqdq ymm0, ymm0, YMMWORD PTR _evens_23$[ebp]
	vmovdqu	YMMWORD PTR _evens_0123$[ebp], ymm0

; 622  : 
; 623  :   return _mm256_permute4x64_epi64(evens_0123, _MM_SHUFFLE(3, 1, 2, 0));

	vpermq	ymm0, YMMWORD PTR _evens_0123$[ebp], 216 ; 000000d8H

; 624  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_extract_26ae ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _extract_combine_odds
_TEXT	SEGMENT
_tmp2$ = -384						; size = 32
_tmp1$ = -320						; size = 32
_tmp0$ = -256						; size = 32
_oddmask$ = -192					; size = 32
_v1$ = -128						; size = 32
_v0$ = -64						; size = 32
_extract_combine_odds PROC				; COMDAT
; _v0$ = ymm0
; _v1$ = ymm1

; 584  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 600				; 00000258H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-600]
	mov	ecx, 150				; 00000096H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	vmovups	YMMWORD PTR _v1$[ebp], ymm1
	vmovups	YMMWORD PTR _v0$[ebp], ymm0
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 585  :   // 0 1 2 3 4 5 6 7 | 8 9 a b c d e f => 1 3 5 7 1 3 5 7 | 9 b d f 9 b d f
; 586  :   const __m256i oddmask = _mm256_setr_epi8( 2,  3,  6,  7, 10, 11, 14, 15,

	vmovdqu	ymm0, YMMWORD PTR __ymm@0f0e0b0a070603020f0e0b0a070603020f0e0b0a070603020f0e0b0a07060302
	vmovdqu	YMMWORD PTR _oddmask$[ebp], ymm0

; 587  :                                             2,  3,  6,  7, 10, 11, 14, 15,
; 588  :                                             2,  3,  6,  7, 10, 11, 14, 15,
; 589  :                                             2,  3,  6,  7, 10, 11, 14, 15);
; 590  : 
; 591  :   __m256i tmp0 = _mm256_shuffle_epi8(v0,   oddmask);

	vmovdqu	ymm0, YMMWORD PTR _v0$[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _oddmask$[ebp]
	vmovdqu	YMMWORD PTR _tmp0$[ebp], ymm0

; 592  :   __m256i tmp1 = _mm256_shuffle_epi8(v1,   oddmask);

	vmovdqu	ymm0, YMMWORD PTR _v1$[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _oddmask$[ebp]
	vmovdqu	YMMWORD PTR _tmp1$[ebp], ymm0

; 593  : 
; 594  :   __m256i tmp2 = _mm256_blend_epi32 (tmp0, tmp1, 0xcc); // 1100 1100

	vmovdqu	ymm0, YMMWORD PTR _tmp0$[ebp]
	vpblendd ymm0, ymm0, YMMWORD PTR _tmp1$[ebp], 204 ; 000000ccH
	vmovdqu	YMMWORD PTR _tmp2$[ebp], ymm0

; 595  : 
; 596  :   return _mm256_permute4x64_epi64   (tmp2, _MM_SHUFFLE(3, 1, 2, 0));

	vpermq	ymm0, YMMWORD PTR _tmp2$[ebp], 216	; 000000d8H

; 597  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_extract_combine_odds ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _extract_odds
_TEXT	SEGMENT
_tmp$ = -192						; size = 32
_oddmask$ = -128					; size = 32
_v$ = -64						; size = 32
_extract_odds PROC					; COMDAT
; _v$ = ymm0

; 572  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 408				; 00000198H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-408]
	mov	ecx, 102				; 00000066H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	vmovups	YMMWORD PTR _v$[ebp], ymm0
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 573  :   // 0 1 2 3 4 5 6 7 | 8 9 a b c d e f => 1 3 5 7 1 3 5 7 | 9 b d f 9 b d f
; 574  :   const __m256i oddmask = _mm256_setr_epi8( 2,  3,  6,  7, 10, 11, 14, 15,

	vmovdqu	ymm0, YMMWORD PTR __ymm@0f0e0b0a070603020f0e0b0a070603020f0e0b0a070603020f0e0b0a07060302
	vmovdqu	YMMWORD PTR _oddmask$[ebp], ymm0

; 575  :                                             2,  3,  6,  7, 10, 11, 14, 15,
; 576  :                                             2,  3,  6,  7, 10, 11, 14, 15,
; 577  :                                             2,  3,  6,  7, 10, 11, 14, 15);
; 578  : 
; 579  :   __m256i tmp = _mm256_shuffle_epi8 (v,   oddmask);

	vmovdqu	ymm0, YMMWORD PTR _v$[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _oddmask$[ebp]
	vmovdqu	YMMWORD PTR _tmp$[ebp], ymm0

; 580  :   return _mm256_permute4x64_epi64   (tmp, _MM_SHUFFLE(3, 1, 2, 0));

	vpermq	ymm0, YMMWORD PTR _tmp$[ebp], 216	; 000000d8H

; 581  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_extract_odds ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _truncate_inv
_TEXT	SEGMENT
_trunced$ = -256					; size = 32
_v2$ = -192						; size = 32
_debias$ = -128						; size = 32
_add$ = -76						; size = 4
_v$ = -64						; size = 32
_shift$ = 8						; size = 4
_truncate_inv PROC					; COMDAT
; _v$ = ymm0

; 562  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 472				; 000001d8H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-472]
	mov	ecx, 118				; 00000076H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	vmovups	YMMWORD PTR _v$[ebp], ymm0
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 563  :   int32_t add = 1 << (shift - 1);

	mov	eax, DWORD PTR _shift$[ebx]
	sub	eax, 1
	mov	ecx, 1
	shlx	edx, ecx, eax
	mov	DWORD PTR _add$[ebp], edx

; 564  : 
; 565  :   __m256i debias  = _mm256_set1_epi32(add);

	vmovd	xmm0, DWORD PTR _add$[ebp]
	vpbroadcastd ymm0, xmm0
	vmovdqu	YMMWORD PTR _debias$[ebp], ymm0

; 566  :   __m256i v2      = _mm256_add_epi32 (v,  debias);

	vmovdqu	ymm0, YMMWORD PTR _v$[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _debias$[ebp]
	vmovdqu	YMMWORD PTR _v2$[ebp], ymm0

; 567  :   __m256i trunced = _mm256_srai_epi32(v2, shift);

	vmovdqu	ymm0, YMMWORD PTR _v2$[ebp]
	vmovd	xmm1, DWORD PTR _shift$[ebx]
	vpsrad	ymm0, ymm0, xmm1
	vmovdqu	YMMWORD PTR _trunced$[ebp], ymm0

; 568  :   return  trunced;

	vmovdqu	ymm0, YMMWORD PTR _trunced$[ebp]

; 569  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_truncate_inv ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _transpose_16x16
_TEXT	SEGMENT
_src$ = 8						; size = 4
_dst$ = 12						; size = 4
_transpose_16x16 PROC					; COMDAT

; 557  : {

	push	ebp
	mov	ebp, esp
	sub	esp, 192				; 000000c0H
	push	ebx
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-192]
	mov	ecx, 48					; 00000030H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 558  :   transpose_16x16_stride(src, dst, 0, 0);

	push	0
	push	0
	mov	eax, DWORD PTR _dst$[ebp]
	push	eax
	mov	ecx, DWORD PTR _src$[ebp]
	push	ecx
	call	_transpose_16x16_stride
	add	esp, 16					; 00000010H

; 559  : }

	pop	edi
	pop	esi
	pop	ebx
	add	esp, 192				; 000000c0H
	cmp	ebp, esp
	call	__RTC_CheckEsp
	mov	esp, ebp
	pop	ebp
	ret	0
_transpose_16x16 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _transpose_16x16_stride
_TEXT	SEGMENT
_final_hi$1 = -1728					; size = 32
_final_lo$2 = -1664					; size = 32
_hi$3 = -1600						; size = 32
_lo$4 = -1536						; size = 32
_dst_hiid$5 = -1468					; size = 4
_dst_loid$6 = -1456					; size = 4
_hiid$7 = -1444						; size = 4
_loid$8 = -1432						; size = 4
_i$9 = -1420						; size = 4
_m$10 = -1408						; size = 256
_tmp_64$11 = -1120					; size = 256
_tmp_32$12 = -832					; size = 256
_i$13 = -556						; size = 4
_tmp_128$ = -544					; size = 512
__$ArrayPad$ = -4					; size = 4
_src$ = 8						; size = 4
_dst$ = 12						; size = 4
_s_stride_log2$ = 16					; size = 1
_d_stride_log2$ = 20					; size = 1
_transpose_16x16_stride PROC				; COMDAT

; 485  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 2520				; 000009d8H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-2520]
	mov	ecx, 630				; 00000276H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 486  :   __m256i tmp_128[16];
; 487  :   for (uint32_t i = 0; i < 16; i += 8) {

	mov	DWORD PTR _i$13[ebp], 0
	jmp	SHORT $LN4@transpose_
$LN2@transpose_:
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 8
	mov	DWORD PTR _i$13[ebp], eax
$LN4@transpose_:
	cmp	DWORD PTR _i$13[ebp], 16		; 00000010H
	jae	$LN3@transpose_

; 488  : 
; 489  :     // After every n-bit unpack, 2n-bit units in the vectors will be in
; 490  :     // correct order. Pair words first, then dwords, then qwords. After that,
; 491  :     // whole lanes will be correct.
; 492  :     __m256i tmp_32[8];
; 493  :     __m256i tmp_64[8];
; 494  : 
; 495  :     __m256i m[8] = {

	movzx	eax, BYTE PTR _s_stride_log2$[ebx]
	shlx	ecx, DWORD PTR _i$13[ebp], eax
	shl	ecx, 5
	add	ecx, DWORD PTR _src$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _m$10[ebp], ymm0
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 1
	movzx	ecx, BYTE PTR _s_stride_log2$[ebx]
	shlx	edx, eax, ecx
	shl	edx, 5
	add	edx, DWORD PTR _src$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [edx]
	vmovdqu	YMMWORD PTR _m$10[ebp+32], ymm0
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 2
	movzx	ecx, BYTE PTR _s_stride_log2$[ebx]
	shlx	edx, eax, ecx
	shl	edx, 5
	add	edx, DWORD PTR _src$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [edx]
	vmovdqu	YMMWORD PTR _m$10[ebp+64], ymm0
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 3
	movzx	ecx, BYTE PTR _s_stride_log2$[ebx]
	shlx	edx, eax, ecx
	shl	edx, 5
	add	edx, DWORD PTR _src$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [edx]
	vmovdqu	YMMWORD PTR _m$10[ebp+96], ymm0
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 4
	movzx	ecx, BYTE PTR _s_stride_log2$[ebx]
	shlx	edx, eax, ecx
	shl	edx, 5
	add	edx, DWORD PTR _src$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [edx]
	vmovdqu	YMMWORD PTR _m$10[ebp+128], ymm0
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 5
	movzx	ecx, BYTE PTR _s_stride_log2$[ebx]
	shlx	edx, eax, ecx
	shl	edx, 5
	add	edx, DWORD PTR _src$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [edx]
	vmovdqu	YMMWORD PTR _m$10[ebp+160], ymm0
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 6
	movzx	ecx, BYTE PTR _s_stride_log2$[ebx]
	shlx	edx, eax, ecx
	shl	edx, 5
	add	edx, DWORD PTR _src$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [edx]
	vmovdqu	YMMWORD PTR _m$10[ebp+192], ymm0
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 7
	movzx	ecx, BYTE PTR _s_stride_log2$[ebx]
	shlx	edx, eax, ecx
	shl	edx, 5
	add	edx, DWORD PTR _src$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [edx]
	vmovdqu	YMMWORD PTR _m$10[ebp+224], ymm0

; 496  :       _mm256_load_si256((const __m256i *)src + ((i + 0) << s_stride_log2)),
; 497  :       _mm256_load_si256((const __m256i *)src + ((i + 1) << s_stride_log2)),
; 498  :       _mm256_load_si256((const __m256i *)src + ((i + 2) << s_stride_log2)),
; 499  :       _mm256_load_si256((const __m256i *)src + ((i + 3) << s_stride_log2)),
; 500  :       _mm256_load_si256((const __m256i *)src + ((i + 4) << s_stride_log2)),
; 501  :       _mm256_load_si256((const __m256i *)src + ((i + 5) << s_stride_log2)),
; 502  :       _mm256_load_si256((const __m256i *)src + ((i + 6) << s_stride_log2)),
; 503  :       _mm256_load_si256((const __m256i *)src + ((i + 7) << s_stride_log2)),
; 504  :     };
; 505  : 
; 506  :     tmp_32[0]      = _mm256_unpacklo_epi16(     m[0],      m[1]);

	mov	eax, 32					; 00000020H
	shl	eax, 0
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 0
	vmovdqu	ymm0, YMMWORD PTR _m$10[ebp+edx]
	vpunpcklwd ymm0, ymm0, YMMWORD PTR _m$10[ebp+eax]
	mov	eax, 32					; 00000020H
	imul	ecx, eax, 0
	vmovdqu	YMMWORD PTR _tmp_32$12[ebp+ecx], ymm0

; 507  :     tmp_32[1]      = _mm256_unpacklo_epi16(     m[2],      m[3]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	mov	edx, 32					; 00000020H
	shl	edx, 1
	vmovdqu	ymm0, YMMWORD PTR _m$10[ebp+edx]
	vpunpcklwd ymm0, ymm0, YMMWORD PTR _m$10[ebp+ecx]
	mov	eax, 32					; 00000020H
	shl	eax, 0
	vmovdqu	YMMWORD PTR _tmp_32$12[ebp+eax], ymm0

; 508  :     tmp_32[2]      = _mm256_unpackhi_epi16(     m[0],      m[1]);

	mov	eax, 32					; 00000020H
	shl	eax, 0
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 0
	vmovdqu	ymm0, YMMWORD PTR _m$10[ebp+edx]
	vpunpckhwd ymm0, ymm0, YMMWORD PTR _m$10[ebp+eax]
	mov	eax, 32					; 00000020H
	shl	eax, 1
	vmovdqu	YMMWORD PTR _tmp_32$12[ebp+eax], ymm0

; 509  :     tmp_32[3]      = _mm256_unpackhi_epi16(     m[2],      m[3]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	mov	edx, 32					; 00000020H
	shl	edx, 1
	vmovdqu	ymm0, YMMWORD PTR _m$10[ebp+edx]
	vpunpckhwd ymm0, ymm0, YMMWORD PTR _m$10[ebp+ecx]
	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	vmovdqu	YMMWORD PTR _tmp_32$12[ebp+ecx], ymm0

; 510  : 
; 511  :     tmp_32[4]      = _mm256_unpacklo_epi16(     m[4],      m[5]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 5
	mov	edx, 32					; 00000020H
	shl	edx, 2
	vmovdqu	ymm0, YMMWORD PTR _m$10[ebp+edx]
	vpunpcklwd ymm0, ymm0, YMMWORD PTR _m$10[ebp+ecx]
	mov	eax, 32					; 00000020H
	shl	eax, 2
	vmovdqu	YMMWORD PTR _tmp_32$12[ebp+eax], ymm0

; 512  :     tmp_32[5]      = _mm256_unpacklo_epi16(     m[6],      m[7]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 7
	mov	edx, 32					; 00000020H
	imul	eax, edx, 6
	vmovdqu	ymm0, YMMWORD PTR _m$10[ebp+eax]
	vpunpcklwd ymm0, ymm0, YMMWORD PTR _m$10[ebp+ecx]
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 5
	vmovdqu	YMMWORD PTR _tmp_32$12[ebp+edx], ymm0

; 513  :     tmp_32[6]      = _mm256_unpackhi_epi16(     m[4],      m[5]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 5
	mov	edx, 32					; 00000020H
	shl	edx, 2
	vmovdqu	ymm0, YMMWORD PTR _m$10[ebp+edx]
	vpunpckhwd ymm0, ymm0, YMMWORD PTR _m$10[ebp+ecx]
	mov	eax, 32					; 00000020H
	imul	ecx, eax, 6
	vmovdqu	YMMWORD PTR _tmp_32$12[ebp+ecx], ymm0

; 514  :     tmp_32[7]      = _mm256_unpackhi_epi16(     m[6],      m[7]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 7
	mov	edx, 32					; 00000020H
	imul	eax, edx, 6
	vmovdqu	ymm0, YMMWORD PTR _m$10[ebp+eax]
	vpunpckhwd ymm0, ymm0, YMMWORD PTR _m$10[ebp+ecx]
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 7
	vmovdqu	YMMWORD PTR _tmp_32$12[ebp+edx], ymm0

; 515  : 
; 516  : 
; 517  :     tmp_64[0]      = _mm256_unpacklo_epi32(tmp_32[0], tmp_32[1]);

	mov	eax, 32					; 00000020H
	shl	eax, 0
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 0
	vmovdqu	ymm0, YMMWORD PTR _tmp_32$12[ebp+edx]
	vpunpckldq ymm0, ymm0, YMMWORD PTR _tmp_32$12[ebp+eax]
	mov	eax, 32					; 00000020H
	imul	ecx, eax, 0
	vmovdqu	YMMWORD PTR _tmp_64$11[ebp+ecx], ymm0

; 518  :     tmp_64[1]      = _mm256_unpacklo_epi32(tmp_32[2], tmp_32[3]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	mov	edx, 32					; 00000020H
	shl	edx, 1
	vmovdqu	ymm0, YMMWORD PTR _tmp_32$12[ebp+edx]
	vpunpckldq ymm0, ymm0, YMMWORD PTR _tmp_32$12[ebp+ecx]
	mov	eax, 32					; 00000020H
	shl	eax, 0
	vmovdqu	YMMWORD PTR _tmp_64$11[ebp+eax], ymm0

; 519  :     tmp_64[2]      = _mm256_unpackhi_epi32(tmp_32[0], tmp_32[1]);

	mov	eax, 32					; 00000020H
	shl	eax, 0
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 0
	vmovdqu	ymm0, YMMWORD PTR _tmp_32$12[ebp+edx]
	vpunpckhdq ymm0, ymm0, YMMWORD PTR _tmp_32$12[ebp+eax]
	mov	eax, 32					; 00000020H
	shl	eax, 1
	vmovdqu	YMMWORD PTR _tmp_64$11[ebp+eax], ymm0

; 520  :     tmp_64[3]      = _mm256_unpackhi_epi32(tmp_32[2], tmp_32[3]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	mov	edx, 32					; 00000020H
	shl	edx, 1
	vmovdqu	ymm0, YMMWORD PTR _tmp_32$12[ebp+edx]
	vpunpckhdq ymm0, ymm0, YMMWORD PTR _tmp_32$12[ebp+ecx]
	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	vmovdqu	YMMWORD PTR _tmp_64$11[ebp+ecx], ymm0

; 521  : 
; 522  :     tmp_64[4]      = _mm256_unpacklo_epi32(tmp_32[4], tmp_32[5]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 5
	mov	edx, 32					; 00000020H
	shl	edx, 2
	vmovdqu	ymm0, YMMWORD PTR _tmp_32$12[ebp+edx]
	vpunpckldq ymm0, ymm0, YMMWORD PTR _tmp_32$12[ebp+ecx]
	mov	eax, 32					; 00000020H
	shl	eax, 2
	vmovdqu	YMMWORD PTR _tmp_64$11[ebp+eax], ymm0

; 523  :     tmp_64[5]      = _mm256_unpacklo_epi32(tmp_32[6], tmp_32[7]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 7
	mov	edx, 32					; 00000020H
	imul	eax, edx, 6
	vmovdqu	ymm0, YMMWORD PTR _tmp_32$12[ebp+eax]
	vpunpckldq ymm0, ymm0, YMMWORD PTR _tmp_32$12[ebp+ecx]
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 5
	vmovdqu	YMMWORD PTR _tmp_64$11[ebp+edx], ymm0

; 524  :     tmp_64[6]      = _mm256_unpackhi_epi32(tmp_32[4], tmp_32[5]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 5
	mov	edx, 32					; 00000020H
	shl	edx, 2
	vmovdqu	ymm0, YMMWORD PTR _tmp_32$12[ebp+edx]
	vpunpckhdq ymm0, ymm0, YMMWORD PTR _tmp_32$12[ebp+ecx]
	mov	eax, 32					; 00000020H
	imul	ecx, eax, 6
	vmovdqu	YMMWORD PTR _tmp_64$11[ebp+ecx], ymm0

; 525  :     tmp_64[7]      = _mm256_unpackhi_epi32(tmp_32[6], tmp_32[7]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 7
	mov	edx, 32					; 00000020H
	imul	eax, edx, 6
	vmovdqu	ymm0, YMMWORD PTR _tmp_32$12[ebp+eax]
	vpunpckhdq ymm0, ymm0, YMMWORD PTR _tmp_32$12[ebp+ecx]
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 7
	vmovdqu	YMMWORD PTR _tmp_64$11[ebp+edx], ymm0

; 526  : 
; 527  : 
; 528  :     tmp_128[i + 0] = _mm256_unpacklo_epi64(tmp_64[0], tmp_64[4]);

	mov	eax, 32					; 00000020H
	shl	eax, 2
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 0
	vmovdqu	ymm0, YMMWORD PTR _tmp_64$11[ebp+edx]
	vpunpcklqdq ymm0, ymm0, YMMWORD PTR _tmp_64$11[ebp+eax]
	mov	eax, DWORD PTR _i$13[ebp]
	shl	eax, 5
	vmovdqu	YMMWORD PTR _tmp_128$[ebp+eax], ymm0

; 529  :     tmp_128[i + 1] = _mm256_unpackhi_epi64(tmp_64[0], tmp_64[4]);

	mov	eax, 32					; 00000020H
	shl	eax, 2
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 0
	vmovdqu	ymm0, YMMWORD PTR _tmp_64$11[ebp+edx]
	vpunpckhqdq ymm0, ymm0, YMMWORD PTR _tmp_64$11[ebp+eax]
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 1
	shl	eax, 5
	vmovdqu	YMMWORD PTR _tmp_128$[ebp+eax], ymm0

; 530  :     tmp_128[i + 2] = _mm256_unpacklo_epi64(tmp_64[2], tmp_64[6]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 6
	mov	edx, 32					; 00000020H
	shl	edx, 1
	vmovdqu	ymm0, YMMWORD PTR _tmp_64$11[ebp+edx]
	vpunpcklqdq ymm0, ymm0, YMMWORD PTR _tmp_64$11[ebp+ecx]
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 2
	shl	eax, 5
	vmovdqu	YMMWORD PTR _tmp_128$[ebp+eax], ymm0

; 531  :     tmp_128[i + 3] = _mm256_unpackhi_epi64(tmp_64[2], tmp_64[6]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 6
	mov	edx, 32					; 00000020H
	shl	edx, 1
	vmovdqu	ymm0, YMMWORD PTR _tmp_64$11[ebp+edx]
	vpunpckhqdq ymm0, ymm0, YMMWORD PTR _tmp_64$11[ebp+ecx]
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 3
	shl	eax, 5
	vmovdqu	YMMWORD PTR _tmp_128$[ebp+eax], ymm0

; 532  : 
; 533  :     tmp_128[i + 4] = _mm256_unpacklo_epi64(tmp_64[1], tmp_64[5]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 5
	mov	edx, 32					; 00000020H
	shl	edx, 0
	vmovdqu	ymm0, YMMWORD PTR _tmp_64$11[ebp+edx]
	vpunpcklqdq ymm0, ymm0, YMMWORD PTR _tmp_64$11[ebp+ecx]
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 4
	shl	eax, 5
	vmovdqu	YMMWORD PTR _tmp_128$[ebp+eax], ymm0

; 534  :     tmp_128[i + 5] = _mm256_unpackhi_epi64(tmp_64[1], tmp_64[5]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 5
	mov	edx, 32					; 00000020H
	shl	edx, 0
	vmovdqu	ymm0, YMMWORD PTR _tmp_64$11[ebp+edx]
	vpunpckhqdq ymm0, ymm0, YMMWORD PTR _tmp_64$11[ebp+ecx]
	mov	eax, DWORD PTR _i$13[ebp]
	add	eax, 5
	shl	eax, 5
	vmovdqu	YMMWORD PTR _tmp_128$[ebp+eax], ymm0

; 535  :     tmp_128[i + 6] = _mm256_unpacklo_epi64(tmp_64[3], tmp_64[7]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 7
	mov	edx, 32					; 00000020H
	imul	eax, edx, 3
	vmovdqu	ymm0, YMMWORD PTR _tmp_64$11[ebp+eax]
	vpunpcklqdq ymm0, ymm0, YMMWORD PTR _tmp_64$11[ebp+ecx]
	mov	ecx, DWORD PTR _i$13[ebp]
	add	ecx, 6
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _tmp_128$[ebp+ecx], ymm0

; 536  :     tmp_128[i + 7] = _mm256_unpackhi_epi64(tmp_64[3], tmp_64[7]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 7
	mov	edx, 32					; 00000020H
	imul	eax, edx, 3
	vmovdqu	ymm0, YMMWORD PTR _tmp_64$11[ebp+eax]
	vpunpckhqdq ymm0, ymm0, YMMWORD PTR _tmp_64$11[ebp+ecx]
	mov	ecx, DWORD PTR _i$13[ebp]
	add	ecx, 7
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _tmp_128$[ebp+ecx], ymm0

; 537  :   }

	jmp	$LN2@transpose_
$LN3@transpose_:

; 538  : 
; 539  :   for (uint32_t i = 0; i < 8; i++) {

	mov	DWORD PTR _i$9[ebp], 0
	jmp	SHORT $LN7@transpose_
$LN5@transpose_:
	mov	eax, DWORD PTR _i$9[ebp]
	add	eax, 1
	mov	DWORD PTR _i$9[ebp], eax
$LN7@transpose_:
	cmp	DWORD PTR _i$9[ebp], 8
	jae	$LN1@transpose_

; 540  :     uint32_t loid     = i + 0;

	mov	eax, DWORD PTR _i$9[ebp]
	mov	DWORD PTR _loid$8[ebp], eax

; 541  :     uint32_t hiid     = i + 8;

	mov	eax, DWORD PTR _i$9[ebp]
	add	eax, 8
	mov	DWORD PTR _hiid$7[ebp], eax

; 542  : 
; 543  :     uint32_t dst_loid = loid << d_stride_log2;

	movzx	eax, BYTE PTR _d_stride_log2$[ebx]
	shlx	ecx, DWORD PTR _loid$8[ebp], eax
	mov	DWORD PTR _dst_loid$6[ebp], ecx

; 544  :     uint32_t dst_hiid = hiid << d_stride_log2;

	movzx	eax, BYTE PTR _d_stride_log2$[ebx]
	shlx	ecx, DWORD PTR _hiid$7[ebp], eax
	mov	DWORD PTR _dst_hiid$5[ebp], ecx

; 545  : 
; 546  :     __m256i lo       = tmp_128[loid];

	mov	eax, DWORD PTR _loid$8[ebp]
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _tmp_128$[ebp+eax]
	vmovdqu	YMMWORD PTR _lo$4[ebp], ymm0

; 547  :     __m256i hi       = tmp_128[hiid];

	mov	eax, DWORD PTR _hiid$7[ebp]
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _tmp_128$[ebp+eax]
	vmovdqu	YMMWORD PTR _hi$3[ebp], ymm0

; 548  :     __m256i final_lo = _mm256_permute2x128_si256(lo, hi, 0x20);

	vmovdqu	ymm0, YMMWORD PTR _lo$4[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _hi$3[ebp], 32 ; 00000020H
	vmovdqu	YMMWORD PTR _final_lo$2[ebp], ymm0

; 549  :     __m256i final_hi = _mm256_permute2x128_si256(lo, hi, 0x31);

	vmovdqu	ymm0, YMMWORD PTR _lo$4[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _hi$3[ebp], 49 ; 00000031H
	vmovdqu	YMMWORD PTR _final_hi$1[ebp], ymm0

; 550  : 
; 551  :     _mm256_store_si256((__m256i *)dst + dst_loid, final_lo);

	vmovdqu	ymm0, YMMWORD PTR _final_lo$2[ebp]
	mov	eax, DWORD PTR _dst_loid$6[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _dst$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 552  :     _mm256_store_si256((__m256i *)dst + dst_hiid, final_hi);

	vmovdqu	ymm0, YMMWORD PTR _final_hi$1[ebp]
	mov	eax, DWORD PTR _dst_hiid$5[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _dst$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 553  :   }

	jmp	$LN5@transpose_
$LN1@transpose_:

; 554  : }

	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN14@transpose_
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	1
$LN14@transpose_:
	DD	4
	DD	$LN13@transpose_
$LN13@transpose_:
	DD	-544					; fffffde0H
	DD	512					; 00000200H
	DD	$LN9@transpose_
	DD	-832					; fffffcc0H
	DD	256					; 00000100H
	DD	$LN10@transpose_
	DD	-1120					; fffffba0H
	DD	256					; 00000100H
	DD	$LN11@transpose_
	DD	-1408					; fffffa80H
	DD	256					; 00000100H
	DD	$LN12@transpose_
$LN12@transpose_:
	DB	109					; 0000006dH
	DB	0
$LN11@transpose_:
	DB	116					; 00000074H
	DB	109					; 0000006dH
	DB	112					; 00000070H
	DB	95					; 0000005fH
	DB	54					; 00000036H
	DB	52					; 00000034H
	DB	0
$LN10@transpose_:
	DB	116					; 00000074H
	DB	109					; 0000006dH
	DB	112					; 00000070H
	DB	95					; 0000005fH
	DB	51					; 00000033H
	DB	50					; 00000032H
	DB	0
$LN9@transpose_:
	DB	116					; 00000074H
	DB	109					; 0000006dH
	DB	112					; 00000070H
	DB	95					; 0000005fH
	DB	49					; 00000031H
	DB	50					; 00000032H
	DB	56					; 00000038H
	DB	0
_transpose_16x16_stride ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matmul_16x16_a_bt
_TEXT	SEGMENT
_res$1 = -2464						; size = 32
_s9$2 = -2400						; size = 32
_s8$3 = -2336						; size = 32
_s7$4 = -2272						; size = 32
_s6$5 = -2208						; size = 32
_s5$6 = -2144						; size = 32
_s4$7 = -2080						; size = 32
_s3$8 = -2016						; size = 32
_s2$9 = -1952						; size = 32
_s1$10 = -1888						; size = 32
_s0$11 = -1824						; size = 32
_p3h$12 = -1760						; size = 32
_p3l$13 = -1696						; size = 32
_p2h$14 = -1632						; size = 32
_p2l$15 = -1568						; size = 32
_p1h$16 = -1504						; size = 32
_p1l$17 = -1440						; size = 32
_p0h$18 = -1376						; size = 32
_p0l$19 = -1312						; size = 32
_p11$20 = -1248						; size = 32
_p10$21 = -1184						; size = 32
_p9$22 = -1120						; size = 32
_p8$23 = -1056						; size = 32
_p3$24 = -992						; size = 32
_p2$25 = -928						; size = 32
_p1$26 = -864						; size = 32
_p0$27 = -800						; size = 32
_bt_c11$28 = -736					; size = 32
_bt_c10$29 = -672					; size = 32
_bt_c9$30 = -608					; size = 32
_bt_c8$31 = -544					; size = 32
_bt_c3$32 = -480					; size = 32
_bt_c2$33 = -416					; size = 32
_bt_c1$34 = -352					; size = 32
_bt_c0$35 = -288					; size = 32
_fco$36 = -236						; size = 4
_results_32$37 = -224					; size = 64
_a_r$38 = -128						; size = 32
_y$39 = -76						; size = 4
_debias$ = -64						; size = 32
_add$ = -12						; size = 4
__$ArrayPad$ = -4					; size = 4
_a$ = 8							; size = 4
_b_t$ = 12						; size = 4
_output$ = 16						; size = 4
_shift$ = 20						; size = 4
_matmul_16x16_a_bt PROC					; COMDAT

; 420  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 3448				; 00000d78H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-3448]
	mov	ecx, 862				; 0000035eH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 421  :   const int32_t add    = 1 << (shift - 1);

	mov	eax, DWORD PTR _shift$[ebx]
	sub	eax, 1
	mov	ecx, 1
	shlx	edx, ecx, eax
	mov	DWORD PTR _add$[ebp], edx

; 422  :   const __m256i debias = _mm256_set1_epi32(add);

	vmovd	xmm0, DWORD PTR _add$[ebp]
	vpbroadcastd ymm0, xmm0
	vmovdqu	YMMWORD PTR _debias$[ebp], ymm0

; 423  : 
; 424  :   for (int32_t y = 0; y < 16; y++) {

	mov	DWORD PTR _y$39[ebp], 0
	jmp	SHORT $LN4@matmul_16x
$LN2@matmul_16x:
	mov	eax, DWORD PTR _y$39[ebp]
	add	eax, 1
	mov	DWORD PTR _y$39[ebp], eax
$LN4@matmul_16x:
	cmp	DWORD PTR _y$39[ebp], 16		; 00000010H
	jge	$LN1@matmul_16x

; 425  :     __m256i a_r = a[y];

	mov	eax, DWORD PTR _y$39[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _a$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _a_r$38[ebp], ymm0

; 426  :     __m256i results_32[2];
; 427  : 
; 428  :     for (int32_t fco = 0; fco < 2; fco++) {

	mov	DWORD PTR _fco$36[ebp], 0
	jmp	SHORT $LN7@matmul_16x
$LN5@matmul_16x:
	mov	eax, DWORD PTR _fco$36[ebp]
	add	eax, 1
	mov	DWORD PTR _fco$36[ebp], eax
$LN7@matmul_16x:
	cmp	DWORD PTR _fco$36[ebp], 2
	jge	$LN6@matmul_16x

; 429  :       // Read first cols 0, 1, 2, 3, 8, 9, 10, 11, and then next 4
; 430  :       __m256i bt_c0  = b_t[fco * 4 + 0];

	mov	eax, DWORD PTR _fco$36[ebp]
	shl	eax, 2
	shl	eax, 5
	add	eax, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _bt_c0$35[ebp], ymm0

; 431  :       __m256i bt_c1  = b_t[fco * 4 + 1];

	mov	eax, DWORD PTR _fco$36[ebp]
	lea	ecx, DWORD PTR [eax*4+1]
	shl	ecx, 5
	add	ecx, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _bt_c1$34[ebp], ymm0

; 432  :       __m256i bt_c2  = b_t[fco * 4 + 2];

	mov	eax, DWORD PTR _fco$36[ebp]
	lea	ecx, DWORD PTR [eax*4+2]
	shl	ecx, 5
	add	ecx, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _bt_c2$33[ebp], ymm0

; 433  :       __m256i bt_c3  = b_t[fco * 4 + 3];

	mov	eax, DWORD PTR _fco$36[ebp]
	lea	ecx, DWORD PTR [eax*4+3]
	shl	ecx, 5
	add	ecx, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _bt_c3$32[ebp], ymm0

; 434  :       __m256i bt_c8  = b_t[fco * 4 + 8];

	mov	eax, DWORD PTR _fco$36[ebp]
	lea	ecx, DWORD PTR [eax*4+8]
	shl	ecx, 5
	add	ecx, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _bt_c8$31[ebp], ymm0

; 435  :       __m256i bt_c9  = b_t[fco * 4 + 9];

	mov	eax, DWORD PTR _fco$36[ebp]
	lea	ecx, DWORD PTR [eax*4+9]
	shl	ecx, 5
	add	ecx, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _bt_c9$30[ebp], ymm0

; 436  :       __m256i bt_c10 = b_t[fco * 4 + 10];

	mov	eax, DWORD PTR _fco$36[ebp]
	lea	ecx, DWORD PTR [eax*4+10]
	shl	ecx, 5
	add	ecx, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _bt_c10$29[ebp], ymm0

; 437  :       __m256i bt_c11 = b_t[fco * 4 + 11];

	mov	eax, DWORD PTR _fco$36[ebp]
	lea	ecx, DWORD PTR [eax*4+11]
	shl	ecx, 5
	add	ecx, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _bt_c11$28[ebp], ymm0

; 438  : 
; 439  :       __m256i p0  = _mm256_madd_epi16(a_r, bt_c0);

	vmovdqu	ymm0, YMMWORD PTR _a_r$38[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _bt_c0$35[ebp]
	vmovdqu	YMMWORD PTR _p0$27[ebp], ymm0

; 440  :       __m256i p1  = _mm256_madd_epi16(a_r, bt_c1);

	vmovdqu	ymm0, YMMWORD PTR _a_r$38[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _bt_c1$34[ebp]
	vmovdqu	YMMWORD PTR _p1$26[ebp], ymm0

; 441  :       __m256i p2  = _mm256_madd_epi16(a_r, bt_c2);

	vmovdqu	ymm0, YMMWORD PTR _a_r$38[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _bt_c2$33[ebp]
	vmovdqu	YMMWORD PTR _p2$25[ebp], ymm0

; 442  :       __m256i p3  = _mm256_madd_epi16(a_r, bt_c3);

	vmovdqu	ymm0, YMMWORD PTR _a_r$38[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _bt_c3$32[ebp]
	vmovdqu	YMMWORD PTR _p3$24[ebp], ymm0

; 443  :       __m256i p8  = _mm256_madd_epi16(a_r, bt_c8);

	vmovdqu	ymm0, YMMWORD PTR _a_r$38[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _bt_c8$31[ebp]
	vmovdqu	YMMWORD PTR _p8$23[ebp], ymm0

; 444  :       __m256i p9  = _mm256_madd_epi16(a_r, bt_c9);

	vmovdqu	ymm0, YMMWORD PTR _a_r$38[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _bt_c9$30[ebp]
	vmovdqu	YMMWORD PTR _p9$22[ebp], ymm0

; 445  :       __m256i p10 = _mm256_madd_epi16(a_r, bt_c10);

	vmovdqu	ymm0, YMMWORD PTR _a_r$38[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _bt_c10$29[ebp]
	vmovdqu	YMMWORD PTR _p10$21[ebp], ymm0

; 446  :       __m256i p11 = _mm256_madd_epi16(a_r, bt_c11);

	vmovdqu	ymm0, YMMWORD PTR _a_r$38[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _bt_c11$28[ebp]
	vmovdqu	YMMWORD PTR _p11$20[ebp], ymm0

; 447  : 
; 448  :       // Combine low lanes from P0 and P8, high lanes from them, and the same
; 449  :       // with P1:P9 and so on
; 450  :       __m256i p0l = _mm256_permute2x128_si256(p0, p8,  0x20);

	vmovdqu	ymm0, YMMWORD PTR _p0$27[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _p8$23[ebp], 32 ; 00000020H
	vmovdqu	YMMWORD PTR _p0l$19[ebp], ymm0

; 451  :       __m256i p0h = _mm256_permute2x128_si256(p0, p8,  0x31);

	vmovdqu	ymm0, YMMWORD PTR _p0$27[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _p8$23[ebp], 49 ; 00000031H
	vmovdqu	YMMWORD PTR _p0h$18[ebp], ymm0

; 452  :       __m256i p1l = _mm256_permute2x128_si256(p1, p9,  0x20);

	vmovdqu	ymm0, YMMWORD PTR _p1$26[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _p9$22[ebp], 32 ; 00000020H
	vmovdqu	YMMWORD PTR _p1l$17[ebp], ymm0

; 453  :       __m256i p1h = _mm256_permute2x128_si256(p1, p9,  0x31);

	vmovdqu	ymm0, YMMWORD PTR _p1$26[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _p9$22[ebp], 49 ; 00000031H
	vmovdqu	YMMWORD PTR _p1h$16[ebp], ymm0

; 454  :       __m256i p2l = _mm256_permute2x128_si256(p2, p10, 0x20);

	vmovdqu	ymm0, YMMWORD PTR _p2$25[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _p10$21[ebp], 32 ; 00000020H
	vmovdqu	YMMWORD PTR _p2l$15[ebp], ymm0

; 455  :       __m256i p2h = _mm256_permute2x128_si256(p2, p10, 0x31);

	vmovdqu	ymm0, YMMWORD PTR _p2$25[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _p10$21[ebp], 49 ; 00000031H
	vmovdqu	YMMWORD PTR _p2h$14[ebp], ymm0

; 456  :       __m256i p3l = _mm256_permute2x128_si256(p3, p11, 0x20);

	vmovdqu	ymm0, YMMWORD PTR _p3$24[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _p11$20[ebp], 32 ; 00000020H
	vmovdqu	YMMWORD PTR _p3l$13[ebp], ymm0

; 457  :       __m256i p3h = _mm256_permute2x128_si256(p3, p11, 0x31);

	vmovdqu	ymm0, YMMWORD PTR _p3$24[ebp]
	vperm2i128 ymm0, ymm0, YMMWORD PTR _p11$20[ebp], 49 ; 00000031H
	vmovdqu	YMMWORD PTR _p3h$12[ebp], ymm0

; 458  : 
; 459  :       __m256i s0  = _mm256_add_epi32(p0l, p0h);

	vmovdqu	ymm0, YMMWORD PTR _p0l$19[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _p0h$18[ebp]
	vmovdqu	YMMWORD PTR _s0$11[ebp], ymm0

; 460  :       __m256i s1  = _mm256_add_epi32(p1l, p1h);

	vmovdqu	ymm0, YMMWORD PTR _p1l$17[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _p1h$16[ebp]
	vmovdqu	YMMWORD PTR _s1$10[ebp], ymm0

; 461  :       __m256i s2  = _mm256_add_epi32(p2l, p2h);

	vmovdqu	ymm0, YMMWORD PTR _p2l$15[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _p2h$14[ebp]
	vmovdqu	YMMWORD PTR _s2$9[ebp], ymm0

; 462  :       __m256i s3  = _mm256_add_epi32(p3l, p3h);

	vmovdqu	ymm0, YMMWORD PTR _p3l$13[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _p3h$12[ebp]
	vmovdqu	YMMWORD PTR _s3$8[ebp], ymm0

; 463  : 
; 464  :       __m256i s4  = _mm256_unpacklo_epi64(s0, s1);

	vmovdqu	ymm0, YMMWORD PTR _s0$11[ebp]
	vpunpcklqdq ymm0, ymm0, YMMWORD PTR _s1$10[ebp]
	vmovdqu	YMMWORD PTR _s4$7[ebp], ymm0

; 465  :       __m256i s5  = _mm256_unpackhi_epi64(s0, s1);

	vmovdqu	ymm0, YMMWORD PTR _s0$11[ebp]
	vpunpckhqdq ymm0, ymm0, YMMWORD PTR _s1$10[ebp]
	vmovdqu	YMMWORD PTR _s5$6[ebp], ymm0

; 466  :       __m256i s6  = _mm256_unpacklo_epi64(s2, s3);

	vmovdqu	ymm0, YMMWORD PTR _s2$9[ebp]
	vpunpcklqdq ymm0, ymm0, YMMWORD PTR _s3$8[ebp]
	vmovdqu	YMMWORD PTR _s6$5[ebp], ymm0

; 467  :       __m256i s7  = _mm256_unpackhi_epi64(s2, s3);

	vmovdqu	ymm0, YMMWORD PTR _s2$9[ebp]
	vpunpckhqdq ymm0, ymm0, YMMWORD PTR _s3$8[ebp]
	vmovdqu	YMMWORD PTR _s7$4[ebp], ymm0

; 468  : 
; 469  :       __m256i s8  = _mm256_add_epi32(s4, s5);

	vmovdqu	ymm0, YMMWORD PTR _s4$7[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _s5$6[ebp]
	vmovdqu	YMMWORD PTR _s8$3[ebp], ymm0

; 470  :       __m256i s9  = _mm256_add_epi32(s6, s7);

	vmovdqu	ymm0, YMMWORD PTR _s6$5[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _s7$4[ebp]
	vmovdqu	YMMWORD PTR _s9$2[ebp], ymm0

; 471  : 
; 472  :       __m256i res = _mm256_hadd_epi32(s8, s9);

	vmovdqu	ymm0, YMMWORD PTR _s8$3[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _s9$2[ebp]
	vmovdqu	YMMWORD PTR _res$1[ebp], ymm0

; 473  :       results_32[fco] = truncate_avx2(res, debias, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _res$1[ebp]
	call	_truncate_avx2
	add	esp, 4
	mov	ecx, DWORD PTR _fco$36[ebp]
	shl	ecx, 5
	vmovdqu	YMMWORD PTR _results_32$37[ebp+ecx], ymm0

; 474  :     }

	jmp	$LN5@matmul_16x
$LN6@matmul_16x:

; 475  :     output[y] = _mm256_packs_epi32(results_32[0], results_32[1]);

	mov	eax, 32					; 00000020H
	shl	eax, 0
	mov	ecx, 32					; 00000020H
	imul	edx, ecx, 0
	vmovdqu	ymm0, YMMWORD PTR _results_32$37[ebp+edx]
	vpackssdw ymm0, ymm0, YMMWORD PTR _results_32$37[ebp+eax]
	mov	eax, DWORD PTR _y$39[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _output$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 476  :   }

	jmp	$LN2@matmul_16x
$LN1@matmul_16x:

; 477  : }

	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN11@matmul_16x
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	3
$LN11@matmul_16x:
	DD	1
	DD	$LN10@matmul_16x
$LN10@matmul_16x:
	DD	-224					; ffffff20H
	DD	64					; 00000040H
	DD	$LN9@matmul_16x
$LN9@matmul_16x:
	DB	114					; 00000072H
	DB	101					; 00000065H
	DB	115					; 00000073H
	DB	117					; 00000075H
	DB	108					; 0000006cH
	DB	116					; 00000074H
	DB	115					; 00000073H
	DB	95					; 0000005fH
	DB	51					; 00000033H
	DB	50					; 00000032H
	DB	0
_matmul_16x16_a_bt ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_idct_8x8_avx2
_TEXT	SEGMENT
_dct$ = -216						; size = 4
_tdct$ = -204						; size = 4
_tmp$ = -192						; size = 128
_shift_2nd$ = -24					; size = 4
_shift_1st$ = -12					; size = 4
__$ArrayPad$ = -4					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_idct_8x8_avx2 PROC				; COMDAT

; 392  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -64				; ffffffc0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 440				; 000001b8H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-440]
	mov	ecx, 110				; 0000006eH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 393  :   int32_t shift_1st = 7;

	mov	DWORD PTR _shift_1st$[ebp], 7

; 394  :   int32_t shift_2nd = 12 - (bitdepth - 8);

	movsx	eax, BYTE PTR _bitdepth$[ebx]
	sub	eax, 8
	mov	ecx, 12					; 0000000cH
	sub	ecx, eax
	mov	DWORD PTR _shift_2nd$[ebp], ecx

; 395  :   ALIGNED(64) int16_t tmp[8 * 8];
; 396  : 
; 397  :   const int16_t *tdct = &kvz_g_dct_8_t[0][0];

	mov	eax, 16					; 00000010H
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_8_t[ecx+eax]
	mov	DWORD PTR _tdct$[ebp], ecx

; 398  :   const int16_t *dct  = &kvz_g_dct_8  [0][0];

	mov	eax, 16					; 00000010H
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_8[ecx+eax]
	mov	DWORD PTR _dct$[ebp], ecx

; 399  : 
; 400  :   mul_clip_matrix_8x8_avx2(tdct, input, tmp,    shift_1st);

	mov	eax, DWORD PTR _shift_1st$[ebp]
	push	eax
	lea	ecx, DWORD PTR _tmp$[ebp]
	push	ecx
	mov	edx, DWORD PTR _input$[ebx]
	push	edx
	mov	eax, DWORD PTR _tdct$[ebp]
	push	eax
	call	_mul_clip_matrix_8x8_avx2
	add	esp, 16					; 00000010H

; 401  :   mul_clip_matrix_8x8_avx2(tmp,  dct,   output, shift_2nd);

	mov	eax, DWORD PTR _shift_2nd$[ebp]
	push	eax
	mov	ecx, DWORD PTR _output$[ebx]
	push	ecx
	mov	edx, DWORD PTR _dct$[ebp]
	push	edx
	lea	eax, DWORD PTR _tmp$[ebp]
	push	eax
	call	_mul_clip_matrix_8x8_avx2
	add	esp, 16					; 00000010H

; 402  : 
; 403  :   /*
; 404  :    * Because:
; 405  :    * out = tdct * input * dct = tdct * (input * dct) = tdct * (input * transpose(tdct))
; 406  :    * This could almost be done this way:
; 407  :    *
; 408  :    * matmul_8x8_a_bt_t(input, tdct, debias1, shift_1st, tmp);
; 409  :    * matmul_8x8_a_bt  (tdct,  tmp,  debias2, shift_2nd, output);
; 410  :    *
; 411  :    * But not really, since it will fall victim to some very occasional
; 412  :    * rounding errors. Sadly.
; 413  :    */
; 414  : }

	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN5@matrix_idc
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	2
$LN5@matrix_idc:
	DD	1
	DD	$LN4@matrix_idc
$LN4@matrix_idc:
	DD	-192					; ffffff40H
	DD	128					; 00000080H
	DD	$LN3@matrix_idc
$LN3@matrix_idc:
	DB	116					; 00000074H
	DB	109					; 0000006dH
	DB	112					; 00000070H
	DB	0
_matrix_idct_8x8_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_dct_8x8_avx2
_TEXT	SEGMENT
_tmpres$ = -192						; size = 128
_dct$ = -36						; size = 4
_shift_2nd$ = -24					; size = 4
_shift_1st$ = -12					; size = 4
__$ArrayPad$ = -4					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_dct_8x8_avx2 PROC				; COMDAT

; 366  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 408				; 00000198H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-408]
	mov	ecx, 102				; 00000066H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 367  :   int32_t shift_1st = kvz_g_convert_to_bit[8] + 1 + (bitdepth - 8);

	mov	eax, 1
	shl	eax, 3
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	movsx	edx, BYTE PTR _bitdepth$[ebx]
	lea	eax, DWORD PTR [ecx+edx-7]
	mov	DWORD PTR _shift_1st$[ebp], eax

; 368  :   int32_t shift_2nd = kvz_g_convert_to_bit[8] + 8;

	mov	eax, 1
	shl	eax, 3
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	add	ecx, 8
	mov	DWORD PTR _shift_2nd$[ebp], ecx

; 369  : 
; 370  :   const int16_t *dct  = &kvz_g_dct_8[0][0];

	mov	eax, 16					; 00000010H
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_8[ecx+eax]
	mov	DWORD PTR _dct$[ebp], ecx

; 371  : 
; 372  :   /*
; 373  :    * Multiply input by the tranpose of DCT matrix into tmpres, and DCT matrix
; 374  :    * by tmpres - this is then our output matrix
; 375  :    *
; 376  :    * It's easier to implement an AVX2 matrix multiplication if you can multiply
; 377  :    * the left term with the transpose of the right term. Here things are stored
; 378  :    * row-wise, not column-wise, so we can effectively read DCT_T column-wise
; 379  :    * into YMM registers by reading DCT row-wise. Also because of this, the
; 380  :    * first multiplication is hacked to produce the transpose of the result
; 381  :    * instead, since it will be used in similar fashion as the right operand
; 382  :    * in the second multiplication.
; 383  :    */
; 384  : 
; 385  :   __m256i tmpres[4];
; 386  : 
; 387  :   matmul_8x8_a_bt_t(input,  dct, tmpres, shift_1st);

	movzx	eax, BYTE PTR _shift_1st$[ebp]
	push	eax
	lea	ecx, DWORD PTR _tmpres$[ebp]
	push	ecx
	mov	edx, DWORD PTR _dct$[ebp]
	push	edx
	mov	eax, DWORD PTR _input$[ebx]
	push	eax
	call	_matmul_8x8_a_bt_t
	add	esp, 16					; 00000010H

; 388  :   matmul_8x8_a_bt  (dct, tmpres, output, shift_2nd);

	movzx	eax, BYTE PTR _shift_2nd$[ebp]
	push	eax
	mov	ecx, DWORD PTR _output$[ebx]
	push	ecx
	lea	edx, DWORD PTR _tmpres$[ebp]
	push	edx
	mov	eax, DWORD PTR _dct$[ebp]
	push	eax
	call	_matmul_8x8_a_bt
	add	esp, 16					; 00000010H

; 389  : }

	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN5@matrix_dct
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	3
$LN5@matrix_dct:
	DD	1
	DD	$LN4@matrix_dct
$LN4@matrix_dct:
	DD	-192					; ffffff40H
	DD	128					; 00000080H
	DD	$LN3@matrix_dct
$LN3@matrix_dct:
	DB	116					; 00000074H
	DB	109					; 0000006dH
	DB	112					; 00000070H
	DB	114					; 00000072H
	DB	101					; 00000065H
	DB	115					; 00000073H
	DB	0
_matrix_dct_8x8_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matmul_8x8_a_bt
_TEXT	SEGMENT
_final_dr$1 = -1856					; size = 32
_tmp_dr$2 = -1792					; size = 32
_hsum2c_1_tr$3 = -1728					; size = 32
_hsum2c_0_tr$4 = -1664					; size = 32
_hsum2c_1$5 = -1600					; size = 32
_hsum2c_0$6 = -1536					; size = 32
_hsum3$7 = -1472					; size = 32
_hsum2$8 = -1408					; size = 32
_hsum1$9 = -1344					; size = 32
_hsum0$10 = -1280					; size = 32
_prod3_swp$11 = -1216					; size = 32
_prod3$12 = -1152					; size = 32
_prod2_swp$13 = -1088					; size = 32
_prod2$14 = -1024					; size = 32
_prod1_swp$15 = -960					; size = 32
_prod1$16 = -896					; size = 32
_prod0_swp$17 = -832					; size = 32
_prod0$18 = -768					; size = 32
_a_dr$19 = -704						; size = 32
_dry$20 = -652						; size = 4
_b_dc_3_swp$ = -640					; size = 32
_b_dc_2_swp$ = -576					; size = 32
_b_dc_1_swp$ = -512					; size = 32
_b_dc_0_swp$ = -448					; size = 32
_b_dc_3$ = -384						; size = 32
_b_dc_2$ = -320						; size = 32
_b_dc_1$ = -256						; size = 32
_b_dc_0$ = -192						; size = 32
_a_256$ = -140						; size = 4
_shuf_lorow_mask$ = -128				; size = 32
_debias$ = -64						; size = 32
_add$ = -8						; size = 4
_a$ = 8							; size = 4
_b_t$ = 12						; size = 4
_output$ = 16						; size = 4
_shift$ = 20						; size = 1
_matmul_8x8_a_bt PROC					; COMDAT

; 312  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 2648				; 00000a58H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-2648]
	mov	ecx, 662				; 00000296H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 313  :   const int32_t add    = 1 << (shift - 1);

	movsx	eax, BYTE PTR _shift$[ebx]
	sub	eax, 1
	mov	ecx, 1
	shlx	edx, ecx, eax
	mov	DWORD PTR _add$[ebp], edx

; 314  :   const __m256i debias = _mm256_set1_epi32(add);

	vmovd	xmm0, DWORD PTR _add$[ebp]
	vpbroadcastd ymm0, xmm0
	vmovdqu	YMMWORD PTR _debias$[ebp], ymm0

; 315  : 
; 316  :   const __m256i shuf_lorow_mask =

	vmovdqu	ymm0, YMMWORD PTR __ymm@1d1c1f1e19181b1a15141716111013120f0e0d0c0b0a09080706050403020100
	vmovdqu	YMMWORD PTR _shuf_lorow_mask$[ebp], ymm0

; 317  :       _mm256_setr_epi8(0,  1,  2,  3,  4,  5,  6,  7,
; 318  :                        8,  9,  10, 11, 12, 13, 14, 15,
; 319  :                        18, 19, 16, 17, 22, 23, 20, 21,
; 320  :                        26, 27, 24, 25, 30, 31, 28, 29);
; 321  : 
; 322  :   const __m256i *a_256 = (const __m256i *)a;

	mov	eax, DWORD PTR _a$[ebx]
	mov	DWORD PTR _a_256$[ebp], eax

; 323  : 
; 324  :   __m256i b_dc_0      = b_t[0];

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 0
	add	ecx, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _b_dc_0$[ebp], ymm0

; 325  :   __m256i b_dc_1      = b_t[1];

	mov	eax, 32					; 00000020H
	shl	eax, 0
	add	eax, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _b_dc_1$[ebp], ymm0

; 326  :   __m256i b_dc_2      = b_t[2];

	mov	eax, 32					; 00000020H
	shl	eax, 1
	add	eax, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _b_dc_2$[ebp], ymm0

; 327  :   __m256i b_dc_3      = b_t[3];

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	add	ecx, DWORD PTR _b_t$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [ecx]
	vmovdqu	YMMWORD PTR _b_dc_3$[ebp], ymm0

; 328  : 
; 329  :   __m256i b_dc_0_swp  = swap_lanes(b_dc_0);

	vmovdqu	ymm0, YMMWORD PTR _b_dc_0$[ebp]
	call	_swap_lanes
	vmovdqu	YMMWORD PTR _b_dc_0_swp$[ebp], ymm0

; 330  :   __m256i b_dc_1_swp  = swap_lanes(b_dc_1);

	vmovdqu	ymm0, YMMWORD PTR _b_dc_1$[ebp]
	call	_swap_lanes
	vmovdqu	YMMWORD PTR _b_dc_1_swp$[ebp], ymm0

; 331  :   __m256i b_dc_2_swp  = swap_lanes(b_dc_2);

	vmovdqu	ymm0, YMMWORD PTR _b_dc_2$[ebp]
	call	_swap_lanes
	vmovdqu	YMMWORD PTR _b_dc_2_swp$[ebp], ymm0

; 332  :   __m256i b_dc_3_swp  = swap_lanes(b_dc_3);

	vmovdqu	ymm0, YMMWORD PTR _b_dc_3$[ebp]
	call	_swap_lanes
	vmovdqu	YMMWORD PTR _b_dc_3_swp$[ebp], ymm0

; 333  : 
; 334  :   for (int dry = 0; dry < 4; dry++) {

	mov	DWORD PTR _dry$20[ebp], 0
	jmp	SHORT $LN4@matmul_8x8
$LN2@matmul_8x8:
	mov	eax, DWORD PTR _dry$20[ebp]
	add	eax, 1
	mov	DWORD PTR _dry$20[ebp], eax
$LN4@matmul_8x8:
	cmp	DWORD PTR _dry$20[ebp], 4
	jge	$LN1@matmul_8x8

; 335  :     __m256i a_dr        = _mm256_load_si256(a_256 + dry);

	mov	eax, DWORD PTR _dry$20[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _a_256$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _a_dr$19[ebp], ymm0

; 336  : 
; 337  :     __m256i prod0       = _mm256_madd_epi16(a_dr,     b_dc_0);

	vmovdqu	ymm0, YMMWORD PTR _a_dr$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _b_dc_0$[ebp]
	vmovdqu	YMMWORD PTR _prod0$18[ebp], ymm0

; 338  :     __m256i prod0_swp   = _mm256_madd_epi16(a_dr,     b_dc_0_swp);

	vmovdqu	ymm0, YMMWORD PTR _a_dr$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _b_dc_0_swp$[ebp]
	vmovdqu	YMMWORD PTR _prod0_swp$17[ebp], ymm0

; 339  :     __m256i prod1       = _mm256_madd_epi16(a_dr,     b_dc_1);

	vmovdqu	ymm0, YMMWORD PTR _a_dr$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _b_dc_1$[ebp]
	vmovdqu	YMMWORD PTR _prod1$16[ebp], ymm0

; 340  :     __m256i prod1_swp   = _mm256_madd_epi16(a_dr,     b_dc_1_swp);

	vmovdqu	ymm0, YMMWORD PTR _a_dr$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _b_dc_1_swp$[ebp]
	vmovdqu	YMMWORD PTR _prod1_swp$15[ebp], ymm0

; 341  :     __m256i prod2       = _mm256_madd_epi16(a_dr,     b_dc_2);

	vmovdqu	ymm0, YMMWORD PTR _a_dr$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _b_dc_2$[ebp]
	vmovdqu	YMMWORD PTR _prod2$14[ebp], ymm0

; 342  :     __m256i prod2_swp   = _mm256_madd_epi16(a_dr,     b_dc_2_swp);

	vmovdqu	ymm0, YMMWORD PTR _a_dr$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _b_dc_2_swp$[ebp]
	vmovdqu	YMMWORD PTR _prod2_swp$13[ebp], ymm0

; 343  :     __m256i prod3       = _mm256_madd_epi16(a_dr,     b_dc_3);

	vmovdqu	ymm0, YMMWORD PTR _a_dr$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _b_dc_3$[ebp]
	vmovdqu	YMMWORD PTR _prod3$12[ebp], ymm0

; 344  :     __m256i prod3_swp   = _mm256_madd_epi16(a_dr,     b_dc_3_swp);

	vmovdqu	ymm0, YMMWORD PTR _a_dr$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _b_dc_3_swp$[ebp]
	vmovdqu	YMMWORD PTR _prod3_swp$11[ebp], ymm0

; 345  : 
; 346  :     __m256i hsum0       = _mm256_hadd_epi32(prod0,    prod0_swp);

	vmovdqu	ymm0, YMMWORD PTR _prod0$18[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _prod0_swp$17[ebp]
	vmovdqu	YMMWORD PTR _hsum0$10[ebp], ymm0

; 347  :     __m256i hsum1       = _mm256_hadd_epi32(prod1,    prod1_swp);

	vmovdqu	ymm0, YMMWORD PTR _prod1$16[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _prod1_swp$15[ebp]
	vmovdqu	YMMWORD PTR _hsum1$9[ebp], ymm0

; 348  :     __m256i hsum2       = _mm256_hadd_epi32(prod2,    prod2_swp);

	vmovdqu	ymm0, YMMWORD PTR _prod2$14[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _prod2_swp$13[ebp]
	vmovdqu	YMMWORD PTR _hsum2$8[ebp], ymm0

; 349  :     __m256i hsum3       = _mm256_hadd_epi32(prod3,    prod3_swp);

	vmovdqu	ymm0, YMMWORD PTR _prod3$12[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _prod3_swp$11[ebp]
	vmovdqu	YMMWORD PTR _hsum3$7[ebp], ymm0

; 350  : 
; 351  :     __m256i hsum2c_0    = _mm256_hadd_epi32(hsum0,    hsum1);

	vmovdqu	ymm0, YMMWORD PTR _hsum0$10[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _hsum1$9[ebp]
	vmovdqu	YMMWORD PTR _hsum2c_0$6[ebp], ymm0

; 352  :     __m256i hsum2c_1    = _mm256_hadd_epi32(hsum2,    hsum3);

	vmovdqu	ymm0, YMMWORD PTR _hsum2$8[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _hsum3$7[ebp]
	vmovdqu	YMMWORD PTR _hsum2c_1$5[ebp], ymm0

; 353  : 
; 354  :     __m256i hsum2c_0_tr = truncate_avx2(hsum2c_0, debias, shift);

	movsx	eax, BYTE PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _hsum2c_0$6[ebp]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _hsum2c_0_tr$4[ebp], ymm0

; 355  :     __m256i hsum2c_1_tr = truncate_avx2(hsum2c_1, debias, shift);

	movsx	eax, BYTE PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _hsum2c_1$5[ebp]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _hsum2c_1_tr$3[ebp], ymm0

; 356  : 
; 357  :     __m256i tmp_dr      = _mm256_packs_epi32(hsum2c_0_tr, hsum2c_1_tr);

	vmovdqu	ymm0, YMMWORD PTR _hsum2c_0_tr$4[ebp]
	vpackssdw ymm0, ymm0, YMMWORD PTR _hsum2c_1_tr$3[ebp]
	vmovdqu	YMMWORD PTR _tmp_dr$2[ebp], ymm0

; 358  : 
; 359  :     __m256i final_dr    = _mm256_shuffle_epi8(tmp_dr, shuf_lorow_mask);

	vmovdqu	ymm0, YMMWORD PTR _tmp_dr$2[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _shuf_lorow_mask$[ebp]
	vmovdqu	YMMWORD PTR _final_dr$1[ebp], ymm0

; 360  : 
; 361  :     _mm256_store_si256((__m256i *)output + dry, final_dr);

	vmovdqu	ymm0, YMMWORD PTR _final_dr$1[ebp]
	mov	eax, DWORD PTR _dry$20[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _output$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 362  :   }

	jmp	$LN2@matmul_8x8
$LN1@matmul_8x8:

; 363  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_matmul_8x8_a_bt ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matmul_8x8_a_bt_t
_TEXT	SEGMENT
_tmp_dc$1 = -1792					; size = 32
_hsum2c_1_tr$2 = -1728					; size = 32
_hsum2c_0_tr$3 = -1664					; size = 32
_hsum2c_1$4 = -1600					; size = 32
_hsum2c_0$5 = -1536					; size = 32
_hsum3$6 = -1472					; size = 32
_hsum2$7 = -1408					; size = 32
_hsum1$8 = -1344					; size = 32
_hsum0$9 = -1280					; size = 32
_prod3_swp$10 = -1216					; size = 32
_prod3$11 = -1152					; size = 32
_prod2_swp$12 = -1088					; size = 32
_prod2$13 = -1024					; size = 32
_prod1_swp$14 = -960					; size = 32
_prod1$15 = -896					; size = 32
_prod0_swp$16 = -832					; size = 32
_prod0$17 = -768					; size = 32
_b_dc$18 = -704						; size = 32
_dry$19 = -652						; size = 4
_a_dr_3_swp$ = -640					; size = 32
_a_dr_2_swp$ = -576					; size = 32
_a_dr_1_swp$ = -512					; size = 32
_a_dr_0_swp$ = -448					; size = 32
_a_dr_3$ = -384						; size = 32
_a_dr_2$ = -320						; size = 32
_a_dr_1$ = -256						; size = 32
_a_dr_0$ = -192						; size = 32
_b_t_256$ = -140					; size = 4
_shuf_lorow_mask$ = -128				; size = 32
_debias$ = -64						; size = 32
_add$ = -8						; size = 4
_a$ = 8							; size = 4
_b_t$ = 12						; size = 4
_output$ = 16						; size = 4
_shift$ = 20						; size = 1
_matmul_8x8_a_bt_t PROC					; COMDAT

; 253  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 2584				; 00000a18H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-2584]
	mov	ecx, 646				; 00000286H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 254  :   const int32_t add    = 1 << (shift - 1);

	movsx	eax, BYTE PTR _shift$[ebx]
	sub	eax, 1
	mov	ecx, 1
	shlx	edx, ecx, eax
	mov	DWORD PTR _add$[ebp], edx

; 255  :   const __m256i debias = _mm256_set1_epi32(add);

	vmovd	xmm0, DWORD PTR _add$[ebp]
	vpbroadcastd ymm0, xmm0
	vmovdqu	YMMWORD PTR _debias$[ebp], ymm0

; 256  : 
; 257  :   // Keep upper row intact and swap neighboring 16-bit words in lower row
; 258  :   const __m256i shuf_lorow_mask =

	vmovdqu	ymm0, YMMWORD PTR __ymm@1d1c1f1e19181b1a15141716111013120f0e0d0c0b0a09080706050403020100
	vmovdqu	YMMWORD PTR _shuf_lorow_mask$[ebp], ymm0

; 259  :       _mm256_setr_epi8(0,  1,  2,  3,  4,  5,  6,  7,
; 260  :                        8,  9,  10, 11, 12, 13, 14, 15,
; 261  :                        18, 19, 16, 17, 22, 23, 20, 21,
; 262  :                        26, 27, 24, 25, 30, 31, 28, 29);
; 263  : 
; 264  :   const __m256i *b_t_256 = (const __m256i *)b_t;

	mov	eax, DWORD PTR _b_t$[ebx]
	mov	DWORD PTR _b_t_256$[ebp], eax

; 265  : 
; 266  :   // Dual Rows, because two 8x16b words fit in one YMM
; 267  :   __m256i a_dr_0      = _mm256_load_si256((__m256i *)a + 0);

	mov	eax, DWORD PTR _a$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _a_dr_0$[ebp], ymm0

; 268  :   __m256i a_dr_1      = _mm256_load_si256((__m256i *)a + 1);

	mov	eax, DWORD PTR _a$[ebx]
	add	eax, 32					; 00000020H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _a_dr_1$[ebp], ymm0

; 269  :   __m256i a_dr_2      = _mm256_load_si256((__m256i *)a + 2);

	mov	eax, DWORD PTR _a$[ebx]
	add	eax, 64					; 00000040H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _a_dr_2$[ebp], ymm0

; 270  :   __m256i a_dr_3      = _mm256_load_si256((__m256i *)a + 3);

	mov	eax, DWORD PTR _a$[ebx]
	add	eax, 96					; 00000060H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _a_dr_3$[ebp], ymm0

; 271  : 
; 272  :   __m256i a_dr_0_swp  = swap_lanes(a_dr_0);

	vmovdqu	ymm0, YMMWORD PTR _a_dr_0$[ebp]
	call	_swap_lanes
	vmovdqu	YMMWORD PTR _a_dr_0_swp$[ebp], ymm0

; 273  :   __m256i a_dr_1_swp  = swap_lanes(a_dr_1);

	vmovdqu	ymm0, YMMWORD PTR _a_dr_1$[ebp]
	call	_swap_lanes
	vmovdqu	YMMWORD PTR _a_dr_1_swp$[ebp], ymm0

; 274  :   __m256i a_dr_2_swp  = swap_lanes(a_dr_2);

	vmovdqu	ymm0, YMMWORD PTR _a_dr_2$[ebp]
	call	_swap_lanes
	vmovdqu	YMMWORD PTR _a_dr_2_swp$[ebp], ymm0

; 275  :   __m256i a_dr_3_swp  = swap_lanes(a_dr_3);

	vmovdqu	ymm0, YMMWORD PTR _a_dr_3$[ebp]
	call	_swap_lanes
	vmovdqu	YMMWORD PTR _a_dr_3_swp$[ebp], ymm0

; 276  : 
; 277  :   for (int dry = 0; dry < 4; dry++) {

	mov	DWORD PTR _dry$19[ebp], 0
	jmp	SHORT $LN4@matmul_8x8
$LN2@matmul_8x8:
	mov	eax, DWORD PTR _dry$19[ebp]
	add	eax, 1
	mov	DWORD PTR _dry$19[ebp], eax
$LN4@matmul_8x8:
	cmp	DWORD PTR _dry$19[ebp], 4
	jge	$LN1@matmul_8x8

; 278  : 
; 279  :     // Read dual columns of B matrix by reading rows of its transpose
; 280  :     __m256i b_dc        = _mm256_load_si256(b_t_256 + dry);

	mov	eax, DWORD PTR _dry$19[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _b_t_256$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _b_dc$18[ebp], ymm0

; 281  : 
; 282  :     __m256i prod0       = _mm256_madd_epi16(b_dc,     a_dr_0);

	vmovdqu	ymm0, YMMWORD PTR _b_dc$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _a_dr_0$[ebp]
	vmovdqu	YMMWORD PTR _prod0$17[ebp], ymm0

; 283  :     __m256i prod0_swp   = _mm256_madd_epi16(b_dc,     a_dr_0_swp);

	vmovdqu	ymm0, YMMWORD PTR _b_dc$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _a_dr_0_swp$[ebp]
	vmovdqu	YMMWORD PTR _prod0_swp$16[ebp], ymm0

; 284  :     __m256i prod1       = _mm256_madd_epi16(b_dc,     a_dr_1);

	vmovdqu	ymm0, YMMWORD PTR _b_dc$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _a_dr_1$[ebp]
	vmovdqu	YMMWORD PTR _prod1$15[ebp], ymm0

; 285  :     __m256i prod1_swp   = _mm256_madd_epi16(b_dc,     a_dr_1_swp);

	vmovdqu	ymm0, YMMWORD PTR _b_dc$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _a_dr_1_swp$[ebp]
	vmovdqu	YMMWORD PTR _prod1_swp$14[ebp], ymm0

; 286  :     __m256i prod2       = _mm256_madd_epi16(b_dc,     a_dr_2);

	vmovdqu	ymm0, YMMWORD PTR _b_dc$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _a_dr_2$[ebp]
	vmovdqu	YMMWORD PTR _prod2$13[ebp], ymm0

; 287  :     __m256i prod2_swp   = _mm256_madd_epi16(b_dc,     a_dr_2_swp);

	vmovdqu	ymm0, YMMWORD PTR _b_dc$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _a_dr_2_swp$[ebp]
	vmovdqu	YMMWORD PTR _prod2_swp$12[ebp], ymm0

; 288  :     __m256i prod3       = _mm256_madd_epi16(b_dc,     a_dr_3);

	vmovdqu	ymm0, YMMWORD PTR _b_dc$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _a_dr_3$[ebp]
	vmovdqu	YMMWORD PTR _prod3$11[ebp], ymm0

; 289  :     __m256i prod3_swp   = _mm256_madd_epi16(b_dc,     a_dr_3_swp);

	vmovdqu	ymm0, YMMWORD PTR _b_dc$18[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _a_dr_3_swp$[ebp]
	vmovdqu	YMMWORD PTR _prod3_swp$10[ebp], ymm0

; 290  : 
; 291  :     __m256i hsum0       = _mm256_hadd_epi32(prod0,    prod0_swp);

	vmovdqu	ymm0, YMMWORD PTR _prod0$17[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _prod0_swp$16[ebp]
	vmovdqu	YMMWORD PTR _hsum0$9[ebp], ymm0

; 292  :     __m256i hsum1       = _mm256_hadd_epi32(prod1,    prod1_swp);

	vmovdqu	ymm0, YMMWORD PTR _prod1$15[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _prod1_swp$14[ebp]
	vmovdqu	YMMWORD PTR _hsum1$8[ebp], ymm0

; 293  :     __m256i hsum2       = _mm256_hadd_epi32(prod2,    prod2_swp);

	vmovdqu	ymm0, YMMWORD PTR _prod2$13[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _prod2_swp$12[ebp]
	vmovdqu	YMMWORD PTR _hsum2$7[ebp], ymm0

; 294  :     __m256i hsum3       = _mm256_hadd_epi32(prod3,    prod3_swp);

	vmovdqu	ymm0, YMMWORD PTR _prod3$11[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _prod3_swp$10[ebp]
	vmovdqu	YMMWORD PTR _hsum3$6[ebp], ymm0

; 295  : 
; 296  :     __m256i hsum2c_0    = _mm256_hadd_epi32(hsum0,    hsum1);

	vmovdqu	ymm0, YMMWORD PTR _hsum0$9[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _hsum1$8[ebp]
	vmovdqu	YMMWORD PTR _hsum2c_0$5[ebp], ymm0

; 297  :     __m256i hsum2c_1    = _mm256_hadd_epi32(hsum2,    hsum3);

	vmovdqu	ymm0, YMMWORD PTR _hsum2$7[ebp]
	vphaddd	ymm0, ymm0, YMMWORD PTR _hsum3$6[ebp]
	vmovdqu	YMMWORD PTR _hsum2c_1$4[ebp], ymm0

; 298  : 
; 299  :     __m256i hsum2c_0_tr = truncate_avx2(hsum2c_0, debias, shift);

	movsx	eax, BYTE PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _hsum2c_0$5[ebp]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _hsum2c_0_tr$3[ebp], ymm0

; 300  :     __m256i hsum2c_1_tr = truncate_avx2(hsum2c_1, debias, shift);

	movsx	eax, BYTE PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _hsum2c_1$4[ebp]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _hsum2c_1_tr$2[ebp], ymm0

; 301  : 
; 302  :     __m256i tmp_dc      = _mm256_packs_epi32(hsum2c_0_tr, hsum2c_1_tr);

	vmovdqu	ymm0, YMMWORD PTR _hsum2c_0_tr$3[ebp]
	vpackssdw ymm0, ymm0, YMMWORD PTR _hsum2c_1_tr$2[ebp]
	vmovdqu	YMMWORD PTR _tmp_dc$1[ebp], ymm0

; 303  : 
; 304  :     output[dry]         = _mm256_shuffle_epi8(tmp_dc, shuf_lorow_mask);

	vmovdqu	ymm0, YMMWORD PTR _tmp_dc$1[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _shuf_lorow_mask$[ebp]
	mov	eax, DWORD PTR _dry$19[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _output$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 305  :   }

	jmp	$LN2@matmul_8x8
$LN1@matmul_8x8:

; 306  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_matmul_8x8_a_bt_t ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _mul_clip_matrix_8x8_avx2
_TEXT	SEGMENT
$T1 = -3456						; size = 16
_final_dr$2 = -2464					; size = 32
_hi_tr$3 = -2400					; size = 32
_lo_tr$4 = -2336					; size = 32
_hi$5 = -2272						; size = 32
_lo$6 = -2208						; size = 32
_hi_2$7 = -2144						; size = 32
_lo_2$8 = -2080						; size = 32
_hi_1$9 = -2016						; size = 32
_lo_1$10 = -1952					; size = 32
_prod8$11 = -1888					; size = 32
_prod7$12 = -1824					; size = 32
_prod6$13 = -1760					; size = 32
_prod5$14 = -1696					; size = 32
_prod4$15 = -1632					; size = 32
_prod3$16 = -1568					; size = 32
_prod2$17 = -1504					; size = 32
_prod1$18 = -1440					; size = 32
_ldr_slice78$19 = -1376					; size = 32
_ldr_slice56$20 = -1312					; size = 32
_ldr_slice34$21 = -1248					; size = 32
_ldr_slice12$22 = -1184					; size = 32
_ldr$23 = -1120						; size = 32
_dry$24 = -1068						; size = 4
_rdr_hi_rearr$25 = -1056				; size = 32
_rdr_lo_rearr$26 = -992					; size = 32
_rdr_his$27 = -928					; size = 32
_rdr_los$28 = -864					; size = 32
_rdr$29 = -800						; size = 32
_dry$30 = -748						; size = 4
_rdrs_rearr$ = -736					; size = 256
_right_dr$ = -448					; size = 128
_left_dr$ = -288					; size = 128
_debias$ = -128						; size = 32
_add$ = -76						; size = 4
_transp_mask$ = -64					; size = 32
__$ArrayPad$ = -4					; size = 4
_left$ = 8						; size = 4
_right$ = 12						; size = 4
_dst$ = 16						; size = 4
_shift$ = 20						; size = 4
_mul_clip_matrix_8x8_avx2 PROC				; COMDAT

; 180  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 3480				; 00000d98H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-3480]
	mov	ecx, 870				; 00000366H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	eax, DWORD PTR ___security_cookie
	xor	eax, ebp
	mov	DWORD PTR __$ArrayPad$[ebp], eax
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 181  :   const __m256i transp_mask = _mm256_broadcastsi128_si256(_mm_setr_epi8(0, 1, 8, 9, 2, 3, 10, 11, 4, 5, 12, 13, 6, 7, 14, 15));

	vmovdqa	xmm0, XMMWORD PTR __xmm@0f0e07060d0c05040b0a030209080100
	vmovdqa	XMMWORD PTR $T1[ebp], xmm0
	vbroadcasti128 ymm0, XMMWORD PTR $T1[ebp]
	vmovdqu	YMMWORD PTR _transp_mask$[ebp], ymm0

; 182  : 
; 183  :   const int32_t add    = 1 << (shift - 1);

	mov	eax, DWORD PTR _shift$[ebx]
	sub	eax, 1
	mov	ecx, 1
	shlx	edx, ecx, eax
	mov	DWORD PTR _add$[ebp], edx

; 184  :   const __m256i debias = _mm256_set1_epi32(add);

	vmovd	xmm0, DWORD PTR _add$[ebp]
	vpbroadcastd ymm0, xmm0
	vmovdqu	YMMWORD PTR _debias$[ebp], ymm0

; 185  : 
; 186  :   __m256i left_dr[4] = {

	mov	eax, DWORD PTR _left$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _left_dr$[ebp], ymm0
	mov	eax, DWORD PTR _left$[ebx]
	add	eax, 32					; 00000020H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _left_dr$[ebp+32], ymm0
	mov	eax, DWORD PTR _left$[ebx]
	add	eax, 64					; 00000040H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _left_dr$[ebp+64], ymm0
	mov	eax, DWORD PTR _left$[ebx]
	add	eax, 96					; 00000060H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _left_dr$[ebp+96], ymm0

; 187  :     _mm256_load_si256((const __m256i *)left + 0),
; 188  :     _mm256_load_si256((const __m256i *)left + 1),
; 189  :     _mm256_load_si256((const __m256i *)left + 2),
; 190  :     _mm256_load_si256((const __m256i *)left + 3),
; 191  :   };
; 192  :   __m256i right_dr[4] = {

	mov	eax, DWORD PTR _right$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _right_dr$[ebp], ymm0
	mov	eax, DWORD PTR _right$[ebx]
	add	eax, 32					; 00000020H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _right_dr$[ebp+32], ymm0
	mov	eax, DWORD PTR _right$[ebx]
	add	eax, 64					; 00000040H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _right_dr$[ebp+64], ymm0
	mov	eax, DWORD PTR _right$[ebx]
	add	eax, 96					; 00000060H
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _right_dr$[ebp+96], ymm0

; 193  :     _mm256_load_si256((const __m256i *)right + 0),
; 194  :     _mm256_load_si256((const __m256i *)right + 1),
; 195  :     _mm256_load_si256((const __m256i *)right + 2),
; 196  :     _mm256_load_si256((const __m256i *)right + 3),
; 197  :   };
; 198  : 
; 199  :   __m256i rdrs_rearr[8];
; 200  : 
; 201  :   // Rearrange right matrix
; 202  :   for (int32_t dry = 0; dry < 4; dry++) {

	mov	DWORD PTR _dry$30[ebp], 0
	jmp	SHORT $LN4@mul_clip_m
$LN2@mul_clip_m:
	mov	eax, DWORD PTR _dry$30[ebp]
	add	eax, 1
	mov	DWORD PTR _dry$30[ebp], eax
$LN4@mul_clip_m:
	cmp	DWORD PTR _dry$30[ebp], 4
	jge	$LN3@mul_clip_m

; 203  :     __m256i rdr = right_dr[dry];

	mov	eax, DWORD PTR _dry$30[ebp]
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _right_dr$[ebp+eax]
	vmovdqu	YMMWORD PTR _rdr$29[ebp], ymm0

; 204  :     __m256i rdr_los = _mm256_permute4x64_epi64(rdr, _MM_SHUFFLE(2, 0, 2, 0));

	vpermq	ymm0, YMMWORD PTR _rdr$29[ebp], 136	; 00000088H
	vmovdqu	YMMWORD PTR _rdr_los$28[ebp], ymm0

; 205  :     __m256i rdr_his = _mm256_permute4x64_epi64(rdr, _MM_SHUFFLE(3, 1, 3, 1));

	vpermq	ymm0, YMMWORD PTR _rdr$29[ebp], 221	; 000000ddH
	vmovdqu	YMMWORD PTR _rdr_his$27[ebp], ymm0

; 206  : 
; 207  :     __m256i rdr_lo_rearr = _mm256_shuffle_epi8(rdr_los, transp_mask);

	vmovdqu	ymm0, YMMWORD PTR _rdr_los$28[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _transp_mask$[ebp]
	vmovdqu	YMMWORD PTR _rdr_lo_rearr$26[ebp], ymm0

; 208  :     __m256i rdr_hi_rearr = _mm256_shuffle_epi8(rdr_his, transp_mask);

	vmovdqu	ymm0, YMMWORD PTR _rdr_his$27[ebp]
	vpshufb	ymm0, ymm0, YMMWORD PTR _transp_mask$[ebp]
	vmovdqu	YMMWORD PTR _rdr_hi_rearr$25[ebp], ymm0

; 209  : 
; 210  :     rdrs_rearr[dry * 2 + 0] = rdr_lo_rearr;

	mov	eax, DWORD PTR _dry$30[ebp]
	shl	eax, 1
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _rdr_lo_rearr$26[ebp]
	vmovdqu	YMMWORD PTR _rdrs_rearr$[ebp+eax], ymm0

; 211  :     rdrs_rearr[dry * 2 + 1] = rdr_hi_rearr;

	mov	eax, DWORD PTR _dry$30[ebp]
	lea	ecx, DWORD PTR [eax+eax+1]
	shl	ecx, 5
	vmovdqu	ymm0, YMMWORD PTR _rdr_hi_rearr$25[ebp]
	vmovdqu	YMMWORD PTR _rdrs_rearr$[ebp+ecx], ymm0

; 212  :   }

	jmp	$LN2@mul_clip_m
$LN3@mul_clip_m:

; 213  : 
; 214  :   // Double-Row Y for destination matrix
; 215  :   for (int32_t dry = 0; dry < 4; dry++) {

	mov	DWORD PTR _dry$24[ebp], 0
	jmp	SHORT $LN7@mul_clip_m
$LN5@mul_clip_m:
	mov	eax, DWORD PTR _dry$24[ebp]
	add	eax, 1
	mov	DWORD PTR _dry$24[ebp], eax
$LN7@mul_clip_m:
	cmp	DWORD PTR _dry$24[ebp], 4
	jge	$LN1@mul_clip_m

; 216  :     __m256i ldr = left_dr[dry];

	mov	eax, DWORD PTR _dry$24[ebp]
	shl	eax, 5
	vmovdqu	ymm0, YMMWORD PTR _left_dr$[ebp+eax]
	vmovdqu	YMMWORD PTR _ldr$23[ebp], ymm0

; 217  : 
; 218  :     __m256i ldr_slice12 = _mm256_shuffle_epi32(ldr, _MM_SHUFFLE(0, 0, 0, 0));

	vpshufd	ymm0, YMMWORD PTR _ldr$23[ebp], 0
	vmovdqu	YMMWORD PTR _ldr_slice12$22[ebp], ymm0

; 219  :     __m256i ldr_slice34 = _mm256_shuffle_epi32(ldr, _MM_SHUFFLE(1, 1, 1, 1));

	vpshufd	ymm0, YMMWORD PTR _ldr$23[ebp], 85	; 00000055H
	vmovdqu	YMMWORD PTR _ldr_slice34$21[ebp], ymm0

; 220  :     __m256i ldr_slice56 = _mm256_shuffle_epi32(ldr, _MM_SHUFFLE(2, 2, 2, 2));

	vpshufd	ymm0, YMMWORD PTR _ldr$23[ebp], 170	; 000000aaH
	vmovdqu	YMMWORD PTR _ldr_slice56$20[ebp], ymm0

; 221  :     __m256i ldr_slice78 = _mm256_shuffle_epi32(ldr, _MM_SHUFFLE(3, 3, 3, 3));

	vpshufd	ymm0, YMMWORD PTR _ldr$23[ebp], 255	; 000000ffH
	vmovdqu	YMMWORD PTR _ldr_slice78$19[ebp], ymm0

; 222  : 
; 223  :     __m256i prod1 = _mm256_madd_epi16(ldr_slice12, rdrs_rearr[0]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 0
	vmovdqu	ymm0, YMMWORD PTR _ldr_slice12$22[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _rdrs_rearr$[ebp+ecx]
	vmovdqu	YMMWORD PTR _prod1$18[ebp], ymm0

; 224  :     __m256i prod2 = _mm256_madd_epi16(ldr_slice12, rdrs_rearr[1]);

	mov	eax, 32					; 00000020H
	shl	eax, 0
	vmovdqu	ymm0, YMMWORD PTR _ldr_slice12$22[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _rdrs_rearr$[ebp+eax]
	vmovdqu	YMMWORD PTR _prod2$17[ebp], ymm0

; 225  :     __m256i prod3 = _mm256_madd_epi16(ldr_slice34, rdrs_rearr[2]);

	mov	eax, 32					; 00000020H
	shl	eax, 1
	vmovdqu	ymm0, YMMWORD PTR _ldr_slice34$21[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _rdrs_rearr$[ebp+eax]
	vmovdqu	YMMWORD PTR _prod3$16[ebp], ymm0

; 226  :     __m256i prod4 = _mm256_madd_epi16(ldr_slice34, rdrs_rearr[3]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 3
	vmovdqu	ymm0, YMMWORD PTR _ldr_slice34$21[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _rdrs_rearr$[ebp+ecx]
	vmovdqu	YMMWORD PTR _prod4$15[ebp], ymm0

; 227  :     __m256i prod5 = _mm256_madd_epi16(ldr_slice56, rdrs_rearr[4]);

	mov	eax, 32					; 00000020H
	shl	eax, 2
	vmovdqu	ymm0, YMMWORD PTR _ldr_slice56$20[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _rdrs_rearr$[ebp+eax]
	vmovdqu	YMMWORD PTR _prod5$14[ebp], ymm0

; 228  :     __m256i prod6 = _mm256_madd_epi16(ldr_slice56, rdrs_rearr[5]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 5
	vmovdqu	ymm0, YMMWORD PTR _ldr_slice56$20[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _rdrs_rearr$[ebp+ecx]
	vmovdqu	YMMWORD PTR _prod6$13[ebp], ymm0

; 229  :     __m256i prod7 = _mm256_madd_epi16(ldr_slice78, rdrs_rearr[6]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 6
	vmovdqu	ymm0, YMMWORD PTR _ldr_slice78$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _rdrs_rearr$[ebp+ecx]
	vmovdqu	YMMWORD PTR _prod7$12[ebp], ymm0

; 230  :     __m256i prod8 = _mm256_madd_epi16(ldr_slice78, rdrs_rearr[7]);

	mov	eax, 32					; 00000020H
	imul	ecx, eax, 7
	vmovdqu	ymm0, YMMWORD PTR _ldr_slice78$19[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _rdrs_rearr$[ebp+ecx]
	vmovdqu	YMMWORD PTR _prod8$11[ebp], ymm0

; 231  : 
; 232  :     __m256i lo_1 = _mm256_add_epi32(prod1, prod3);

	vmovdqu	ymm0, YMMWORD PTR _prod1$18[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _prod3$16[ebp]
	vmovdqu	YMMWORD PTR _lo_1$10[ebp], ymm0

; 233  :     __m256i hi_1 = _mm256_add_epi32(prod2, prod4);

	vmovdqu	ymm0, YMMWORD PTR _prod2$17[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _prod4$15[ebp]
	vmovdqu	YMMWORD PTR _hi_1$9[ebp], ymm0

; 234  :     __m256i lo_2 = _mm256_add_epi32(prod5, prod7);

	vmovdqu	ymm0, YMMWORD PTR _prod5$14[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _prod7$12[ebp]
	vmovdqu	YMMWORD PTR _lo_2$8[ebp], ymm0

; 235  :     __m256i hi_2 = _mm256_add_epi32(prod6, prod8);

	vmovdqu	ymm0, YMMWORD PTR _prod6$13[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _prod8$11[ebp]
	vmovdqu	YMMWORD PTR _hi_2$7[ebp], ymm0

; 236  : 
; 237  :     __m256i lo   = _mm256_add_epi32(lo_1,  lo_2);

	vmovdqu	ymm0, YMMWORD PTR _lo_1$10[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _lo_2$8[ebp]
	vmovdqu	YMMWORD PTR _lo$6[ebp], ymm0

; 238  :     __m256i hi   = _mm256_add_epi32(hi_1,  hi_2);

	vmovdqu	ymm0, YMMWORD PTR _hi_1$9[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _hi_2$7[ebp]
	vmovdqu	YMMWORD PTR _hi$5[ebp], ymm0

; 239  : 
; 240  :     __m256i lo_tr = truncate_avx2(lo, debias, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _lo$6[ebp]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _lo_tr$4[ebp], ymm0

; 241  :     __m256i hi_tr = truncate_avx2(hi, debias, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _hi$5[ebp]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _hi_tr$3[ebp], ymm0

; 242  : 
; 243  :     __m256i final_dr = _mm256_packs_epi32(lo_tr, hi_tr);

	vmovdqu	ymm0, YMMWORD PTR _lo_tr$4[ebp]
	vpackssdw ymm0, ymm0, YMMWORD PTR _hi_tr$3[ebp]
	vmovdqu	YMMWORD PTR _final_dr$2[ebp], ymm0

; 244  : 
; 245  :     _mm256_store_si256((__m256i *)dst + dry, final_dr);

	vmovdqu	ymm0, YMMWORD PTR _final_dr$2[ebp]
	mov	eax, DWORD PTR _dry$24[ebp]
	shl	eax, 5
	add	eax, DWORD PTR _dst$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 246  :   }

	jmp	$LN5@mul_clip_m
$LN1@mul_clip_m:

; 247  : }

	push	edx
	mov	ecx, ebp
	push	eax
	lea	edx, DWORD PTR $LN13@mul_clip_m
	call	@_RTC_CheckStackVars@8
	pop	eax
	pop	edx
	pop	edi
	pop	esi
	mov	ecx, DWORD PTR __$ArrayPad$[ebp]
	xor	ecx, ebp
	call	@__security_check_cookie@4
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
	npad	1
$LN13@mul_clip_m:
	DD	3
	DD	$LN12@mul_clip_m
$LN12@mul_clip_m:
	DD	-288					; fffffee0H
	DD	128					; 00000080H
	DD	$LN9@mul_clip_m
	DD	-448					; fffffe40H
	DD	128					; 00000080H
	DD	$LN10@mul_clip_m
	DD	-736					; fffffd20H
	DD	256					; 00000100H
	DD	$LN11@mul_clip_m
$LN11@mul_clip_m:
	DB	114					; 00000072H
	DB	100					; 00000064H
	DB	114					; 00000072H
	DB	115					; 00000073H
	DB	95					; 0000005fH
	DB	114					; 00000072H
	DB	101					; 00000065H
	DB	97					; 00000061H
	DB	114					; 00000072H
	DB	114					; 00000072H
	DB	0
$LN10@mul_clip_m:
	DB	114					; 00000072H
	DB	105					; 00000069H
	DB	103					; 00000067H
	DB	104					; 00000068H
	DB	116					; 00000074H
	DB	95					; 0000005fH
	DB	100					; 00000064H
	DB	114					; 00000072H
	DB	0
$LN9@mul_clip_m:
	DB	108					; 0000006cH
	DB	101					; 00000065H
	DB	102					; 00000066H
	DB	116					; 00000074H
	DB	95					; 0000005fH
	DB	100					; 00000064H
	DB	114					; 00000072H
	DB	0
_mul_clip_matrix_8x8_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_idct_4x4_avx2
_TEXT	SEGMENT
_result$ = -352						; size = 32
_tmp$ = -288						; size = 32
_in_v$ = -224						; size = 32
_dct_v$ = -160						; size = 32
_tdct_v$ = -96						; size = 32
_dct$ = -44						; size = 4
_tdct$ = -32						; size = 4
_shift_2nd$ = -20					; size = 4
_shift_1st$ = -8					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_idct_4x4_avx2 PROC				; COMDAT

; 162  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 568				; 00000238H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-568]
	mov	ecx, 142				; 0000008eH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 163  :   int32_t shift_1st = 7;

	mov	DWORD PTR _shift_1st$[ebp], 7

; 164  :   int32_t shift_2nd = 12 - (bitdepth - 8);

	movsx	eax, BYTE PTR _bitdepth$[ebx]
	sub	eax, 8
	mov	ecx, 12					; 0000000cH
	sub	ecx, eax
	mov	DWORD PTR _shift_2nd$[ebp], ecx

; 165  : 
; 166  :   const int16_t *tdct = &kvz_g_dct_4_t[0][0];

	mov	eax, 8
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_4_t[ecx+eax]
	mov	DWORD PTR _tdct$[ebp], ecx

; 167  :   const int16_t *dct  = &kvz_g_dct_4  [0][0];

	mov	eax, 8
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_4[ecx+eax]
	mov	DWORD PTR _dct$[ebp], ecx

; 168  : 
; 169  :   __m256i tdct_v = _mm256_load_si256((const __m256i *)tdct);

	mov	eax, DWORD PTR _tdct$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _tdct_v$[ebp], ymm0

; 170  :   __m256i  dct_v = _mm256_load_si256((const __m256i *) dct);

	mov	eax, DWORD PTR _dct$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_v$[ebp], ymm0

; 171  :   __m256i   in_v = _mm256_load_si256((const __m256i *)input);

	mov	eax, DWORD PTR _input$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _in_v$[ebp], ymm0

; 172  : 
; 173  :   __m256i tmp    = mul_clip_matrix_4x4_avx2(tdct_v, in_v,  shift_1st);

	mov	eax, DWORD PTR _shift_1st$[ebp]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _in_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _tdct_v$[ebp]
	call	_mul_clip_matrix_4x4_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _tmp$[ebp], ymm0

; 174  :   __m256i result = mul_clip_matrix_4x4_avx2(tmp,    dct_v, shift_2nd);

	mov	eax, DWORD PTR _shift_2nd$[ebp]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _dct_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _tmp$[ebp]
	call	_mul_clip_matrix_4x4_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _result$[ebp], ymm0

; 175  : 
; 176  :   _mm256_store_si256((__m256i *)output, result);

	vmovdqu	ymm0, YMMWORD PTR _result$[ebp]
	mov	eax, DWORD PTR _output$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 177  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_matrix_idct_4x4_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_dct_4x4_avx2
_TEXT	SEGMENT
_result$ = -352						; size = 32
_tmp$ = -288						; size = 32
_in_v$ = -224						; size = 32
_dct_v$ = -160						; size = 32
_tdct_v$ = -96						; size = 32
_dct$ = -44						; size = 4
_tdct$ = -32						; size = 4
_shift_2nd$ = -20					; size = 4
_shift_1st$ = -8					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_dct_4x4_avx2 PROC				; COMDAT

; 145  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 568				; 00000238H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-568]
	mov	ecx, 142				; 0000008eH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 146  :   int32_t shift_1st = kvz_g_convert_to_bit[4] + 1 + (bitdepth - 8);

	mov	eax, 1
	shl	eax, 2
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	movsx	edx, BYTE PTR _bitdepth$[ebx]
	lea	eax, DWORD PTR [ecx+edx-7]
	mov	DWORD PTR _shift_1st$[ebp], eax

; 147  :   int32_t shift_2nd = kvz_g_convert_to_bit[4] + 8;

	mov	eax, 1
	shl	eax, 2
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	add	ecx, 8
	mov	DWORD PTR _shift_2nd$[ebp], ecx

; 148  :   const int16_t *tdct = &kvz_g_dct_4_t[0][0];

	mov	eax, 8
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_4_t[ecx+eax]
	mov	DWORD PTR _tdct$[ebp], ecx

; 149  :   const int16_t *dct  = &kvz_g_dct_4  [0][0];

	mov	eax, 8
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dct_4[ecx+eax]
	mov	DWORD PTR _dct$[ebp], ecx

; 150  : 
; 151  :   __m256i tdct_v = _mm256_load_si256((const __m256i *) tdct);

	mov	eax, DWORD PTR _tdct$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _tdct_v$[ebp], ymm0

; 152  :   __m256i  dct_v = _mm256_load_si256((const __m256i *)  dct);

	mov	eax, DWORD PTR _dct$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dct_v$[ebp], ymm0

; 153  :   __m256i   in_v = _mm256_load_si256((const __m256i *)input);

	mov	eax, DWORD PTR _input$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _in_v$[ebp], ymm0

; 154  : 
; 155  :   __m256i tmp    = mul_clip_matrix_4x4_avx2(in_v,  tdct_v, shift_1st);

	mov	eax, DWORD PTR _shift_1st$[ebp]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _tdct_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _in_v$[ebp]
	call	_mul_clip_matrix_4x4_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _tmp$[ebp], ymm0

; 156  :   __m256i result = mul_clip_matrix_4x4_avx2(dct_v, tmp,    shift_2nd);

	mov	eax, DWORD PTR _shift_2nd$[ebp]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _tmp$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _dct_v$[ebp]
	call	_mul_clip_matrix_4x4_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _result$[ebp], ymm0

; 157  : 
; 158  :   _mm256_store_si256((__m256i *)output, result);

	vmovdqu	ymm0, YMMWORD PTR _result$[ebp]
	mov	eax, DWORD PTR _output$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 159  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_matrix_dct_4x4_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_idst_4x4_avx2
_TEXT	SEGMENT
_result$ = -352						; size = 32
_tmp$ = -288						; size = 32
_in_v$ = -224						; size = 32
_dst_v$ = -160						; size = 32
_tdst_v$ = -96						; size = 32
_dst$ = -44						; size = 4
_tdst$ = -32						; size = 4
_shift_2nd$ = -20					; size = 4
_shift_1st$ = -8					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_idst_4x4_avx2 PROC				; COMDAT

; 127  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 568				; 00000238H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-568]
	mov	ecx, 142				; 0000008eH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 128  :   int32_t shift_1st = 7;

	mov	DWORD PTR _shift_1st$[ebp], 7

; 129  :   int32_t shift_2nd = 12 - (bitdepth - 8);

	movsx	eax, BYTE PTR _bitdepth$[ebx]
	sub	eax, 8
	mov	ecx, 12					; 0000000cH
	sub	ecx, eax
	mov	DWORD PTR _shift_2nd$[ebp], ecx

; 130  : 
; 131  :   const int16_t *tdst = &kvz_g_dst_4_t[0][0];

	mov	eax, 8
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dst_4_t[ecx+eax]
	mov	DWORD PTR _tdst$[ebp], ecx

; 132  :   const int16_t *dst  = &kvz_g_dst_4  [0][0];

	mov	eax, 8
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dst_4[ecx+eax]
	mov	DWORD PTR _dst$[ebp], ecx

; 133  : 
; 134  :   __m256i tdst_v = _mm256_load_si256((const __m256i *)tdst);

	mov	eax, DWORD PTR _tdst$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _tdst_v$[ebp], ymm0

; 135  :   __m256i  dst_v = _mm256_load_si256((const __m256i *) dst);

	mov	eax, DWORD PTR _dst$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dst_v$[ebp], ymm0

; 136  :   __m256i   in_v = _mm256_load_si256((const __m256i *)input);

	mov	eax, DWORD PTR _input$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _in_v$[ebp], ymm0

; 137  : 
; 138  :   __m256i tmp    = mul_clip_matrix_4x4_avx2(tdst_v, in_v,  shift_1st);

	mov	eax, DWORD PTR _shift_1st$[ebp]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _in_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _tdst_v$[ebp]
	call	_mul_clip_matrix_4x4_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _tmp$[ebp], ymm0

; 139  :   __m256i result = mul_clip_matrix_4x4_avx2(tmp,    dst_v, shift_2nd);

	mov	eax, DWORD PTR _shift_2nd$[ebp]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _dst_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _tmp$[ebp]
	call	_mul_clip_matrix_4x4_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _result$[ebp], ymm0

; 140  : 
; 141  :   _mm256_store_si256((__m256i *)output, result);

	vmovdqu	ymm0, YMMWORD PTR _result$[ebp]
	mov	eax, DWORD PTR _output$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 142  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_matrix_idst_4x4_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _matrix_dst_4x4_avx2
_TEXT	SEGMENT
_result$ = -352						; size = 32
_tmp$ = -288						; size = 32
_in_v$ = -224						; size = 32
_dst_v$ = -160						; size = 32
_tdst_v$ = -96						; size = 32
_dst$ = -44						; size = 4
_tdst$ = -32						; size = 4
_shift_2nd$ = -20					; size = 4
_shift_1st$ = -8					; size = 4
_bitdepth$ = 8						; size = 1
_input$ = 12						; size = 4
_output$ = 16						; size = 4
_matrix_dst_4x4_avx2 PROC				; COMDAT

; 110  : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 568				; 00000238H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-568]
	mov	ecx, 142				; 0000008eH
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 111  :   int32_t shift_1st = kvz_g_convert_to_bit[4] + 1 + (bitdepth - 8);

	mov	eax, 1
	shl	eax, 2
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	movsx	edx, BYTE PTR _bitdepth$[ebx]
	lea	eax, DWORD PTR [ecx+edx-7]
	mov	DWORD PTR _shift_1st$[ebp], eax

; 112  :   int32_t shift_2nd = kvz_g_convert_to_bit[4] + 8;

	mov	eax, 1
	shl	eax, 2
	movsx	ecx, BYTE PTR _kvz_g_convert_to_bit[eax]
	add	ecx, 8
	mov	DWORD PTR _shift_2nd$[ebp], ecx

; 113  :   const int16_t *tdst = &kvz_g_dst_4_t[0][0];

	mov	eax, 8
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dst_4_t[ecx+eax]
	mov	DWORD PTR _tdst$[ebp], ecx

; 114  :   const int16_t *dst  = &kvz_g_dst_4  [0][0];

	mov	eax, 8
	imul	ecx, eax, 0
	mov	edx, 2
	imul	eax, edx, 0
	lea	ecx, DWORD PTR _kvz_g_dst_4[ecx+eax]
	mov	DWORD PTR _dst$[ebp], ecx

; 115  : 
; 116  :   __m256i tdst_v = _mm256_load_si256((const __m256i *) tdst);

	mov	eax, DWORD PTR _tdst$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _tdst_v$[ebp], ymm0

; 117  :   __m256i  dst_v = _mm256_load_si256((const __m256i *)  dst);

	mov	eax, DWORD PTR _dst$[ebp]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _dst_v$[ebp], ymm0

; 118  :   __m256i   in_v = _mm256_load_si256((const __m256i *)input);

	mov	eax, DWORD PTR _input$[ebx]
	vmovdqu	ymm0, YMMWORD PTR [eax]
	vmovdqu	YMMWORD PTR _in_v$[ebp], ymm0

; 119  : 
; 120  :   __m256i tmp    = mul_clip_matrix_4x4_avx2(in_v,  tdst_v, shift_1st);

	mov	eax, DWORD PTR _shift_1st$[ebp]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _tdst_v$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _in_v$[ebp]
	call	_mul_clip_matrix_4x4_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _tmp$[ebp], ymm0

; 121  :   __m256i result = mul_clip_matrix_4x4_avx2(dst_v, tmp,    shift_2nd);

	mov	eax, DWORD PTR _shift_2nd$[ebp]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _tmp$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _dst_v$[ebp]
	call	_mul_clip_matrix_4x4_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _result$[ebp], ymm0

; 122  : 
; 123  :   _mm256_store_si256((__m256i *)output, result);

	vmovdqu	ymm0, YMMWORD PTR _result$[ebp]
	mov	eax, DWORD PTR _output$[ebx]
	vmovdqu	YMMWORD PTR [eax], ymm0

; 124  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_matrix_dst_4x4_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _mul_clip_matrix_4x4_avx2
_TEXT	SEGMENT
_result$ = -1280					; size = 32
_rows_dn_tr$ = -1216					; size = 32
_rows_up_tr$ = -1152					; size = 32
_rows_dn$ = -1088					; size = 32
_rows_up$ = -1024					; size = 32
_prod4$ = -960						; size = 32
_prod3$ = -896						; size = 32
_prod2$ = -832						; size = 32
_prod1$ = -768						; size = 32
_left_slice4$ = -704					; size = 32
_left_slice3$ = -640					; size = 32
_left_slice2$ = -576					; size = 32
_left_slice1$ = -512					; size = 32
_right_cols_dn$ = -448					; size = 32
_right_cols_up$ = -384					; size = 32
_right_his$ = -320					; size = 32
_right_los$ = -256					; size = 32
_debias$ = -192						; size = 32
_add$ = -140						; size = 4
_right$ = -128						; size = 32
_left$ = -64						; size = 32
_shift$ = 8						; size = 4
_mul_clip_matrix_4x4_avx2 PROC				; COMDAT
; _left$ = ymm0
; _right$ = ymm1

; 79   : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 1880				; 00000758H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-1880]
	mov	ecx, 470				; 000001d6H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	vmovups	YMMWORD PTR _right$[ebp], ymm1
	vmovups	YMMWORD PTR _left$[ebp], ymm0
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 80   :   const int32_t add    = 1 << (shift - 1);

	mov	eax, DWORD PTR _shift$[ebx]
	sub	eax, 1
	mov	ecx, 1
	shlx	edx, ecx, eax
	mov	DWORD PTR _add$[ebp], edx

; 81   :   const __m256i debias = _mm256_set1_epi32(add);

	vmovd	xmm0, DWORD PTR _add$[ebp]
	vpbroadcastd ymm0, xmm0
	vmovdqu	YMMWORD PTR _debias$[ebp], ymm0

; 82   : 
; 83   :   __m256i right_los = _mm256_permute4x64_epi64(right, _MM_SHUFFLE(2, 0, 2, 0));

	vpermq	ymm0, YMMWORD PTR _right$[ebp], 136	; 00000088H
	vmovdqu	YMMWORD PTR _right_los$[ebp], ymm0

; 84   :   __m256i right_his = _mm256_permute4x64_epi64(right, _MM_SHUFFLE(3, 1, 3, 1));

	vpermq	ymm0, YMMWORD PTR _right$[ebp], 221	; 000000ddH
	vmovdqu	YMMWORD PTR _right_his$[ebp], ymm0

; 85   : 
; 86   :   __m256i right_cols_up = _mm256_unpacklo_epi16(right_los, right_his);

	vmovdqu	ymm0, YMMWORD PTR _right_los$[ebp]
	vpunpcklwd ymm0, ymm0, YMMWORD PTR _right_his$[ebp]
	vmovdqu	YMMWORD PTR _right_cols_up$[ebp], ymm0

; 87   :   __m256i right_cols_dn = _mm256_unpackhi_epi16(right_los, right_his);

	vmovdqu	ymm0, YMMWORD PTR _right_los$[ebp]
	vpunpckhwd ymm0, ymm0, YMMWORD PTR _right_his$[ebp]
	vmovdqu	YMMWORD PTR _right_cols_dn$[ebp], ymm0

; 88   : 
; 89   :   __m256i left_slice1 = _mm256_shuffle_epi32(left, _MM_SHUFFLE(0, 0, 0, 0));

	vpshufd	ymm0, YMMWORD PTR _left$[ebp], 0
	vmovdqu	YMMWORD PTR _left_slice1$[ebp], ymm0

; 90   :   __m256i left_slice2 = _mm256_shuffle_epi32(left, _MM_SHUFFLE(1, 1, 1, 1));

	vpshufd	ymm0, YMMWORD PTR _left$[ebp], 85	; 00000055H
	vmovdqu	YMMWORD PTR _left_slice2$[ebp], ymm0

; 91   :   __m256i left_slice3 = _mm256_shuffle_epi32(left, _MM_SHUFFLE(2, 2, 2, 2));

	vpshufd	ymm0, YMMWORD PTR _left$[ebp], 170	; 000000aaH
	vmovdqu	YMMWORD PTR _left_slice3$[ebp], ymm0

; 92   :   __m256i left_slice4 = _mm256_shuffle_epi32(left, _MM_SHUFFLE(3, 3, 3, 3));

	vpshufd	ymm0, YMMWORD PTR _left$[ebp], 255	; 000000ffH
	vmovdqu	YMMWORD PTR _left_slice4$[ebp], ymm0

; 93   : 
; 94   :   __m256i prod1 = _mm256_madd_epi16(left_slice1, right_cols_up);

	vmovdqu	ymm0, YMMWORD PTR _left_slice1$[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _right_cols_up$[ebp]
	vmovdqu	YMMWORD PTR _prod1$[ebp], ymm0

; 95   :   __m256i prod2 = _mm256_madd_epi16(left_slice2, right_cols_dn);

	vmovdqu	ymm0, YMMWORD PTR _left_slice2$[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _right_cols_dn$[ebp]
	vmovdqu	YMMWORD PTR _prod2$[ebp], ymm0

; 96   :   __m256i prod3 = _mm256_madd_epi16(left_slice3, right_cols_up);

	vmovdqu	ymm0, YMMWORD PTR _left_slice3$[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _right_cols_up$[ebp]
	vmovdqu	YMMWORD PTR _prod3$[ebp], ymm0

; 97   :   __m256i prod4 = _mm256_madd_epi16(left_slice4, right_cols_dn);

	vmovdqu	ymm0, YMMWORD PTR _left_slice4$[ebp]
	vpmaddwd ymm0, ymm0, YMMWORD PTR _right_cols_dn$[ebp]
	vmovdqu	YMMWORD PTR _prod4$[ebp], ymm0

; 98   : 
; 99   :   __m256i rows_up = _mm256_add_epi32(prod1, prod2);

	vmovdqu	ymm0, YMMWORD PTR _prod1$[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _prod2$[ebp]
	vmovdqu	YMMWORD PTR _rows_up$[ebp], ymm0

; 100  :   __m256i rows_dn = _mm256_add_epi32(prod3, prod4);

	vmovdqu	ymm0, YMMWORD PTR _prod3$[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _prod4$[ebp]
	vmovdqu	YMMWORD PTR _rows_dn$[ebp], ymm0

; 101  : 
; 102  :   __m256i rows_up_tr = truncate_avx2(rows_up, debias, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _rows_up$[ebp]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _rows_up_tr$[ebp], ymm0

; 103  :   __m256i rows_dn_tr = truncate_avx2(rows_dn, debias, shift);

	mov	eax, DWORD PTR _shift$[ebx]
	push	eax
	vmovdqu	ymm1, YMMWORD PTR _debias$[ebp]
	vmovdqu	ymm0, YMMWORD PTR _rows_dn$[ebp]
	call	_truncate_avx2
	add	esp, 4
	vmovdqu	YMMWORD PTR _rows_dn_tr$[ebp], ymm0

; 104  : 
; 105  :   __m256i result = _mm256_packs_epi32(rows_up_tr, rows_dn_tr);

	vmovdqu	ymm0, YMMWORD PTR _rows_up_tr$[ebp]
	vpackssdw ymm0, ymm0, YMMWORD PTR _rows_dn_tr$[ebp]
	vmovdqu	YMMWORD PTR _result$[ebp], ymm0

; 106  :   return result;

	vmovdqu	ymm0, YMMWORD PTR _result$[ebp]

; 107  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_mul_clip_matrix_4x4_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _truncate_avx2
_TEXT	SEGMENT
_truncable$ = -192					; size = 32
_debias$ = -128						; size = 32
_v$ = -64						; size = 32
_shift$ = 8						; size = 4
_truncate_avx2 PROC					; COMDAT
; _v$ = ymm0
; _debias$ = ymm1

; 70   : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 408				; 00000198H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-408]
	mov	ecx, 102				; 00000066H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	vmovups	YMMWORD PTR _debias$[ebp], ymm1
	vmovups	YMMWORD PTR _v$[ebp], ymm0
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 71   :   __m256i truncable = _mm256_add_epi32 (v,         debias);

	vmovdqu	ymm0, YMMWORD PTR _v$[ebp]
	vpaddd	ymm0, ymm0, YMMWORD PTR _debias$[ebp]
	vmovdqu	YMMWORD PTR _truncable$[ebp], ymm0

; 72   :   return              _mm256_srai_epi32(truncable, shift);

	vmovdqu	ymm0, YMMWORD PTR _truncable$[ebp]
	vmovd	xmm1, DWORD PTR _shift$[ebx]
	vpsrad	ymm0, ymm0, xmm1

; 73   : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_truncate_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _swap_lanes
_TEXT	SEGMENT
_v$ = -64						; size = 32
_swap_lanes PROC					; COMDAT
; _v$ = ymm0

; 65   : {

	push	ebx
	mov	ebx, esp
	sub	esp, 8
	and	esp, -32				; ffffffe0H
	add	esp, 4
	push	ebp
	mov	ebp, DWORD PTR [ebx+4]
	mov	DWORD PTR [esp+4], ebp
	mov	ebp, esp
	sub	esp, 280				; 00000118H
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-280]
	mov	ecx, 70					; 00000046H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	vmovups	YMMWORD PTR _v$[ebp], ymm0
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 66   :   return _mm256_permute4x64_epi64(v, _MM_SHUFFLE(1, 0, 3, 2));

	vpermq	ymm0, YMMWORD PTR _v$[ebp], 78		; 0000004eH

; 67   : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	mov	esp, ebx
	pop	ebx
	ret	0
_swap_lanes ENDP
_TEXT	ENDS
; Function compile flags: /Odtp /RTCsu /ZI
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\dct-avx2.c
;	COMDAT _kvz_strategy_register_dct_avx2
_TEXT	SEGMENT
tv206 = -208						; size = 4
tv195 = -208						; size = 4
tv184 = -208						; size = 4
tv173 = -208						; size = 4
tv162 = -208						; size = 4
tv151 = -208						; size = 4
tv140 = -208						; size = 4
tv129 = -208						; size = 4
tv86 = -208						; size = 4
tv75 = -208						; size = 4
_success$ = -5						; size = 1
_opaque$ = 8						; size = 4
_bitdepth$ = 12						; size = 1
_kvz_strategy_register_dct_avx2 PROC			; COMDAT

; 945  : {

	push	ebp
	mov	ebp, esp
	sub	esp, 208				; 000000d0H
	push	ebx
	push	esi
	push	edi
	lea	edi, DWORD PTR [ebp-208]
	mov	ecx, 52					; 00000034H
	mov	eax, -858993460				; ccccccccH
	rep stosd
	mov	ecx, OFFSET __56A71F03_dct-avx2@c
	call	@__CheckForDebuggerJustMyCode@4

; 946  :   bool success = true;

	mov	BYTE PTR _success$[ebp], 1

; 947  : #if COMPILE_INTEL_AVX2
; 948  : #if KVZ_BIT_DEPTH == 8
; 949  :   if (bitdepth == 8){

	movzx	eax, BYTE PTR _bitdepth$[ebp]
	cmp	eax, 8
	jne	$LN2@kvz_strate

; 950  :     success &= kvz_strategyselector_register(opaque, "fast_forward_dst_4x4", "avx2", 40, &matrix_dst_4x4_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_dst_4x4_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_0BF@BJKPGPEP@fast_forward_dst_4x4@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN4@kvz_strate
	mov	DWORD PTR tv75[ebp], 0
	jmp	SHORT $LN5@kvz_strate
$LN4@kvz_strate:
	mov	DWORD PTR tv75[ebp], 1
$LN5@kvz_strate:
	mov	cl, BYTE PTR tv75[ebp]
	mov	BYTE PTR _success$[ebp], cl

; 951  : 
; 952  :     success &= kvz_strategyselector_register(opaque, "dct_4x4", "avx2", 40, &matrix_dct_4x4_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_dct_4x4_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_07MAFDGKIL@dct_4x4@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN6@kvz_strate
	mov	DWORD PTR tv86[ebp], 0
	jmp	SHORT $LN7@kvz_strate
$LN6@kvz_strate:
	mov	DWORD PTR tv86[ebp], 1
$LN7@kvz_strate:
	mov	cl, BYTE PTR tv86[ebp]
	mov	BYTE PTR _success$[ebp], cl

; 953  :     success &= kvz_strategyselector_register(opaque, "dct_8x8", "avx2", 40, &matrix_dct_8x8_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_dct_8x8_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_07CGDAJKDP@dct_8x8@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN8@kvz_strate
	mov	DWORD PTR tv129[ebp], 0
	jmp	SHORT $LN9@kvz_strate
$LN8@kvz_strate:
	mov	DWORD PTR tv129[ebp], 1
$LN9@kvz_strate:
	mov	cl, BYTE PTR tv129[ebp]
	mov	BYTE PTR _success$[ebp], cl

; 954  :     success &= kvz_strategyselector_register(opaque, "dct_16x16", "avx2", 40, &matrix_dct_16x16_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_dct_16x16_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_09LPGJIHFJ@dct_16x16@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN10@kvz_strate
	mov	DWORD PTR tv140[ebp], 0
	jmp	SHORT $LN11@kvz_strate
$LN10@kvz_strate:
	mov	DWORD PTR tv140[ebp], 1
$LN11@kvz_strate:
	mov	cl, BYTE PTR tv140[ebp]
	mov	BYTE PTR _success$[ebp], cl

; 955  :     success &= kvz_strategyselector_register(opaque, "dct_32x32", "avx2", 40, &matrix_dct_32x32_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_dct_32x32_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_09GAMJJBPI@dct_32x32@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN12@kvz_strate
	mov	DWORD PTR tv151[ebp], 0
	jmp	SHORT $LN13@kvz_strate
$LN12@kvz_strate:
	mov	DWORD PTR tv151[ebp], 1
$LN13@kvz_strate:
	mov	cl, BYTE PTR tv151[ebp]
	mov	BYTE PTR _success$[ebp], cl

; 956  : 
; 957  :     success &= kvz_strategyselector_register(opaque, "fast_inverse_dst_4x4", "avx2", 40, &matrix_idst_4x4_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_idst_4x4_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_0BF@LGIDMEOF@fast_inverse_dst_4x4@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN14@kvz_strate
	mov	DWORD PTR tv162[ebp], 0
	jmp	SHORT $LN15@kvz_strate
$LN14@kvz_strate:
	mov	DWORD PTR tv162[ebp], 1
$LN15@kvz_strate:
	mov	cl, BYTE PTR tv162[ebp]
	mov	BYTE PTR _success$[ebp], cl

; 958  : 
; 959  :     success &= kvz_strategyselector_register(opaque, "idct_4x4", "avx2", 40, &matrix_idct_4x4_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_idct_4x4_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_08LDLIJGLD@idct_4x4@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN16@kvz_strate
	mov	DWORD PTR tv173[ebp], 0
	jmp	SHORT $LN17@kvz_strate
$LN16@kvz_strate:
	mov	DWORD PTR tv173[ebp], 1
$LN17@kvz_strate:
	mov	cl, BYTE PTR tv173[ebp]
	mov	BYTE PTR _success$[ebp], cl

; 960  :     success &= kvz_strategyselector_register(opaque, "idct_8x8", "avx2", 40, &matrix_idct_8x8_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_idct_8x8_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_08FFNLGGAH@idct_8x8@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN18@kvz_strate
	mov	DWORD PTR tv184[ebp], 0
	jmp	SHORT $LN19@kvz_strate
$LN18@kvz_strate:
	mov	DWORD PTR tv184[ebp], 1
$LN19@kvz_strate:
	mov	cl, BYTE PTR tv184[ebp]
	mov	BYTE PTR _success$[ebp], cl

; 961  :     success &= kvz_strategyselector_register(opaque, "idct_16x16", "avx2", 40, &matrix_idct_16x16_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_idct_16x16_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_0L@BMPNPGHO@idct_16x16@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN20@kvz_strate
	mov	DWORD PTR tv195[ebp], 0
	jmp	SHORT $LN21@kvz_strate
$LN20@kvz_strate:
	mov	DWORD PTR tv195[ebp], 1
$LN21@kvz_strate:
	mov	cl, BYTE PTR tv195[ebp]
	mov	BYTE PTR _success$[ebp], cl

; 962  :     success &= kvz_strategyselector_register(opaque, "idct_32x32", "avx2", 40, &matrix_idct_32x32_avx2);

	movzx	esi, BYTE PTR _success$[ebp]
	push	OFFSET _matrix_idct_32x32_avx2
	push	40					; 00000028H
	push	OFFSET ??_C@_04GEEJMEMG@avx2@
	push	OFFSET ??_C@_0L@MDFNOANP@idct_32x32@
	mov	eax, DWORD PTR _opaque$[ebp]
	push	eax
	call	_kvz_strategyselector_register
	add	esp, 20					; 00000014H
	and	esi, eax
	jne	SHORT $LN22@kvz_strate
	mov	DWORD PTR tv206[ebp], 0
	jmp	SHORT $LN23@kvz_strate
$LN22@kvz_strate:
	mov	DWORD PTR tv206[ebp], 1
$LN23@kvz_strate:
	mov	cl, BYTE PTR tv206[ebp]
	mov	BYTE PTR _success$[ebp], cl
$LN2@kvz_strate:

; 963  :   }
; 964  : #endif // KVZ_BIT_DEPTH == 8
; 965  : #endif //COMPILE_INTEL_AVX2  
; 966  :   return success;

	movzx	eax, BYTE PTR _success$[ebp]

; 967  : }

	pop	edi
	pop	esi
	pop	ebx
	add	esp, 208				; 000000d0H
	cmp	ebp, esp
	call	__RTC_CheckEsp
	mov	esp, ebp
	pop	ebp
	ret	0
_kvz_strategy_register_dct_avx2 ENDP
_TEXT	ENDS
END
