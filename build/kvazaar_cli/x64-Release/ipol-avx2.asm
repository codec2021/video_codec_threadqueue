; Listing generated by Microsoft (R) Optimizing Compiler Version 19.26.28806.0 

include listing.inc

INCLUDELIB OLDNAMES

cbf_masks DW	01fH
	DW	0fH
	DW	07H
	DW	03H
	DW	01H
	ORG $+6
g_sig_last_scan_16x16 DD 00H
	DD	04H
	DD	01H
	DD	08H
	DD	05H
	DD	02H
	DD	0cH
	DD	09H
	DD	06H
	DD	03H
	DD	0dH
	DD	0aH
	DD	07H
	DD	0eH
	DD	0bH
	DD	0fH
g_group_idx DB	00H
	DB	01H
	DB	02H
	DB	03H
	DB	04H
	DB	04H
	DB	05H
	DB	05H
	DB	06H
	DB	06H
	DB	06H
	DB	06H
	DB	07H
	DB	07H
	DB	07H
	DB	07H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	08H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
	DB	09H
strategies_to_select DQ FLAT:$SG4294948721
	DQ	FLAT:kvz_array_checksum
	DQ	FLAT:$SG4294948720
	DQ	FLAT:kvz_array_md5
	DQ	FLAT:$SG4294948719
	DQ	FLAT:kvz_reg_sad
	DQ	FLAT:$SG4294948718
	DQ	FLAT:kvz_sad_4x4
	DQ	FLAT:$SG4294948717
	DQ	FLAT:kvz_sad_8x8
	DQ	FLAT:$SG4294948716
	DQ	FLAT:kvz_sad_16x16
	DQ	FLAT:$SG4294948715
	DQ	FLAT:kvz_sad_32x32
	DQ	FLAT:$SG4294948714
	DQ	FLAT:kvz_sad_64x64
	DQ	FLAT:$SG4294948713
	DQ	FLAT:kvz_satd_4x4
	DQ	FLAT:$SG4294948712
	DQ	FLAT:kvz_satd_8x8
	DQ	FLAT:$SG4294948711
	DQ	FLAT:kvz_satd_16x16
	DQ	FLAT:$SG4294948710
	DQ	FLAT:kvz_satd_32x32
	DQ	FLAT:$SG4294948709
	DQ	FLAT:kvz_satd_64x64
	DQ	FLAT:$SG4294948708
	DQ	FLAT:kvz_satd_any_size
	DQ	FLAT:$SG4294948707
	DQ	FLAT:kvz_sad_4x4_dual
	DQ	FLAT:$SG4294948706
	DQ	FLAT:kvz_sad_8x8_dual
	DQ	FLAT:$SG4294948705
	DQ	FLAT:kvz_sad_16x16_dual
	DQ	FLAT:$SG4294948704
	DQ	FLAT:kvz_sad_32x32_dual
	DQ	FLAT:$SG4294948703
	DQ	FLAT:kvz_sad_64x64_dual
	DQ	FLAT:$SG4294948702
	DQ	FLAT:kvz_satd_4x4_dual
	DQ	FLAT:$SG4294948701
	DQ	FLAT:kvz_satd_8x8_dual
	DQ	FLAT:$SG4294948700
	DQ	FLAT:kvz_satd_16x16_dual
	DQ	FLAT:$SG4294948699
	DQ	FLAT:kvz_satd_32x32_dual
	DQ	FLAT:$SG4294948698
	DQ	FLAT:kvz_satd_64x64_dual
	DQ	FLAT:$SG4294948697
	DQ	FLAT:kvz_satd_any_size_quad
	DQ	FLAT:$SG4294948696
	DQ	FLAT:kvz_pixels_calc_ssd
	DQ	FLAT:$SG4294948695
	DQ	FLAT:kvz_bipred_average
	DQ	FLAT:$SG4294948694
	DQ	FLAT:kvz_get_optimized_sad
	DQ	FLAT:$SG4294948693
	DQ	FLAT:kvz_ver_sad
	DQ	FLAT:$SG4294948692
	DQ	FLAT:kvz_hor_sad
	DQ	FLAT:$SG4294948691
	DQ	FLAT:kvz_pixel_var
	DQ	FLAT:$SG4294948690
	DQ	FLAT:kvz_fast_forward_dst_4x4
	DQ	FLAT:$SG4294948689
	DQ	FLAT:kvz_dct_4x4
	DQ	FLAT:$SG4294948688
	DQ	FLAT:kvz_dct_8x8
	DQ	FLAT:$SG4294948687
	DQ	FLAT:kvz_dct_16x16
	DQ	FLAT:$SG4294948686
	DQ	FLAT:kvz_dct_32x32
	DQ	FLAT:$SG4294948685
	DQ	FLAT:kvz_fast_inverse_dst_4x4
	DQ	FLAT:$SG4294948684
	DQ	FLAT:kvz_idct_4x4
	DQ	FLAT:$SG4294948683
	DQ	FLAT:kvz_idct_8x8
	DQ	FLAT:$SG4294948682
	DQ	FLAT:kvz_idct_16x16
	DQ	FLAT:$SG4294948681
	DQ	FLAT:kvz_idct_32x32
	DQ	FLAT:$SG4294948680
	DQ	FLAT:kvz_filter_hpel_blocks_hor_ver_luma
	DQ	FLAT:$SG4294948679
	DQ	FLAT:kvz_filter_hpel_blocks_diag_luma
	DQ	FLAT:$SG4294948678
	DQ	FLAT:kvz_filter_qpel_blocks_hor_ver_luma
	DQ	FLAT:$SG4294948677
	DQ	FLAT:kvz_filter_qpel_blocks_diag_luma
	DQ	FLAT:$SG4294948676
	DQ	FLAT:kvz_sample_quarterpel_luma
	DQ	FLAT:$SG4294948675
	DQ	FLAT:kvz_sample_octpel_chroma
	DQ	FLAT:$SG4294948674
	DQ	FLAT:kvz_sample_quarterpel_luma_hi
	DQ	FLAT:$SG4294948673
	DQ	FLAT:kvz_sample_octpel_chroma_hi
	DQ	FLAT:$SG4294948672
	DQ	FLAT:kvz_get_extended_block
	DQ	FLAT:$SG4294948671
	DQ	FLAT:kvz_quant
	DQ	FLAT:$SG4294948670
	DQ	FLAT:kvz_quantize_residual
	DQ	FLAT:$SG4294948669
	DQ	FLAT:kvz_dequant
	DQ	FLAT:$SG4294948668
	DQ	FLAT:kvz_coeff_abs_sum
	DQ	FLAT:$SG4294948667
	DQ	FLAT:kvz_fast_coeff_cost
	DQ	FLAT:$SG4294948666
	DQ	FLAT:kvz_angular_pred
	DQ	FLAT:$SG4294948665
	DQ	FLAT:kvz_intra_pred_planar
	DQ	FLAT:$SG4294948664
	DQ	FLAT:kvz_intra_pred_filtered_dc
	DQ	FLAT:$SG4294948663
	DQ	FLAT:kvz_sao_edge_ddistortion
	DQ	FLAT:$SG4294948662
	DQ	FLAT:kvz_calc_sao_edge_dir
	DQ	FLAT:$SG4294948661
	DQ	FLAT:kvz_sao_reconstruct_color
	DQ	FLAT:$SG4294948660
	DQ	FLAT:kvz_sao_band_ddistortion
	DQ	FLAT:$SG4294948659
	DQ	FLAT:kvz_encode_coeff_nxn
	DQ	0000000000000000H
	DQ	0000000000000000H
g_sig_last_scan_32x32 DD 00H
	DD	08H
	DD	01H
	DD	010H
	DD	09H
	DD	02H
	DD	018H
	DD	011H
	DD	0aH
	DD	03H
	DD	020H
	DD	019H
	DD	012H
	DD	0bH
	DD	04H
	DD	028H
	DD	021H
	DD	01aH
	DD	013H
	DD	0cH
	DD	05H
	DD	030H
	DD	029H
	DD	022H
	DD	01bH
	DD	014H
	DD	0dH
	DD	06H
	DD	038H
	DD	031H
	DD	02aH
	DD	023H
	DD	01cH
	DD	015H
	DD	0eH
	DD	07H
	DD	039H
	DD	032H
	DD	02bH
	DD	024H
	DD	01dH
	DD	016H
	DD	0fH
	DD	03aH
	DD	033H
	DD	02cH
	DD	025H
	DD	01eH
	DD	017H
	DD	03bH
	DD	034H
	DD	02dH
	DD	026H
	DD	01fH
	DD	03cH
	DD	035H
	DD	02eH
	DD	027H
	DD	03dH
	DD	036H
	DD	02fH
	DD	03eH
	DD	037H
	DD	03fH
g_min_in_group DB 00H
	DB	01H
	DB	02H
	DB	03H
	DB	04H
	DB	06H
	DB	08H
	DB	0cH
	DB	010H
	DB	018H
	ORG $+6
default_fast_coeff_cost_wts DD 03e282e88r	; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e282e88r			; 0.16424
	DD	040852b41r			; 4.16153
	DD	0406093ffr			; 3.50903
	DD	040ddb290r			; 6.92805
	DD	03e26c094r			; 0.162844
	DD	04081ca43r			; 4.05594
	DD	04064203ar			; 3.56447
	DD	040db915ar			; 6.86149
	DD	03e03d189r			; 0.128729
	DD	04089fbafr			; 4.31197
	DD	0407c5771r			; 3.94284
	DD	040ddeed2r			; 6.9354
	DD	03de33ce6r			; 0.110956
	DD	0408ddcb1r			; 4.43319
	DD	0407c8738r			; 3.94575
	DD	040dc1618r			; 6.8777
	DD	03dc29cfer			; 0.095026
	DD	0408f7938r			; 4.48355
	DD	0408636aar			; 4.19417
	DD	040d90260r			; 6.78154
	DD	03d99b1b8r			; 0.075046
	DD	04094474cr			; 4.6337
	DD	04082b1b6r			; 4.08419
	DD	040d65aeer			; 6.6986
	DD	03d56bca5r			; 0.052426
	DD	0409ef37er			; 4.96722
	DD	04080dee8r			; 4.02721
	DD	040d19306r			; 6.5492
	DD	03d24bcaer			; 0.040219
	DD	040a489car			; 5.14182
	DD	0407ee3bdr			; 3.98265
	DD	040cec513r			; 6.46156
	DD	03d0fba88r			; 0.03509
	DD	040a628e7r			; 5.19249
	DD	040752e49r			; 3.83095
	DD	040cd642ar			; 6.41848
	DD	03cf47d80r			; 0.029845
	DD	040a6c5d0r			; 5.21165
	DD	040743073r			; 3.81546
	DD	040cb0dd8r			; 6.34544
	DD	03cc0b136r			; 0.023522
	DD	040aa4f92r			; 5.32221
	DD	040744224r			; 3.81654
	DD	040cb8aaar			; 6.36068
	DD	03cae87d3r			; 0.021305
	DD	040a73ac3r			; 5.22592
	DD	04075eeccr			; 3.8427
	DD	040ca6cd9r			; 6.32579
	DD	03c821294r			; 0.015878
	DD	040a5dbe0r			; 5.18309
	DD	0407d2f27r			; 3.956
	DD	040ca8cbdr			; 6.32968
	DD	03c2ae297r			; 0.01043
	DD	040a32ce4r			; 5.09923
	DD	04085a85fr			; 4.1768
	DD	040c9c5d6r			; 6.3054
	DD	03c0a2a91r			; 0.008433
	DD	040a0f7der			; 5.03026
	DD	040879a50r			; 4.23759
	DD	040c8a4eer			; 6.27013
	DD	03bd4fdf4r			; 0.0065
	DD	0409f0412r			; 4.96925
	DD	0408adc57r			; 4.3394
	DD	040c6f870r			; 6.21783
	DD	03ba18373r			; 0.004929
	DD	0409d8d50r			; 4.9235
	DD	0408e283fr			; 4.44241
	DD	040c5df6cr			; 6.18352
	DD	03b73775cr			; 0.003715
	DD	0409d4c75r			; 4.91558
	DD	0408dbb1br			; 4.42909
	DD	040c4029fr			; 6.12532
	DD	03b4a70d2r			; 0.003089
	DD	0409c48f7r			; 4.88391
	DD	040920260r			; 4.56279
	DD	040c5019dr			; 6.15645
	DD	03b219c9dr			; 0.002466
	DD	0409c31abr			; 4.88106
	DD	040942800r			; 4.62988
	DD	040c49088r			; 6.14264
	DD	03b0e25c8r			; 0.002169
	DD	0409c3d62r			; 4.88249
	DD	04094ae99r			; 4.64631
	DD	040c415d1r			; 6.12766
	DD	03b26dacbr			; 0.002546
	DD	040996304r			; 4.79334
	DD	0409acc16r			; 4.83741
	DD	040c6606br			; 6.19927
	DD	03aac3a86r			; 0.001314
	DD	04099e220r			; 4.80885
	DD	0409a81bdr			; 4.82834
	DD	040c7ca3cr			; 6.24344
	DD	03a9741d1r			; 0.001154
	DD	0409b9a72r			; 4.8626
	DD	0409b19aar			; 4.84688
	DD	040c693a5r			; 6.20552
	DD	03a80f990r			; 0.000984
	DD	0409bb993r			; 4.8664
	DD	0409b7fa2r			; 4.85933
	DD	040c7b565r			; 6.24089
	DD	03a551f82r			; 0.000813
	DD	0409b698ar			; 4.85663
	DD	0409d95bar			; 4.92453
	DD	040c963a4r			; 6.29341
	DD	03a91c087r			; 0.001112
	DD	04099419er			; 4.78926
	DD	040a050f0r			; 5.00988
	DD	040cddf8fr			; 6.43354
	DD	03a10b418r			; 0.000552
	DD	04098580ar			; 4.76075
	DD	040a2e4f1r			; 5.09045
	DD	040d32e1fr			; 6.59938
	DD	039ccff22r			; 0.000391
	DD	0409ec42cr			; 4.96145
	DD	040a38d95r			; 5.11103
	DD	040d8342fr			; 6.75637
	DD	039ae1049r			; 0.000332
	DD	0409f63f8r			; 4.98095
	DD	040a46b89r			; 5.13813
	DD	040dbc1e8r			; 6.86742
	DD	03952c387r			; 0.000201
	DD	040a5d297r			; 5.18196
	DD	04097af64r			; 4.74016
	DD	040cec07dr			; 6.461
	DD	0397ba882r			; 0.00024
	DD	040a5eeb7r			; 5.18539
	DD	0409bfeb0r			; 4.87484
	DD	040da3603r			; 6.81909
	DD	03908509cr			; 0.00013
	DD	040a8a6b5r			; 5.27035
	DD	040977eacr			; 4.73421
	DD	040da708fr			; 6.82624
	DD	038da1a93r			; 0.000104
	DD	040abe6e8r			; 5.37194
	DD	040930af4r			; 4.59509
	DD	040d5189ar			; 6.65925
	DD	038ae1049r			; 8.3e-05
	DD	040ab9581r			; 5.362
	DD	04093c250r			; 4.61747
	DD	040dacf03r			; 6.83777
	DD	03890b418r			; 6.9e-05
	DD	040a926e3r			; 5.286
	DD	0409828e7r			; 4.75499
	DD	040e516e1r			; 7.15904
	DD	0384d8559r			; 4.9e-05
	DD	040afa18cr			; 5.48847
	DD	0408cace9r			; 4.39611
	DD	040d74682r			; 6.72736
	DD	038734507r			; 5.8e-05
	DD	0409eafa3r			; 4.95894
	DD	040929321r			; 4.58046
	DD	040cf49a5r			; 6.47774
	DD	037eae18br			; 2.8e-05
	DD	040b0ae1br			; 5.52125
	DD	0408e1885r			; 4.44049
	DD	040e68f80r			; 7.20502
	DD	000000000r			; 0
	DD	000000000r			; 0
	DD	000000000r			; 0
	DD	000000000r			; 0
	DD	0379f6230r			; 1.9e-05
	DD	040b9f5d8r			; 5.81126
	DD	0408cc582r			; 4.39911
	DD	040eac30dr			; 7.33631
g_sao_edge_offsets DD 0ffffffffH
	DD	00H
	DD	01H
	DD	00H
	DD	00H
	DD	0ffffffffH
	DD	00H
	DD	01H
	DD	0ffffffffH
	DD	0ffffffffH
	DD	01H
	DD	01H
	DD	01H
	DD	0ffffffffH
	DD	0ffffffffH
	DD	01H
g_sig_last_scan_cg DQ FLAT:g_sig_last_scan_8x8
	DQ	FLAT:g_sig_last_scan_8x8+16
	DQ	FLAT:g_sig_last_scan_8x8+32
	DQ	FLAT:g_sig_last_scan_8x8
	DQ	FLAT:g_sig_last_scan_8x8+16
	DQ	FLAT:g_sig_last_scan_8x8+32
	DQ	FLAT:g_sig_last_scan_16x16
	DQ	0000000000000000H
	DQ	0000000000000000H
	DQ	FLAT:g_sig_last_scan_32x32
	DQ	0000000000000000H
	DQ	0000000000000000H
g_sig_last_scan_8x8 DD 00H
	DD	02H
	DD	01H
	DD	03H
	DD	00H
	DD	01H
	DD	02H
	DD	03H
	DD	00H
	DD	02H
	DD	01H
	DD	03H
	ORG $+3
$SG4294948671 DB 'quant', 00H
	ORG $+7
$SG4294948721 DB 'array_checksum', 00H
	ORG $+1
$SG4294948720 DB 'array_md5', 00H
	ORG $+6
$SG4294948719 DB 'reg_sad', 00H
$SG4294948718 DB 'sad_4x4', 00H
$SG4294948717 DB 'sad_8x8', 00H
$SG4294948716 DB 'sad_16x16', 00H
	ORG $+6
$SG4294948715 DB 'sad_32x32', 00H
	ORG $+6
$SG4294948714 DB 'sad_64x64', 00H
	ORG $+6
$SG4294948713 DB 'satd_4x4', 00H
	ORG $+7
$SG4294948712 DB 'satd_8x8', 00H
	ORG $+7
$SG4294948711 DB 'satd_16x16', 00H
	ORG $+5
$SG4294948710 DB 'satd_32x32', 00H
	ORG $+5
$SG4294948709 DB 'satd_64x64', 00H
	ORG $+5
$SG4294948708 DB 'satd_any_size', 00H
	ORG $+2
$SG4294948707 DB 'sad_4x4_dual', 00H
	ORG $+3
$SG4294948706 DB 'sad_8x8_dual', 00H
	ORG $+3
$SG4294948705 DB 'sad_16x16_dual', 00H
	ORG $+1
$SG4294948704 DB 'sad_32x32_dual', 00H
	ORG $+1
$SG4294948703 DB 'sad_64x64_dual', 00H
	ORG $+1
$SG4294948702 DB 'satd_4x4_dual', 00H
	ORG $+2
$SG4294948701 DB 'satd_8x8_dual', 00H
	ORG $+2
$SG4294948700 DB 'satd_16x16_dual', 00H
$SG4294948699 DB 'satd_32x32_dual', 00H
$SG4294948698 DB 'satd_64x64_dual', 00H
$SG4294948697 DB 'satd_any_size_quad', 00H
	ORG $+5
$SG4294948696 DB 'pixels_calc_ssd', 00H
$SG4294948695 DB 'bipred_average', 00H
	ORG $+1
$SG4294948694 DB 'get_optimized_sad', 00H
	ORG $+6
$SG4294948693 DB 'ver_sad', 00H
$SG4294948692 DB 'hor_sad', 00H
$SG4294948691 DB 'pixel_var', 00H
	ORG $+6
$SG4294948690 DB 'fast_forward_dst_4x4', 00H
	ORG $+3
$SG4294948689 DB 'dct_4x4', 00H
$SG4294948688 DB 'dct_8x8', 00H
$SG4294948687 DB 'dct_16x16', 00H
	ORG $+6
$SG4294948686 DB 'dct_32x32', 00H
	ORG $+6
$SG4294948685 DB 'fast_inverse_dst_4x4', 00H
	ORG $+3
$SG4294948684 DB 'idct_4x4', 00H
	ORG $+7
$SG4294948683 DB 'idct_8x8', 00H
	ORG $+7
$SG4294948682 DB 'idct_16x16', 00H
	ORG $+5
$SG4294948681 DB 'idct_32x32', 00H
	ORG $+5
$SG4294948680 DB 'filter_hpel_blocks_hor_ver_luma', 00H
$SG4294948679 DB 'filter_hpel_blocks_diag_luma', 00H
	ORG $+3
$SG4294948678 DB 'filter_qpel_blocks_hor_ver_luma', 00H
$SG4294948677 DB 'filter_qpel_blocks_diag_luma', 00H
	ORG $+3
$SG4294948676 DB 'sample_quarterpel_luma', 00H
	ORG $+1
$SG4294948675 DB 'sample_octpel_chroma', 00H
	ORG $+3
$SG4294948674 DB 'sample_quarterpel_luma_hi', 00H
	ORG $+6
$SG4294948673 DB 'sample_octpel_chroma_hi', 00H
$SG4294948672 DB 'get_extended_block', 00H
	ORG $+5
$SG4294948670 DB 'quantize_residual', 00H
	ORG $+6
$SG4294948669 DB 'dequant', 00H
$SG4294948668 DB 'coeff_abs_sum', 00H
	ORG $+2
$SG4294948667 DB 'fast_coeff_cost', 00H
$SG4294948666 DB 'angular_pred', 00H
	ORG $+3
$SG4294948665 DB 'intra_pred_planar', 00H
	ORG $+6
$SG4294948664 DB 'intra_pred_filtered_dc', 00H
	ORG $+1
$SG4294948663 DB 'sao_edge_ddistortion', 00H
	ORG $+3
$SG4294948662 DB 'calc_sao_edge_dir', 00H
	ORG $+6
$SG4294948661 DB 'sao_reconstruct_color', 00H
	ORG $+2
$SG4294948660 DB 'sao_band_ddistortion', 00H
	ORG $+3
$SG4294948659 DB 'encode_coeff_nxn', 00H
PUBLIC	kvz_strategy_register_ipol_avx2
pdata	SEGMENT
$pdata$kvz_sample_octpel_chroma_hi_avx2 DD imagerel kvz_sample_octpel_chroma_hi_avx2
	DD	imagerel kvz_sample_octpel_chroma_hi_avx2+275
	DD	imagerel $unwind$kvz_sample_octpel_chroma_hi_avx2
$pdata$kvz_sample_octpel_chroma_avx2 DD imagerel kvz_sample_octpel_chroma_avx2
	DD	imagerel kvz_sample_octpel_chroma_avx2+275
	DD	imagerel $unwind$kvz_sample_octpel_chroma_avx2
$pdata$kvz_sample_quarterpel_luma_hi_avx2 DD imagerel kvz_sample_quarterpel_luma_hi_avx2
	DD	imagerel kvz_sample_quarterpel_luma_hi_avx2+179
	DD	imagerel $unwind$kvz_sample_quarterpel_luma_hi_avx2
$pdata$kvz_sample_quarterpel_luma_avx2 DD imagerel kvz_sample_quarterpel_luma_avx2
	DD	imagerel kvz_sample_quarterpel_luma_avx2+179
	DD	imagerel $unwind$kvz_sample_quarterpel_luma_avx2
$pdata$kvz_filter_qpel_blocks_diag_luma_avx2 DD imagerel kvz_filter_qpel_blocks_diag_luma_avx2
	DD	imagerel kvz_filter_qpel_blocks_diag_luma_avx2+1284
	DD	imagerel $unwind$kvz_filter_qpel_blocks_diag_luma_avx2
$pdata$kvz_filter_qpel_blocks_hor_ver_luma_avx2 DD imagerel kvz_filter_qpel_blocks_hor_ver_luma_avx2
	DD	imagerel kvz_filter_qpel_blocks_hor_ver_luma_avx2+1713
	DD	imagerel $unwind$kvz_filter_qpel_blocks_hor_ver_luma_avx2
$pdata$kvz_filter_hpel_blocks_diag_luma_avx2 DD imagerel kvz_filter_hpel_blocks_diag_luma_avx2
	DD	imagerel kvz_filter_hpel_blocks_diag_luma_avx2+696
	DD	imagerel $unwind$kvz_filter_hpel_blocks_diag_luma_avx2
$pdata$kvz_filter_hpel_blocks_hor_ver_luma_avx2 DD imagerel kvz_filter_hpel_blocks_hor_ver_luma_avx2
	DD	imagerel kvz_filter_hpel_blocks_hor_ver_luma_avx2+823
	DD	imagerel $unwind$kvz_filter_hpel_blocks_hor_ver_luma_avx2
$pdata$kvz_ipol_4tap_ver_im_hi_avx2 DD imagerel kvz_ipol_4tap_ver_im_hi_avx2
	DD	imagerel kvz_ipol_4tap_ver_im_hi_avx2+58
	DD	imagerel $unwind$kvz_ipol_4tap_ver_im_hi_avx2
$pdata$2$kvz_ipol_4tap_ver_im_hi_avx2 DD imagerel kvz_ipol_4tap_ver_im_hi_avx2+58
	DD	imagerel kvz_ipol_4tap_ver_im_hi_avx2+316
	DD	imagerel $chain$2$kvz_ipol_4tap_ver_im_hi_avx2
$pdata$3$kvz_ipol_4tap_ver_im_hi_avx2 DD imagerel kvz_ipol_4tap_ver_im_hi_avx2+316
	DD	imagerel kvz_ipol_4tap_ver_im_hi_avx2+341
	DD	imagerel $chain$3$kvz_ipol_4tap_ver_im_hi_avx2
$pdata$kvz_ipol_4tap_ver_im_px_avx2 DD imagerel kvz_ipol_4tap_ver_im_px_avx2
	DD	imagerel kvz_ipol_4tap_ver_im_px_avx2+58
	DD	imagerel $unwind$kvz_ipol_4tap_ver_im_px_avx2
$pdata$3$kvz_ipol_4tap_ver_im_px_avx2 DD imagerel kvz_ipol_4tap_ver_im_px_avx2+58
	DD	imagerel kvz_ipol_4tap_ver_im_px_avx2+336
	DD	imagerel $chain$3$kvz_ipol_4tap_ver_im_px_avx2
$pdata$4$kvz_ipol_4tap_ver_im_px_avx2 DD imagerel kvz_ipol_4tap_ver_im_px_avx2+336
	DD	imagerel kvz_ipol_4tap_ver_im_px_avx2+361
	DD	imagerel $chain$4$kvz_ipol_4tap_ver_im_px_avx2
$pdata$kvz_ipol_4tap_hor_px_im_avx2 DD imagerel kvz_ipol_4tap_hor_px_im_avx2
	DD	imagerel kvz_ipol_4tap_hor_px_im_avx2+105
	DD	imagerel $unwind$kvz_ipol_4tap_hor_px_im_avx2
$pdata$4$kvz_ipol_4tap_hor_px_im_avx2 DD imagerel kvz_ipol_4tap_hor_px_im_avx2+105
	DD	imagerel kvz_ipol_4tap_hor_px_im_avx2+389
	DD	imagerel $chain$4$kvz_ipol_4tap_hor_px_im_avx2
$pdata$5$kvz_ipol_4tap_hor_px_im_avx2 DD imagerel kvz_ipol_4tap_hor_px_im_avx2+389
	DD	imagerel kvz_ipol_4tap_hor_px_im_avx2+417
	DD	imagerel $chain$5$kvz_ipol_4tap_hor_px_im_avx2
$pdata$kvz_ipol_8tap_ver_im_hi_avx2 DD imagerel kvz_ipol_8tap_ver_im_hi_avx2
	DD	imagerel kvz_ipol_8tap_ver_im_hi_avx2+85
	DD	imagerel $unwind$kvz_ipol_8tap_ver_im_hi_avx2
$pdata$5$kvz_ipol_8tap_ver_im_hi_avx2 DD imagerel kvz_ipol_8tap_ver_im_hi_avx2+85
	DD	imagerel kvz_ipol_8tap_ver_im_hi_avx2+483
	DD	imagerel $chain$5$kvz_ipol_8tap_ver_im_hi_avx2
$pdata$6$kvz_ipol_8tap_ver_im_hi_avx2 DD imagerel kvz_ipol_8tap_ver_im_hi_avx2+483
	DD	imagerel kvz_ipol_8tap_ver_im_hi_avx2+524
	DD	imagerel $chain$6$kvz_ipol_8tap_ver_im_hi_avx2
$pdata$kvz_ipol_8tap_ver_im_px_avx2 DD imagerel kvz_ipol_8tap_ver_im_px_avx2
	DD	imagerel kvz_ipol_8tap_ver_im_px_avx2+88
	DD	imagerel $unwind$kvz_ipol_8tap_ver_im_px_avx2
$pdata$6$kvz_ipol_8tap_ver_im_px_avx2 DD imagerel kvz_ipol_8tap_ver_im_px_avx2+88
	DD	imagerel kvz_ipol_8tap_ver_im_px_avx2+509
	DD	imagerel $chain$6$kvz_ipol_8tap_ver_im_px_avx2
$pdata$7$kvz_ipol_8tap_ver_im_px_avx2 DD imagerel kvz_ipol_8tap_ver_im_px_avx2+509
	DD	imagerel kvz_ipol_8tap_ver_im_px_avx2+553
	DD	imagerel $chain$7$kvz_ipol_8tap_ver_im_px_avx2
$pdata$kvz_ipol_8tap_hor_px_im_avx2 DD imagerel kvz_ipol_8tap_hor_px_im_avx2
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+131
	DD	imagerel $unwind$kvz_ipol_8tap_hor_px_im_avx2
$pdata$0$kvz_ipol_8tap_hor_px_im_avx2 DD imagerel kvz_ipol_8tap_hor_px_im_avx2+131
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+218
	DD	imagerel $chain$0$kvz_ipol_8tap_hor_px_im_avx2
$pdata$2$kvz_ipol_8tap_hor_px_im_avx2 DD imagerel kvz_ipol_8tap_hor_px_im_avx2+218
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+432
	DD	imagerel $chain$2$kvz_ipol_8tap_hor_px_im_avx2
$pdata$3$kvz_ipol_8tap_hor_px_im_avx2 DD imagerel kvz_ipol_8tap_hor_px_im_avx2+432
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+449
	DD	imagerel $chain$3$kvz_ipol_8tap_hor_px_im_avx2
$pdata$4$kvz_ipol_8tap_hor_px_im_avx2 DD imagerel kvz_ipol_8tap_hor_px_im_avx2+449
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+681
	DD	imagerel $chain$4$kvz_ipol_8tap_hor_px_im_avx2
$pdata$kvz_eight_tap_filter_ver_16bit_1x8_avx2 DD imagerel kvz_eight_tap_filter_ver_16bit_1x8_avx2
	DD	imagerel kvz_eight_tap_filter_ver_16bit_1x8_avx2+289
	DD	imagerel $unwind$kvz_eight_tap_filter_ver_16bit_1x8_avx2
$pdata$kvz_strategy_register_ipol_avx2 DD imagerel $LN5
	DD	imagerel $LN5+382
	DD	imagerel $unwind$kvz_strategy_register_ipol_avx2
xdata	SEGMENT
$unwind$kvz_sample_octpel_chroma_hi_avx2 DD 071e01H
	DD	01457412H
	DD	01446412H
	DD	01420112H
	DD	0500bH
$unwind$kvz_sample_octpel_chroma_avx2 DD 071e01H
	DD	01457412H
	DD	01446412H
	DD	01420112H
	DD	0500bH
$unwind$kvz_sample_quarterpel_luma_hi_avx2 DD 072401H
	DD	04937418H
	DD	04926418H
	DD	04900118H
	DD	0500bH
$unwind$kvz_sample_quarterpel_luma_avx2 DD 072401H
	DD	04937418H
	DD	04926418H
	DD	04900118H
	DD	0500bH
$unwind$kvz_filter_qpel_blocks_diag_luma_avx2 DD 0c2101H
	DD	0166421H
	DD	0155421H
	DD	0143421H
	DD	0f01dd221H
	DD	0d019e01bH
	DD	07015c017H
$unwind$kvz_filter_qpel_blocks_hor_ver_luma_avx2 DD 0a1901H
	DD	0163419H
	DD	0f015d219H
	DD	0d011e013H
	DD	0700dc00fH
	DD	0500b600cH
$unwind$kvz_filter_hpel_blocks_diag_luma_avx2 DD 0c1c01H
	DD	010641cH
	DD	0f541cH
	DD	0e341cH
	DD	0f018721cH
	DD	0d014e016H
	DD	07010c012H
$unwind$kvz_filter_hpel_blocks_hor_ver_luma_avx2 DD 0c1c01H
	DD	011641cH
	DD	010541cH
	DD	0e341cH
	DD	0f018721cH
	DD	0d014e016H
	DD	07010c012H
$unwind$kvz_ipol_4tap_ver_im_hi_avx2 DD 082201H
	DD	07822H
	DD	01681aH
	DD	09640aH
	DD	07006320aH
$chain$2$kvz_ipol_4tap_ver_im_hi_avx2 DD 061c21H
	DD	08f41cH
	DD	07e411H
	DD	063405H
	DD	imagerel kvz_ipol_4tap_ver_im_hi_avx2
	DD	imagerel kvz_ipol_4tap_ver_im_hi_avx2+58
	DD	imagerel $unwind$kvz_ipol_4tap_ver_im_hi_avx2
$chain$3$kvz_ipol_4tap_ver_im_hi_avx2 DD 021H
	DD	imagerel kvz_ipol_4tap_ver_im_hi_avx2
	DD	imagerel kvz_ipol_4tap_ver_im_hi_avx2+58
	DD	imagerel $unwind$kvz_ipol_4tap_ver_im_hi_avx2
$unwind$kvz_ipol_4tap_ver_im_px_avx2 DD 082201H
	DD	08822H
	DD	01781aH
	DD	0b640aH
	DD	07006520aH
$chain$3$kvz_ipol_4tap_ver_im_px_avx2 DD 082721H
	DD	026827H
	DD	0af41cH
	DD	09e411H
	DD	083405H
	DD	imagerel kvz_ipol_4tap_ver_im_px_avx2
	DD	imagerel kvz_ipol_4tap_ver_im_px_avx2+58
	DD	imagerel $unwind$kvz_ipol_4tap_ver_im_px_avx2
$chain$4$kvz_ipol_4tap_ver_im_px_avx2 DD 021H
	DD	imagerel kvz_ipol_4tap_ver_im_px_avx2
	DD	imagerel kvz_ipol_4tap_ver_im_px_avx2+58
	DD	imagerel $unwind$kvz_ipol_4tap_ver_im_px_avx2
$unwind$kvz_ipol_4tap_hor_px_im_avx2 DD 094501H
	DD	08845H
	DD	017836H
	DD	026826H
	DD	0c0048208H
	DD	06002H
$chain$4$kvz_ipol_4tap_hor_px_im_avx2 DD 0a2a21H
	DD	06f42aH
	DD	07e41dH
	DD	08d418H
	DD	0e7411H
	DD	0d3405H
	DD	imagerel kvz_ipol_4tap_hor_px_im_avx2
	DD	imagerel kvz_ipol_4tap_hor_px_im_avx2+105
	DD	imagerel $unwind$kvz_ipol_4tap_hor_px_im_avx2
$chain$5$kvz_ipol_4tap_hor_px_im_avx2 DD 021H
	DD	imagerel kvz_ipol_4tap_hor_px_im_avx2
	DD	imagerel kvz_ipol_4tap_hor_px_im_avx2+105
	DD	imagerel $unwind$kvz_ipol_4tap_hor_px_im_avx2
$unwind$kvz_ipol_8tap_ver_im_hi_avx2 DD 0c3601H
	DD	0c836H
	DD	01b82eH
	DD	02a825H
	DD	039817H
	DD	013640cH
	DD	07008d20cH
$chain$5$kvz_ipol_8tap_ver_im_hi_avx2 DD 0c3521H
	DD	048835H
	DD	05782fH
	DD	066829H
	DD	012f41bH
	DD	011e40eH
	DD	0103404H
	DD	imagerel kvz_ipol_8tap_ver_im_hi_avx2
	DD	imagerel kvz_ipol_8tap_ver_im_hi_avx2+85
	DD	imagerel $unwind$kvz_ipol_8tap_ver_im_hi_avx2
$chain$6$kvz_ipol_8tap_ver_im_hi_avx2 DD 021H
	DD	imagerel kvz_ipol_8tap_ver_im_hi_avx2
	DD	imagerel kvz_ipol_8tap_ver_im_hi_avx2+85
	DD	imagerel $unwind$kvz_ipol_8tap_ver_im_hi_avx2
$unwind$kvz_ipol_8tap_ver_im_px_avx2 DD 0c3901H
	DD	0d839H
	DD	01c831H
	DD	02b828H
	DD	03a81aH
	DD	015640fH
	DD	07008f20fH
$chain$6$kvz_ipol_8tap_ver_im_px_avx2 DD 0e3b21H
	DD	04983bH
	DD	058835H
	DD	06782fH
	DD	076829H
	DD	014f41bH
	DD	013e40eH
	DD	0123404H
	DD	imagerel kvz_ipol_8tap_ver_im_px_avx2
	DD	imagerel kvz_ipol_8tap_ver_im_px_avx2+88
	DD	imagerel $unwind$kvz_ipol_8tap_ver_im_px_avx2
$chain$7$kvz_ipol_8tap_ver_im_px_avx2 DD 021H
	DD	imagerel kvz_ipol_8tap_ver_im_px_avx2
	DD	imagerel kvz_ipol_8tap_ver_im_px_avx2+88
	DD	imagerel $unwind$kvz_ipol_8tap_ver_im_px_avx2
$unwind$kvz_ipol_8tap_hor_px_im_avx2 DD 0187b01H
	DD	0e87bH
	DD	01d86eH
	DD	02c860H
	DD	03b852H
	DD	04a84cH
	DD	059847H
	DD	068842H
	DD	07783aH
	DD	086832H
	DD	0130115H
	DD	0e00cf00eH
	DD	07008d00aH
$chain$0$kvz_ipol_8tap_hor_px_im_avx2 DD 020421H
	DD	0193404H
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+131
	DD	imagerel $unwind$kvz_ipol_8tap_hor_px_im_avx2
$chain$2$kvz_ipol_8tap_hor_px_im_avx2 DD 041421H
	DD	012c414H
	DD	01a6408H
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+131
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+218
	DD	imagerel $chain$0$kvz_ipol_8tap_hor_px_im_avx2
$chain$3$kvz_ipol_8tap_hor_px_im_avx2 DD 021H
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+131
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+218
	DD	imagerel $chain$0$kvz_ipol_8tap_hor_px_im_avx2
$chain$4$kvz_ipol_8tap_hor_px_im_avx2 DD 021H
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2
	DD	imagerel kvz_ipol_8tap_hor_px_im_avx2+131
	DD	imagerel $unwind$kvz_ipol_8tap_hor_px_im_avx2
$unwind$kvz_eight_tap_filter_ver_16bit_1x8_avx2 DD 0b3801H
	DD	0a838H
	DD	019833H
	DD	02882eH
	DD	037829H
	DD	04681fH
	DD	0a207H
$unwind$kvz_strategy_register_ipol_avx2 DD 060f01H
	DD	09640fH
	DD	08340fH
	DD	0700b520fH
$SG4294948644 DB 'avx2', 00H
$SG4294948646 DB 'avx2', 00H
$SG4294948648 DB 'avx2', 00H
$SG4294948650 DB 'avx2', 00H
$SG4294948643 DB 'sample_octpel_chroma_hi', 00H
$SG4294948645 DB 'sample_quarterpel_luma_hi', 00H
	ORG $+6
$SG4294948647 DB 'sample_octpel_chroma', 00H
	ORG $+3
$SG4294948649 DB 'sample_quarterpel_luma', 00H
	ORG $+1
$SG4294948651 DB 'filter_qpel_blocks_diag_luma', 00H
	ORG $+3
$SG4294948652 DB 'avx2', 00H
	ORG $+3
$SG4294948653 DB 'filter_qpel_blocks_hor_ver_luma', 00H
$SG4294948654 DB 'avx2', 00H
	ORG $+3
$SG4294948655 DB 'filter_hpel_blocks_diag_luma', 00H
	ORG $+3
$SG4294948656 DB 'avx2', 00H
	ORG $+3
$SG4294948657 DB 'filter_hpel_blocks_hor_ver_luma', 00H
$SG4294948658 DB 'avx2', 00H
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
opaque$ = 64
bitdepth$dead$ = 72
kvz_strategy_register_ipol_avx2 PROC

; 1249 : {

$LN5:
	mov	QWORD PTR [rsp+8], rbx
	mov	QWORD PTR [rsp+16], rsi
	push	rdi
	sub	rsp, 48					; 00000030H

; 1250 :   bool success = true;
; 1251 : #if COMPILE_INTEL_AVX2 && defined X86_64
; 1252 :   if (bitdepth == 8){
; 1253 :     success &= kvz_strategyselector_register(opaque, "filter_hpel_blocks_hor_ver_luma", "avx2", 40, &kvz_filter_hpel_blocks_hor_ver_luma_avx2);

	lea	rax, OFFSET FLAT:kvz_filter_hpel_blocks_hor_ver_luma_avx2
	mov	r9d, 40					; 00000028H
	lea	r8, OFFSET FLAT:$SG4294948658
	mov	QWORD PTR [rsp+32], rax
	lea	rdx, OFFSET FLAT:$SG4294948657
	mov	rsi, rcx
	call	kvz_strategyselector_register
	mov	ebx, eax

; 1254 :     success &= kvz_strategyselector_register(opaque, "filter_hpel_blocks_diag_luma", "avx2", 40, &kvz_filter_hpel_blocks_diag_luma_avx2);

	lea	r8, OFFSET FLAT:$SG4294948656
	lea	rax, OFFSET FLAT:kvz_filter_hpel_blocks_diag_luma_avx2
	mov	r9d, 40					; 00000028H
	lea	rdx, OFFSET FLAT:$SG4294948655
	mov	QWORD PTR [rsp+32], rax
	mov	rcx, rsi
	and	ebx, 1
	call	kvz_strategyselector_register
	mov	edi, eax

; 1255 :     success &= kvz_strategyselector_register(opaque, "filter_qpel_blocks_hor_ver_luma", "avx2", 40, &kvz_filter_qpel_blocks_hor_ver_luma_avx2);

	lea	r8, OFFSET FLAT:$SG4294948654
	lea	rax, OFFSET FLAT:kvz_filter_qpel_blocks_hor_ver_luma_avx2
	mov	r9d, 40					; 00000028H
	lea	rdx, OFFSET FLAT:$SG4294948653
	mov	QWORD PTR [rsp+32], rax
	mov	rcx, rsi
	and	edi, ebx
	call	kvz_strategyselector_register
	mov	ebx, eax

; 1256 :     success &= kvz_strategyselector_register(opaque, "filter_qpel_blocks_diag_luma", "avx2", 40, &kvz_filter_qpel_blocks_diag_luma_avx2);

	lea	r8, OFFSET FLAT:$SG4294948652
	lea	rax, OFFSET FLAT:kvz_filter_qpel_blocks_diag_luma_avx2
	mov	r9d, 40					; 00000028H
	lea	rdx, OFFSET FLAT:$SG4294948651
	mov	QWORD PTR [rsp+32], rax
	mov	rcx, rsi
	and	ebx, edi
	call	kvz_strategyselector_register
	mov	edi, eax

; 1257 :     success &= kvz_strategyselector_register(opaque, "sample_quarterpel_luma", "avx2", 40, &kvz_sample_quarterpel_luma_avx2);

	lea	r8, OFFSET FLAT:$SG4294948650
	lea	rax, OFFSET FLAT:kvz_sample_quarterpel_luma_avx2
	mov	r9d, 40					; 00000028H
	lea	rdx, OFFSET FLAT:$SG4294948649
	mov	QWORD PTR [rsp+32], rax
	mov	rcx, rsi
	and	edi, ebx
	call	kvz_strategyselector_register
	mov	ebx, eax

; 1258 :     success &= kvz_strategyselector_register(opaque, "sample_octpel_chroma", "avx2", 40, &kvz_sample_octpel_chroma_avx2);

	lea	r8, OFFSET FLAT:$SG4294948648
	lea	rax, OFFSET FLAT:kvz_sample_octpel_chroma_avx2
	mov	r9d, 40					; 00000028H
	lea	rdx, OFFSET FLAT:$SG4294948647
	mov	QWORD PTR [rsp+32], rax
	mov	rcx, rsi
	and	ebx, edi
	call	kvz_strategyselector_register
	mov	edi, eax

; 1259 :     success &= kvz_strategyselector_register(opaque, "sample_quarterpel_luma_hi", "avx2", 40, &kvz_sample_quarterpel_luma_hi_avx2);

	lea	r8, OFFSET FLAT:$SG4294948646
	lea	rax, OFFSET FLAT:kvz_sample_quarterpel_luma_hi_avx2
	mov	r9d, 40					; 00000028H
	lea	rdx, OFFSET FLAT:$SG4294948645
	mov	QWORD PTR [rsp+32], rax
	mov	rcx, rsi
	and	edi, ebx
	call	kvz_strategyselector_register
	mov	ebx, eax

; 1260 :     success &= kvz_strategyselector_register(opaque, "sample_octpel_chroma_hi", "avx2", 40, &kvz_sample_octpel_chroma_hi_avx2);

	lea	r8, OFFSET FLAT:$SG4294948644
	lea	rax, OFFSET FLAT:kvz_sample_octpel_chroma_hi_avx2
	mov	r9d, 40					; 00000028H
	lea	rdx, OFFSET FLAT:$SG4294948643
	mov	QWORD PTR [rsp+32], rax
	mov	rcx, rsi
	and	ebx, edi
	call	kvz_strategyselector_register

; 1261 :   }
; 1262 : #endif //COMPILE_INTEL_AVX2 && defined X86_64
; 1263 :   return success;
; 1264 : }

	mov	rsi, QWORD PTR [rsp+72]
	and	eax, ebx
	mov	rbx, QWORD PTR [rsp+64]
	add	rsp, 48					; 00000030H
	pop	rdi
	ret	0
kvz_strategy_register_ipol_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
filter$ = 8
data$ = 16
kvz_eight_tap_filter_hor_avx2 PROC

; 58   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);
; 59   :   __m128i row = _mm_loadl_epi64((__m128i*)data);

	vmovq	xmm1, QWORD PTR [rdx]
	vmovq	xmm0, QWORD PTR [rcx]

; 60   :   __m128i acc;
; 61   :   acc = _mm_maddubs_epi16(row, fir);

	vpmaddubsw xmm2, xmm1, xmm0

; 62   :   __m128i temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm2, 4

; 63   :   acc = _mm_add_epi16(acc, temp);

	vpaddw	xmm3, xmm1, xmm2

; 64   :   temp = _mm_srli_si128(acc, 2);

	vpsrldq	xmm0, xmm3, 2

; 65   :   acc = _mm_add_epi16(acc, temp);

	vpaddw	xmm1, xmm0, xmm3

; 66   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm1

; 67   : 
; 68   :   return filtered;
; 69   : }

	ret	0
kvz_eight_tap_filter_hor_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
filter$ = 8
data$ = 16
kvz_eight_tap_filter_hor_16bit_avx2 PROC

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [rcx]

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 75   :   __m128i row = _mm_loadu_si128((__m128i*)data);
; 76   :   __m128i acc;
; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [rdx]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 83   : 
; 84   :   return filtered;
; 85   : }

	ret	0
kvz_eight_tap_filter_hor_16bit_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
filter$ = 96
data$ = 104
stride$dead$ = 112
out$ = 120
kvz_eight_tap_filter_ver_16bit_1x8_avx2 PROC

; 88   : {

	mov	rax, rsp
	sub	rsp, 88					; 00000058H

; 89   :   // Interpolation filter shifts
; 90   :   int32_t shift2 = 6;
; 91   : 
; 92   :   // Weighted prediction offset and shift
; 93   :   int32_t wp_shift1 = 14 - KVZ_BIT_DEPTH;
; 94   :   int32_t wp_offset1 = 1 << (wp_shift1 - 1);
; 95   : 
; 96   :   // Filter weights
; 97   :   __m256i all_taps = _mm256_castsi128_si256(_mm_cvtepi8_epi16(_mm_loadl_epi64((__m128i*)filter)));

	vmovq	xmm0, QWORD PTR [rcx]
	vpmovsxbw xmm3, xmm0

; 98   :   __m256i taps_01_23 = _mm256_shuffle_epi32(all_taps, _MM_SHUFFLE(0, 0, 0, 0));
; 99   :   __m128i taps_23 = _mm_shuffle_epi32(_mm256_castsi256_si128(all_taps), _MM_SHUFFLE(1, 1, 1, 1));

	vpshufd	xmm1, xmm3, 85				; 00000055H
	vpshufd	ymm0, ymm3, 0
	vmovaps	XMMWORD PTR [rax-24], xmm6

; 100  :   __m256i taps_45_67 = _mm256_shuffle_epi32(all_taps, _MM_SHUFFLE(2, 2, 2, 2));
; 101  :   __m128i taps_67 = _mm_shuffle_epi32(_mm256_castsi256_si128(all_taps), _MM_SHUFFLE(3, 3, 3, 3));

	vpshufd	xmm2, xmm3, 255				; 000000ffH
	vmovaps	XMMWORD PTR [rax-40], xmm7
	vmovaps	XMMWORD PTR [rax-56], xmm8
	vmovaps	XMMWORD PTR [rax-72], xmm9
	vmovaps	XMMWORD PTR [rsp], xmm10

; 102  : 
; 103  :   taps_01_23 = _mm256_inserti128_si256(taps_01_23, taps_23, 1);

	vinserti128 ymm10, ymm0, xmm1, 1

; 104  :   taps_45_67 = _mm256_inserti128_si256(taps_45_67, taps_67, 1);
; 105  : 
; 106  :   __m256i rows02 = _mm256_castsi128_si256(_mm_loadu_si128((__m128i*)&data[0 * stride]));

	vmovups	xmm1, XMMWORD PTR [rdx]

; 107  :   __m128i row2 = _mm_loadu_si128((__m128i*)&data[2 * stride]);
; 108  :   rows02 = _mm256_inserti128_si256(rows02, row2, 1);

	vinserti128 ymm7, ymm1, XMMWORD PTR [rdx+256], 1

; 109  : 
; 110  :   __m256i rows13 = _mm256_castsi128_si256(_mm_loadu_si128((__m128i*)&data[1 * stride]));
; 111  :   __m128i row3 = _mm_loadu_si128((__m128i*)&data[3 * stride]);
; 112  :   rows13 = _mm256_inserti128_si256(rows13, row3, 1);
; 113  : 
; 114  :   __m256i pairs_01_23_lo = _mm256_unpacklo_epi16(rows02, rows13);
; 115  :   __m256i pairs_01_23_hi = _mm256_unpackhi_epi16(rows02, rows13);
; 116  :   __m256i temp_01_23_lo = _mm256_madd_epi16(pairs_01_23_lo, taps_01_23);
; 117  :   __m256i temp_01_23_hi = _mm256_madd_epi16(pairs_01_23_hi, taps_01_23);
; 118  : 
; 119  :   __m256i rows46 = _mm256_castsi128_si256(_mm_loadu_si128((__m128i*)&data[4 * stride]));

	vmovups	xmm1, XMMWORD PTR [rdx+512]

; 120  :   __m128i row6 = _mm_loadu_si128((__m128i*)&data[6 * stride]);
; 121  :   rows46 = _mm256_inserti128_si256(rows46, row6, 1);

	vinserti128 ymm5, ymm1, XMMWORD PTR [rdx+768], 1
	vpshufd	ymm0, ymm3, 170				; 000000aaH
	vinserti128 ymm8, ymm0, xmm2, 1
	vmovups	xmm0, XMMWORD PTR [rdx+128]
	vinserti128 ymm6, ymm0, XMMWORD PTR [rdx+384], 1

; 122  : 
; 123  :   __m256i rows57 = _mm256_castsi128_si256(_mm_loadu_si128((__m128i*)&data[5 * stride]));

	vmovups	xmm0, XMMWORD PTR [rdx+640]

; 124  :   __m128i row7 = _mm_loadu_si128((__m128i*)&data[7 * stride]);
; 125  :   rows57 = _mm256_inserti128_si256(rows57, row7, 1);

	vinserti128 ymm4, ymm0, XMMWORD PTR [rdx+896], 1

; 126  : 
; 127  :   __m256i pairs_45_67_lo = _mm256_unpacklo_epi16(rows46, rows57);

	vpunpcklwd ymm0, ymm5, ymm4

; 128  :   __m256i pairs_45_67_hi = _mm256_unpackhi_epi16(rows46, rows57);
; 129  :   __m256i temp_45_67_lo = _mm256_madd_epi16(pairs_45_67_lo, taps_45_67);

	vpmaddwd ymm2, ymm0, ymm8
	vpunpcklwd ymm1, ymm7, ymm6
	vpmaddwd ymm3, ymm1, ymm10

; 130  :   __m256i temp_45_67_hi = _mm256_madd_epi16(pairs_45_67_hi, taps_45_67);
; 131  : 
; 132  :   __m256i sum_lo_half = _mm256_add_epi32(temp_01_23_lo, temp_45_67_lo);

	vpaddd	ymm9, ymm2, ymm3
	vpunpckhwd ymm1, ymm5, ymm4
	vpmaddwd ymm2, ymm1, ymm8
	vpunpckhwd ymm0, ymm7, ymm6
	vpmaddwd ymm3, ymm0, ymm10

; 133  :   __m256i sum_hi_half = _mm256_add_epi32(temp_01_23_hi, temp_45_67_hi);

	vpaddd	ymm4, ymm2, ymm3

; 134  : 
; 135  :   __m128i sum_lo = _mm_add_epi32(_mm256_castsi256_si128(sum_lo_half), _mm256_extracti128_si256(sum_lo_half, 1));
; 136  :   __m128i sum_hi = _mm_add_epi32(_mm256_castsi256_si128(sum_hi_half), _mm256_extracti128_si256(sum_hi_half, 1));

	vextracti128 xmm0, ymm4, 1
	vpaddd	xmm0, xmm0, xmm4

; 137  : 
; 138  :   sum_lo = _mm_srai_epi32(sum_lo, shift2);
; 139  :   sum_hi = _mm_srai_epi32(sum_hi, shift2);

	vpsrad	xmm1, xmm0, 6

; 140  : 
; 141  :   __m128i offset = _mm_set1_epi32(wp_offset1);
; 142  :   sum_lo = _mm_add_epi32(sum_lo, offset);
; 143  :   sum_lo = _mm_srai_epi32(sum_lo, wp_shift1);
; 144  :   sum_hi = _mm_add_epi32(sum_hi, offset);

	vpaddd	xmm2, xmm1, XMMWORD PTR __xmm@00000020000000200000002000000020

; 145  :   sum_hi = _mm_srai_epi32(sum_hi, wp_shift1);

	vpsrad	xmm4, xmm2, 6
	vextracti128 xmm0, ymm9, 1
	vpaddd	xmm0, xmm0, xmm9
	vpsrad	xmm1, xmm0, 6
	vpaddd	xmm2, xmm1, XMMWORD PTR __xmm@00000020000000200000002000000020
	vpsrad	xmm3, xmm2, 6

; 146  :   __m128i filtered = _mm_packus_epi32(sum_lo, sum_hi);

	vpackusdw xmm0, xmm3, xmm4

; 147  :   filtered = _mm_packus_epi16(filtered, filtered);

	vpackuswb xmm1, xmm0, xmm0

; 148  : 
; 149  : 
; 150  :   _mm_storel_epi64((__m128i*)out, filtered);

	vmovq	QWORD PTR [r9], xmm1
	vzeroupper

; 151  : }

	vmovaps	xmm6, XMMWORD PTR [rax-24]
	vmovaps	xmm7, XMMWORD PTR [rax-40]
	vmovaps	xmm8, XMMWORD PTR [rax-56]
	vmovaps	xmm9, XMMWORD PTR [rax-72]
	vmovaps	xmm10, XMMWORD PTR [rsp]
	add	rsp, 88					; 00000058H
	ret	0
kvz_eight_tap_filter_ver_16bit_1x8_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
tv1393 = 192
filter$ = 192
width$ = 200
height$ = 208
src$ = 216
tv1397 = 224
src_stride$ = 224
dst$ = 232
dst_stride$dead$ = 240
kvz_ipol_8tap_hor_px_im_avx2 PROC

; 159  :   int16_t dst_stride) {

	mov	rax, rsp
	mov	QWORD PTR [rax+32], r9
	push	rdi
	push	r13
	push	r14
	push	r15
	sub	rsp, 152				; 00000098H

; 161  :                                     0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8);
; 162  :   __m256i shuf23 = _mm256_setr_epi8(2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10,
; 163  :                                     2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10);
; 164  :   __m256i shuf45 = _mm256_setr_epi8(4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12,
; 165  :                                     4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12);
; 166  :   __m256i shuf67 = _mm256_setr_epi8(6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14,
; 167  :                                     6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14);
; 168  : 
; 169  :   __m256i all_w01 = _mm256_set1_epi16(*(uint16_t *)(filter + 0));
; 170  :   __m256i all_w23 = _mm256_set1_epi16(*(uint16_t *)(filter + 2));
; 171  :   __m256i all_w45 = _mm256_set1_epi16(*(uint16_t *)(filter + 4));
; 172  :   __m256i all_w67 = _mm256_set1_epi16(*(uint16_t *)(filter + 6));
; 173  : 
; 174  :   int y_offset = -KVZ_LUMA_FILTER_OFFSET;
; 175  :   int x_offset = -KVZ_LUMA_FILTER_OFFSET;
; 176  : 
; 177  :   kvz_pixel *top_left = src + src_stride * y_offset + x_offset;

	movsx	r15, WORD PTR src_stride$[rsp]

; 178  : 
; 179  :   int y = 0;
; 180  :   int x = 0;
; 181  : 
; 182  :   for (y = 0; y < height + KVZ_EXT_PADDING_LUMA; y += 2) {

	lea	edi, DWORD PTR [r8+7]
	mov	r13, QWORD PTR dst$[rsp]
	xor	r11d, r11d
	vmovaps	XMMWORD PTR [rax-56], xmm6
	mov	r14, r9
	vmovaps	XMMWORD PTR [rax-72], xmm7
	mov	r9d, r11d
	vmovaps	XMMWORD PTR [rax-88], xmm8
	vmovaps	XMMWORD PTR [rax-104], xmm9
	vmovaps	XMMWORD PTR [rax-120], xmm10
	vmovaps	XMMWORD PTR [rsp+48], xmm11
	vmovdqu	ymm11, YMMWORD PTR __ymm@0807070606050504040303020201010008070706060505040403030202010100
	vmovaps	XMMWORD PTR [rsp+32], xmm12
	vmovdqu	ymm12, YMMWORD PTR __ymm@0a0909080807070606050504040303020a090908080707060605050404030302
	vmovaps	XMMWORD PTR [rsp+16], xmm13
	vmovdqu	ymm13, YMMWORD PTR __ymm@0c0b0b0a0a09090808070706060505040c0b0b0a0a0909080807070606050504
	vmovaps	XMMWORD PTR [rsp], xmm14
	vmovdqu	ymm14, YMMWORD PTR __ymm@0e0d0d0c0c0b0b0a0a090908080707060e0d0d0c0c0b0b0a0a09090808070706
	mov	QWORD PTR [rax+16], rbx
	mov	ebx, edx
	movsx	eax, WORD PTR [rcx]
	vmovd	xmm7, eax
	movsx	eax, WORD PTR [rcx+2]
	vmovd	xmm8, eax
	movsx	eax, WORD PTR [rcx+4]
	vmovd	xmm9, eax
	movsx	eax, WORD PTR [rcx+6]
	mov	ecx, r15d
	vmovd	xmm10, eax
	imul	eax, r15d, -3
	vpbroadcastw ymm7, xmm7
	vpbroadcastw ymm8, xmm8
	vpbroadcastw ymm9, xmm9
	vpbroadcastw ymm10, xmm10
	movsxd	rdx, eax
	mov	QWORD PTR tv1393[rsp], rdx
	test	edi, edi
	jle	$LN3@kvz_ipol_8

; 160  :   __m256i shuf01 = _mm256_setr_epi8(0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8,

	lea	r8, QWORD PTR [r14-3]
	mov	QWORD PTR [rsp+208], rsi
	lea	r14d, DWORD PTR [rdi-1]
	mov	QWORD PTR [rsp+144], r12
	shr	r14d, 1
	lea	eax, DWORD PTR [r15+r15]
	add	r8, rdx
	movsxd	r12, eax
	inc	r14d
	lea	r10, QWORD PTR [r13+128]
	mov	esi, r11d
$LL4@kvz_ipol_8:

; 183  : 
; 184  :     for (x = 0; x + 7 < width; x += 8) {

	mov	r9d, r11d
	cmp	ebx, 7
	jle	SHORT $LN2@kvz_ipol_8
	mov	edx, 7
	mov	rax, r10
	mov	rcx, r8
	npad	5
$LL7@kvz_ipol_8:

; 185  : 
; 186  :       kvz_pixel *chunk_ptr = top_left + src_stride * y + x;
; 187  :       __m128i r0 = _mm_loadu_si128((__m128i*)(chunk_ptr + 0 * src_stride));
; 188  :       __m128i r1 = _mm_loadu_si128((__m128i*)(chunk_ptr + 1 * src_stride));
; 189  :       __m256i r0_r1 = _mm256_castsi128_si256(r0);

	vmovups	xmm0, XMMWORD PTR [rcx]

; 190  :       r0_r1 = _mm256_inserti128_si256(r0_r1, r1, 1);

	vinserti128 ymm6, ymm0, XMMWORD PTR [rcx+r15], 1

; 191  : 
; 192  :       __m256i r0_r1_01 = _mm256_shuffle_epi8(r0_r1, shuf01);

	vpshufb	ymm1, ymm6, ymm11

; 193  :       __m256i r0_r1_23 = _mm256_shuffle_epi8(r0_r1, shuf23);
; 194  :       __m256i r0_r1_45 = _mm256_shuffle_epi8(r0_r1, shuf45);
; 195  :       __m256i r0_r1_67 = _mm256_shuffle_epi8(r0_r1, shuf67);
; 196  : 
; 197  :       __m256i dot01 = _mm256_maddubs_epi16(r0_r1_01, all_w01);

	vpmaddubsw ymm3, ymm1, ymm7
	vpshufb	ymm0, ymm6, ymm12

; 198  :       __m256i dot23 = _mm256_maddubs_epi16(r0_r1_23, all_w23);

	vpmaddubsw ymm2, ymm0, ymm8
	vpshufb	ymm1, ymm6, ymm13

; 199  :       __m256i dot45 = _mm256_maddubs_epi16(r0_r1_45, all_w45);
; 200  :       __m256i dot67 = _mm256_maddubs_epi16(r0_r1_67, all_w67);
; 201  : 
; 202  :       __m256i sum0123 = _mm256_add_epi16(dot01, dot23);

	vpaddw	ymm5, ymm2, ymm3
	vpshufb	ymm0, ymm6, ymm14
	vpmaddubsw ymm4, ymm1, ymm9
	vpmaddubsw ymm2, ymm0, ymm10

; 203  :       __m256i sum4567 = _mm256_add_epi16(dot45, dot67);

	vpaddw	ymm1, ymm2, ymm4

; 204  :       __m256i sum = _mm256_add_epi16(sum0123, sum4567);

	vpaddw	ymm3, ymm1, ymm5

; 205  : 
; 206  :       __m128i *dst_r0 = (__m128i*)(dst + (y + 0) * dst_stride + x);
; 207  :       __m128i *dst_r1 = (__m128i*)(dst + (y + 1) * dst_stride + x);
; 208  :       __m128i sum_r0 = _mm256_castsi256_si128(sum);
; 209  :       __m128i sum_r1 = _mm256_extracti128_si256(sum, 1);
; 210  :       _mm_storeu_si128(dst_r0, sum_r0);

	vmovdqu	XMMWORD PTR [rax-128], xmm3
	add	r9d, 8
	add	edx, 8
	vextracti128 XMMWORD PTR [rax], ymm3, 1
	lea	rax, QWORD PTR [rax+16]
	lea	rcx, QWORD PTR [rcx+8]
	cmp	edx, ebx
	jl	SHORT $LL7@kvz_ipol_8
$LN2@kvz_ipol_8:

; 178  : 
; 179  :   int y = 0;
; 180  :   int x = 0;
; 181  : 
; 182  :   for (y = 0; y < height + KVZ_EXT_PADDING_LUMA; y += 2) {

	add	r8, r12
	add	r10, 256				; 00000100H
	sub	rsi, -128				; ffffffffffffff80H
	sub	r14, 1
	jne	$LL4@kvz_ipol_8
	mov	r14, QWORD PTR src$[rsp]
	mov	r12, QWORD PTR [rsp+144]
	mov	ecx, r15d
	mov	rsi, QWORD PTR [rsp+208]
$LN3@kvz_ipol_8:

; 211  :       _mm_storeu_si128(dst_r1, sum_r1);
; 212  :     }
; 213  :   }
; 214  : 
; 215  :   if (x < width) {

	cmp	r9d, ebx
	mov	rbx, QWORD PTR [rsp+200]
	jge	$LN9@kvz_ipol_8

; 216  :     for (int y = 0; y < height + KVZ_EXT_PADDING_LUMA; y += 2) {

	test	edi, edi
	jle	$LN9@kvz_ipol_8
	lea	eax, DWORD PTR [rcx+rcx]
	movsxd	rdx, r9d
	movsxd	r10, eax
	lea	rcx, QWORD PTR [r14-3]
	mov	rax, QWORD PTR tv1393[rsp]
	lea	r8d, DWORD PTR [rdi-1]
	add	rax, rdx
	shr	r8d, 1
	add	rcx, rax
	inc	r8d
	npad	2
$LL10@kvz_ipol_8:

; 217  : 
; 218  :       kvz_pixel *chunk_ptr = top_left + src_stride * y + x;
; 219  :       __m128i r0 = _mm_loadu_si128((__m128i *)(chunk_ptr + 0 * src_stride));
; 220  :       __m128i r1 = _mm_loadu_si128((__m128i *)(chunk_ptr + 1 * src_stride));
; 221  :       __m256i r0_r1 = _mm256_castsi128_si256(r0);

	vmovups	xmm0, XMMWORD PTR [rcx]

; 222  :       r0_r1 = _mm256_inserti128_si256(r0_r1, r1, 1);

	vinserti128 ymm6, ymm0, XMMWORD PTR [r15+rcx], 1

; 223  : 
; 224  :       __m256i r0_r1_01 = _mm256_shuffle_epi8(r0_r1, shuf01);
; 225  :       __m256i r0_r1_23 = _mm256_shuffle_epi8(r0_r1, shuf23);
; 226  :       __m256i r0_r1_45 = _mm256_shuffle_epi8(r0_r1, shuf45);
; 227  :       __m256i r0_r1_67 = _mm256_shuffle_epi8(r0_r1, shuf67);
; 228  : 
; 229  :       __m256i dot01 = _mm256_maddubs_epi16(r0_r1_01, all_w01);
; 230  :       __m256i dot23 = _mm256_maddubs_epi16(r0_r1_23, all_w23);
; 231  :       __m256i dot45 = _mm256_maddubs_epi16(r0_r1_45, all_w45);
; 232  :       __m256i dot67 = _mm256_maddubs_epi16(r0_r1_67, all_w67);
; 233  : 
; 234  :       __m256i sum0123 = _mm256_add_epi16(dot01, dot23);
; 235  :       __m256i sum4567 = _mm256_add_epi16(dot45, dot67);
; 236  :       __m256i sum = _mm256_add_epi16(sum0123, sum4567);
; 237  : 
; 238  :       __m128i *dst_r0 = (__m128i*)(dst + (y + 0) * dst_stride + x);

	lea	rax, QWORD PTR [rdx+r11]
	add	rcx, r10
	vpshufb	ymm1, ymm6, ymm11
	vpmaddubsw ymm3, ymm1, ymm7
	vpshufb	ymm0, ymm6, ymm12
	vpmaddubsw ymm2, ymm0, ymm8
	vpshufb	ymm1, ymm6, ymm13
	vpshufb	ymm0, ymm6, ymm14
	vpaddw	ymm5, ymm2, ymm3
	vpmaddubsw ymm2, ymm0, ymm10
	vpmaddubsw ymm4, ymm1, ymm9
	vpaddw	ymm1, ymm2, ymm4
	vpaddw	ymm3, ymm1, ymm5

; 239  :       __m128i *dst_r1 = (__m128i*)(dst + (y + 1) * dst_stride + x);
; 240  :       __m128i sum_r0 = _mm256_castsi256_si128(sum);
; 241  :       __m128i sum_r1 = _mm256_extracti128_si256(sum, 1);
; 242  :       _mm_storel_epi64(dst_r0, sum_r0);

	vmovq	QWORD PTR [r13+rax*2], xmm3
	lea	rax, QWORD PTR [rdx+r11]
	lea	r11, QWORD PTR [r11+128]
	vextracti128 xmm0, ymm3, 1

; 243  :       _mm_storel_epi64(dst_r1, sum_r1);

	vmovq	QWORD PTR [r13+rax*2+128], xmm0
	sub	r8, 1
	jne	SHORT $LL10@kvz_ipol_8
$LN9@kvz_ipol_8:
	vzeroupper

; 244  :     }
; 245  :   }
; 246  : }

	vmovaps	xmm7, XMMWORD PTR [rsp+112]
	lea	r11, QWORD PTR [rsp+152]
	vmovaps	xmm6, XMMWORD PTR [r11-24]
	vmovaps	xmm8, XMMWORD PTR [r11-56]
	vmovaps	xmm9, XMMWORD PTR [r11-72]
	vmovaps	xmm10, XMMWORD PTR [r11-88]
	vmovaps	xmm11, XMMWORD PTR [r11-104]
	vmovaps	xmm12, XMMWORD PTR [r11-120]
	vmovaps	xmm13, XMMWORD PTR [rsp+16]
	vmovaps	xmm14, XMMWORD PTR [rsp]
	mov	rsp, r11
	pop	r15
	pop	r14
	pop	r13
	pop	rdi
	ret	0
kvz_ipol_8tap_hor_px_im_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
filter$ = 144
width$ = 152
height$ = 160
src$ = 168
src_stride$dead$ = 176
dst$ = 184
dst_stride$ = 192
kvz_ipol_8tap_ver_im_px_avx2 PROC

; 255  : {

	mov	r11, rsp
	mov	QWORD PTR [r11+32], rsi
	push	rdi
	sub	rsp, 128				; 00000080H

; 256  :   // Interpolation filter shifts
; 257  :   int32_t shift2 = 6;
; 258  : 
; 259  :   // Weighted prediction offset and shift
; 260  :   int32_t wp_shift1 = 14 - KVZ_BIT_DEPTH;
; 261  :   int32_t wp_offset1 = 1 << (wp_shift1 - 1);
; 262  : 
; 263  :   __m128i weights_8b = _mm_set1_epi64x(*(uint64_t *)filter);

	vpbroadcastq xmm0, QWORD PTR [rcx]
	vmovaps	XMMWORD PTR [r11-88], xmm10
	mov	rax, r9

; 264  :   __m256i weights_16b = _mm256_cvtepi8_epi16(weights_8b);

	vpmovsxbw ymm1, xmm0
	vmovaps	XMMWORD PTR [r11-104], xmm11

; 265  :   __m256i all_w01 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(0, 0, 0, 0));
; 266  :   __m256i all_w23 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(1, 1, 1, 1));
; 267  :   __m256i all_w45 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(2, 2, 2, 2));
; 268  :   __m256i all_w67 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(3, 3, 3, 3));
; 269  : 
; 270  :   for (int x = 0; x + 3 < width; x += 4) {

	xor	r9d, r9d
	vmovaps	XMMWORD PTR [r11-120], xmm12
	mov	edi, r8d
	vmovaps	XMMWORD PTR [rsp], xmm13
	mov	esi, edx
	vpshufd	ymm10, ymm1, 0
	vpshufd	ymm11, ymm1, 85				; 00000055H
	vpshufd	ymm12, ymm1, 170			; 000000aaH
	vpshufd	ymm13, ymm1, 255			; 000000ffH
	cmp	edx, 3
	jle	$LN3@kvz_ipol_8
	mov	QWORD PTR [r11+8], rbx
	add	rax, 256				; 00000100H
	mov	QWORD PTR [r11+16], r14
	movsx	r14d, WORD PTR dst_stride$[rsp]
	mov	QWORD PTR [r11+24], r15
	mov	r15, QWORD PTR dst$[rsp]
	vmovaps	XMMWORD PTR [rsp+112], xmm6
	vmovaps	XMMWORD PTR [rsp+96], xmm7
	vmovaps	XMMWORD PTR [r11-56], xmm8
	vmovaps	XMMWORD PTR [r11-72], xmm9
$LL4@kvz_ipol_8:

; 273  : 
; 274  :     // Initial values
; 275  :     // Broadcasted rows in both lanes
; 276  :     // __m256i r0; // Unused
; 277  :     // __m256i r1; // Unused
; 278  :     __m256i r2 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 0 * src_stride));
; 279  :     __m256i r3 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 1 * src_stride));

	vpbroadcastq ymm2, QWORD PTR [rax-128]

; 280  :     __m256i r4 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 2 * src_stride));

	vpbroadcastq ymm6, QWORD PTR [rax]
	vpbroadcastq ymm0, QWORD PTR [rax-256]

; 281  :     __m256i r5 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 3 * src_stride));

	vpbroadcastq ymm4, QWORD PTR [rax+128]

; 282  :     __m256i r6 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 4 * src_stride));

	vpbroadcastq ymm5, QWORD PTR [rax+256]

; 283  :     __m256i r7 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 5 * src_stride));

	vpbroadcastq ymm3, QWORD PTR [rax+384]

; 284  :     __m256i r8 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 6 * src_stride));

	vpbroadcastq ymm7, QWORD PTR [rax+512]

; 285  : 
; 286  :     // Consecutive rows in low and high lanes
; 287  :     // __m256i r0_r1; // Unused
; 288  :     // __m256i r1_r2; // Unused
; 289  :     __m256i r2_r3 = _mm256_blend_epi32(r2, r3, 0xF0);

	vpblendd ymm1, ymm0, ymm2, 240			; 000000f0H

; 290  :     __m256i r3_r4 = _mm256_blend_epi32(r3, r4, 0xF0);

	vpblendd ymm0, ymm2, ymm6, 240			; 000000f0H

; 291  :     __m256i r4_r5 = _mm256_blend_epi32(r4, r5, 0xF0);
; 292  :     __m256i r5_r6 = _mm256_blend_epi32(r5, r6, 0xF0);
; 293  :     __m256i r6_r7 = _mm256_blend_epi32(r6, r7, 0xF0);
; 294  :     __m256i r7_r8 = _mm256_blend_epi32(r7, r8, 0xF0);
; 295  : 
; 296  :     // Paired samples of consecutive rows
; 297  :     __m256i r01_r12;
; 298  :     __m256i r23_r34 = _mm256_unpacklo_epi16(r2_r3, r3_r4);

	vpunpcklwd ymm8, ymm1, ymm0
	vpblendd ymm0, ymm6, ymm4, 240			; 000000f0H
	vpblendd ymm2, ymm4, ymm5, 240			; 000000f0H

; 299  :     __m256i r45_r56 = _mm256_unpacklo_epi16(r4_r5, r5_r6);

	vpunpcklwd ymm6, ymm0, ymm2
	vpblendd ymm0, ymm5, ymm3, 240			; 000000f0H
	vpblendd ymm1, ymm3, ymm7, 240			; 000000f0H

; 300  :     __m256i r67_r78 = _mm256_unpacklo_epi16(r6_r7, r7_r8);

	vpunpcklwd ymm9, ymm0, ymm1

; 301  : 
; 302  :     for (int y = 0; y < height; y += 2) {

	test	edi, edi
	jle	$LN2@kvz_ipol_8

; 271  : 
; 272  :     int16_t *strip_ptr = src + 0 * src_stride + x;

	vmovdqu	ymm5, YMMWORD PTR __ymm@0000002000000020000000200000002000000020000000200000002000000020
	movsxd	rdx, r9d
	lea	ecx, DWORD PTR [r14+r14]
	movsxd	rbx, ecx
	lea	r11, QWORD PTR [rax+768]
	lea	ecx, DWORD PTR [r14+r9]
	movsxd	r8, ecx
	sub	r8, rdx
	lea	r10, QWORD PTR [rdx+r15]
	lea	edx, DWORD PTR [rdi-1]
	shr	edx, 1
	inc	edx
$LL7@kvz_ipol_8:

; 303  : 
; 304  :       strip_ptr = src + y * src_stride + x;
; 305  : 
; 306  :       // Slide window
; 307  :       r01_r12 = r23_r34;
; 308  :       r23_r34 = r45_r56;
; 309  :       r45_r56 = r67_r78;
; 310  :       r6 = r8;
; 311  :       r7 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 7 * src_stride));

	vpbroadcastq ymm0, QWORD PTR [r11-128]
	vmovdqu	ymm2, ymm7

; 312  :       r8 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 8 * src_stride));

	vpbroadcastq ymm7, QWORD PTR [r11]

; 313  :       r6_r7 = _mm256_blend_epi32(r6, r7, 0xF0);
; 314  :       r7_r8 = _mm256_blend_epi32(r7, r8, 0xF0);

	vpblendd ymm1, ymm0, ymm7, 240			; 000000f0H
	vpblendd ymm0, ymm2, ymm0, 240			; 000000f0H
	vmovdqu	ymm3, ymm8
	vmovdqu	ymm8, ymm6
	vmovdqu	ymm6, ymm9

; 315  : 
; 316  :       r67_r78 = _mm256_unpacklo_epi16(r6_r7, r7_r8);

	vpunpcklwd ymm9, ymm0, ymm1

; 317  : 
; 318  :       __m256i dot01 = _mm256_madd_epi16(r01_r12, all_w01);

	vpmaddwd ymm0, ymm3, ymm10

; 319  :       __m256i dot23 = _mm256_madd_epi16(r23_r34, all_w23);

	vpmaddwd ymm2, ymm8, ymm11

; 320  :       __m256i dot45 = _mm256_madd_epi16(r45_r56, all_w45);
; 321  :       __m256i dot67 = _mm256_madd_epi16(r67_r78, all_w67);
; 322  : 
; 323  :       __m256i sum0123 = _mm256_add_epi32(dot01, dot23);

	vpaddd	ymm4, ymm0, ymm2
	vpmaddwd ymm3, ymm6, ymm12
	vpmaddwd ymm1, ymm9, ymm13

; 324  :       __m256i sum4567 = _mm256_add_epi32(dot45, dot67);

	vpaddd	ymm0, ymm1, ymm3

; 325  :       __m256i sum = _mm256_add_epi32(sum0123, sum4567);

	vpaddd	ymm2, ymm0, ymm4

; 326  :       sum = _mm256_srai_epi32(sum, shift2);

	vpsrad	ymm3, ymm2, 6

; 327  :       sum = _mm256_add_epi32(sum, _mm256_set1_epi32(wp_offset1));

	vpaddd	ymm1, ymm3, ymm5

; 328  :       sum = _mm256_srai_epi32(sum, wp_shift1);

	vpsrad	ymm0, ymm1, 6

; 329  :       sum = _mm256_packs_epi32(sum, sum);

	vpackssdw ymm2, ymm0, ymm0

; 330  :       sum = _mm256_packus_epi16(sum, sum);

	vpackuswb ymm1, ymm2, ymm2

; 331  : 
; 332  :       kvz_pixel *dst_addr0 = &dst[(y + 0) * dst_stride + x];
; 333  :       kvz_pixel *dst_addr1 = &dst[(y + 1) * dst_stride + x];
; 334  :       *(uint32_t*)dst_addr0 = _mm_cvtsi128_si32(_mm256_castsi256_si128(sum));

	vmovd	DWORD PTR [r10], xmm1

; 335  :       *(uint32_t*)dst_addr1 = _mm_cvtsi128_si32(_mm256_extracti128_si256(sum, 1));

	vextracti128 xmm0, ymm1, 1
	vmovd	DWORD PTR [r10+r8], xmm0
	add	r10, rbx
	lea	r11, QWORD PTR [r11+256]
	sub	rdx, 1
	jne	$LL7@kvz_ipol_8
$LN2@kvz_ipol_8:

; 265  :   __m256i all_w01 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(0, 0, 0, 0));
; 266  :   __m256i all_w23 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(1, 1, 1, 1));
; 267  :   __m256i all_w45 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(2, 2, 2, 2));
; 268  :   __m256i all_w67 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(3, 3, 3, 3));
; 269  : 
; 270  :   for (int x = 0; x + 3 < width; x += 4) {

	add	r9d, 4
	add	rax, 8
	lea	ecx, DWORD PTR [r9+3]
	cmp	ecx, esi
	jl	$LL4@kvz_ipol_8
	vmovaps	xmm9, XMMWORD PTR [rsp+64]
	vmovaps	xmm8, XMMWORD PTR [rsp+80]
	vmovaps	xmm7, XMMWORD PTR [rsp+96]
	vmovaps	xmm6, XMMWORD PTR [rsp+112]
	mov	r15, QWORD PTR [rsp+160]
	mov	r14, QWORD PTR [rsp+152]
	mov	rbx, QWORD PTR [rsp+144]
$LN3@kvz_ipol_8:

; 336  :     }
; 337  :   }
; 338  : }

	vzeroupper
	lea	r11, QWORD PTR [rsp+128]
	mov	rsi, QWORD PTR [r11+40]
	vmovaps	xmm10, XMMWORD PTR [r11-80]
	vmovaps	xmm11, XMMWORD PTR [r11-96]
	vmovaps	xmm12, XMMWORD PTR [r11-112]
	vmovaps	xmm13, XMMWORD PTR [r11-128]
	mov	rsp, r11
	pop	rdi
	ret	0
kvz_ipol_8tap_ver_im_px_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
filter$ = 128
width$ = 136
height$ = 144
src$ = 152
src_stride$dead$ = 160
dst$ = 168
dst_stride$ = 176
kvz_ipol_8tap_ver_im_hi_avx2 PROC

; 347  : {

	mov	r11, rsp
	mov	QWORD PTR [r11+32], rsi
	push	rdi
	sub	rsp, 112				; 00000070H

; 348  :   const int shift2 = 6;
; 349  : 
; 350  :   __m128i weights_8b = _mm_set1_epi64x(*(uint64_t *)filter);

	vpbroadcastq xmm0, QWORD PTR [rcx]
	vmovaps	XMMWORD PTR [r11-72], xmm9
	mov	rax, r9

; 351  :   __m256i weights_16b = _mm256_cvtepi8_epi16(weights_8b);

	vpmovsxbw ymm1, xmm0
	vmovaps	XMMWORD PTR [r11-88], xmm10

; 352  :   __m256i all_w01 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(0, 0, 0, 0));
; 353  :   __m256i all_w23 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(1, 1, 1, 1));
; 354  :   __m256i all_w45 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(2, 2, 2, 2));
; 355  :   __m256i all_w67 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(3, 3, 3, 3));
; 356  : 
; 357  :   for (int x = 0; x + 3 < width; x += 4) {

	xor	r9d, r9d
	vmovaps	XMMWORD PTR [r11-104], xmm11
	mov	edi, r8d
	vmovaps	XMMWORD PTR [rsp], xmm12
	mov	esi, edx
	vpshufd	ymm9, ymm1, 0
	vpshufd	ymm10, ymm1, 85				; 00000055H
	vpshufd	ymm11, ymm1, 170			; 000000aaH
	vpshufd	ymm12, ymm1, 255			; 000000ffH
	cmp	edx, 3
	jle	$LN3@kvz_ipol_8
	mov	QWORD PTR [r11+8], rbx
	add	rax, 256				; 00000100H
	mov	QWORD PTR [r11+16], r14
	movsx	r14d, WORD PTR dst_stride$[rsp]
	mov	QWORD PTR [r11+24], r15
	mov	r15, QWORD PTR dst$[rsp]
	vmovaps	XMMWORD PTR [rsp+96], xmm6
	vmovaps	XMMWORD PTR [rsp+80], xmm7
	vmovaps	XMMWORD PTR [r11-56], xmm8
	npad	6
$LL4@kvz_ipol_8:

; 360  : 
; 361  :     // Initial values
; 362  :     // Broadcasted rows in both lanes
; 363  :     // __m256i r0; // Unused
; 364  :     // __m256i r1; // Unused
; 365  :     __m256i r2 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 0 * src_stride));
; 366  :     __m256i r3 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 1 * src_stride));

	vpbroadcastq ymm2, QWORD PTR [rax-128]

; 367  :     __m256i r4 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 2 * src_stride));

	vpbroadcastq ymm6, QWORD PTR [rax]

; 368  :     __m256i r5 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 3 * src_stride));
; 369  :     __m256i r6 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 4 * src_stride));

	vpbroadcastq ymm5, QWORD PTR [rax+256]
	vpbroadcastq ymm0, QWORD PTR [rax-256]
	vpbroadcastq ymm4, QWORD PTR [rax+128]

; 370  :     __m256i r7 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 5 * src_stride));

	vpbroadcastq ymm3, QWORD PTR [rax+384]

; 371  :     __m256i r8 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 6 * src_stride));

	vpbroadcastq ymm7, QWORD PTR [rax+512]

; 372  : 
; 373  :     // Consecutive rows in low and high lanes
; 374  :     // __m256i r0_r1; // Unused
; 375  :     // __m256i r1_r2; // Unused
; 376  :     __m256i r2_r3 = _mm256_blend_epi32(r2, r3, 0xF0);

	vpblendd ymm1, ymm0, ymm2, 240			; 000000f0H

; 377  :     __m256i r3_r4 = _mm256_blend_epi32(r3, r4, 0xF0);

	vpblendd ymm0, ymm2, ymm6, 240			; 000000f0H

; 378  :     __m256i r4_r5 = _mm256_blend_epi32(r4, r5, 0xF0);
; 379  :     __m256i r5_r6 = _mm256_blend_epi32(r5, r6, 0xF0);
; 380  :     __m256i r6_r7 = _mm256_blend_epi32(r6, r7, 0xF0);
; 381  :     __m256i r7_r8 = _mm256_blend_epi32(r7, r8, 0xF0);
; 382  : 
; 383  :     // Paired samples of consecutive rows
; 384  :     __m256i r01_r12;
; 385  :     __m256i r23_r34 = _mm256_unpacklo_epi16(r2_r3, r3_r4);

	vpunpcklwd ymm8, ymm1, ymm0
	vpblendd ymm0, ymm6, ymm4, 240			; 000000f0H
	vpblendd ymm2, ymm4, ymm5, 240			; 000000f0H

; 386  :     __m256i r45_r56 = _mm256_unpacklo_epi16(r4_r5, r5_r6);

	vpunpcklwd ymm6, ymm0, ymm2
	vpblendd ymm0, ymm5, ymm3, 240			; 000000f0H
	vpblendd ymm1, ymm3, ymm7, 240			; 000000f0H

; 387  :     __m256i r67_r78 = _mm256_unpacklo_epi16(r6_r7, r7_r8);

	vpunpcklwd ymm5, ymm0, ymm1

; 388  : 
; 389  :     for (int y = 0; y < height; y += 2) {

	test	edi, edi
	jle	$LN2@kvz_ipol_8

; 358  : 
; 359  :     int16_t *strip_ptr = src + 0 * src_stride + x;

	movsxd	r8, r9d
	lea	ecx, DWORD PTR [r14+r14]
	movsxd	r10, ecx
	lea	r11, QWORD PTR [rax+768]
	lea	ecx, DWORD PTR [r14+r9]
	add	r10, r10
	movsxd	rdx, ecx
	sub	rdx, r8
	lea	rbx, QWORD PTR [r15+r8*2]
	lea	r8, QWORD PTR [rdx+rdx]
	lea	edx, DWORD PTR [rdi-1]
	shr	edx, 1
	inc	edx
	npad	3
$LL7@kvz_ipol_8:

; 390  : 
; 391  :       strip_ptr = src + y * src_stride + x;
; 392  : 
; 393  :       // Slide window
; 394  :       r01_r12 = r23_r34;
; 395  :       r23_r34 = r45_r56;
; 396  :       r45_r56 = r67_r78;
; 397  :       r6 = r8;
; 398  :       r7 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 7 * src_stride));

	vpbroadcastq ymm0, QWORD PTR [r11-128]
	vmovdqu	ymm2, ymm7

; 399  :       r8 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 8 * src_stride));

	vpbroadcastq ymm7, QWORD PTR [r11]

; 400  :       r6_r7 = _mm256_blend_epi32(r6, r7, 0xF0);
; 401  :       r7_r8 = _mm256_blend_epi32(r7, r8, 0xF0);

	vpblendd ymm1, ymm0, ymm7, 240			; 000000f0H
	vpblendd ymm0, ymm2, ymm0, 240			; 000000f0H
	vmovdqu	ymm3, ymm8
	vmovdqu	ymm8, ymm6
	vmovdqu	ymm6, ymm5

; 402  : 
; 403  :       r67_r78 = _mm256_unpacklo_epi16(r6_r7, r7_r8);

	vpunpcklwd ymm5, ymm0, ymm1

; 404  : 
; 405  :       __m256i dot01 = _mm256_madd_epi16(r01_r12, all_w01);

	vpmaddwd ymm0, ymm3, ymm9

; 406  :       __m256i dot23 = _mm256_madd_epi16(r23_r34, all_w23);

	vpmaddwd ymm2, ymm8, ymm10

; 407  :       __m256i dot45 = _mm256_madd_epi16(r45_r56, all_w45);
; 408  :       __m256i dot67 = _mm256_madd_epi16(r67_r78, all_w67);
; 409  : 
; 410  :       __m256i sum0123 = _mm256_add_epi32(dot01, dot23);

	vpaddd	ymm4, ymm0, ymm2
	vpmaddwd ymm3, ymm6, ymm11
	vpmaddwd ymm1, ymm5, ymm12

; 411  :       __m256i sum4567 = _mm256_add_epi32(dot45, dot67);

	vpaddd	ymm0, ymm1, ymm3

; 412  :       __m256i sum = _mm256_add_epi32(sum0123, sum4567);

	vpaddd	ymm2, ymm0, ymm4

; 413  :       sum = _mm256_srai_epi32(sum, shift2); // TODO: -8192 offsetting for extreme values

	vpsrad	ymm4, ymm2, 6

; 414  :       sum = _mm256_packs_epi32(sum, sum);

	vpackssdw ymm0, ymm4, ymm4

; 415  : 
; 416  :       int16_t *dst_addr0 = &dst[(y + 0) * dst_stride + x];
; 417  :       int16_t *dst_addr1 = &dst[(y + 1) * dst_stride + x];
; 418  :       _mm_storel_epi64((__m128i*)dst_addr0, _mm256_castsi256_si128(sum));

	vmovq	QWORD PTR [rbx], xmm0

; 419  :       _mm_storel_epi64((__m128i*)dst_addr1, _mm256_extracti128_si256(sum, 1));

	vextracti128 xmm0, ymm0, 1
	vmovq	QWORD PTR [rbx+r8], xmm0
	add	rbx, r10
	lea	r11, QWORD PTR [r11+256]
	sub	rdx, 1
	jne	SHORT $LL7@kvz_ipol_8
$LN2@kvz_ipol_8:

; 352  :   __m256i all_w01 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(0, 0, 0, 0));
; 353  :   __m256i all_w23 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(1, 1, 1, 1));
; 354  :   __m256i all_w45 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(2, 2, 2, 2));
; 355  :   __m256i all_w67 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(3, 3, 3, 3));
; 356  : 
; 357  :   for (int x = 0; x + 3 < width; x += 4) {

	add	r9d, 4
	add	rax, 8
	lea	ecx, DWORD PTR [r9+3]
	cmp	ecx, esi
	jl	$LL4@kvz_ipol_8
	vmovaps	xmm8, XMMWORD PTR [rsp+64]
	vmovaps	xmm7, XMMWORD PTR [rsp+80]
	vmovaps	xmm6, XMMWORD PTR [rsp+96]
	mov	r15, QWORD PTR [rsp+144]
	mov	r14, QWORD PTR [rsp+136]
	mov	rbx, QWORD PTR [rsp+128]
$LN3@kvz_ipol_8:

; 420  :     }
; 421  :   }
; 422  : }

	vzeroupper
	lea	r11, QWORD PTR [rsp+112]
	mov	rsi, QWORD PTR [r11+40]
	vmovaps	xmm9, XMMWORD PTR [r11-64]
	vmovaps	xmm10, XMMWORD PTR [r11-80]
	vmovaps	xmm11, XMMWORD PTR [r11-96]
	vmovaps	xmm12, XMMWORD PTR [r11-112]
	mov	rsp, r11
	pop	rdi
	ret	0
kvz_ipol_8tap_ver_im_hi_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
tv982 = 96
filter$ = 96
width$ = 104
height$ = 112
src$ = 120
src_stride$ = 128
dst$ = 136
dst_stride$dead$ = 144
kvz_ipol_4tap_hor_px_im_avx2 PROC

; 430  :   int16_t dst_stride) {

	push	rsi
	push	r12
	sub	rsp, 72					; 00000048H

; 433  :     8, 9, 9, 10, 10, 11, 11, 12,
; 434  :     0, 1, 1, 2, 2, 3, 3, 4,
; 435  :     8, 9, 9, 10, 10, 11, 11, 12);
; 436  : 
; 437  :   __m256i shuf23 = _mm256_setr_epi8(2, 3, 3, 4, 4, 5, 5, 6,
; 438  :     10, 11, 11, 12, 12, 13, 13, 14,
; 439  :     2, 3, 3, 4, 4, 5, 5, 6,
; 440  :     10, 11, 11, 12, 12, 13, 13, 14);
; 441  : 
; 442  :   __m256i all_w01 = _mm256_set1_epi16(*(uint16_t*)(filter + 0));

	movsx	eax, WORD PTR [rcx]
	mov	r12d, edx

; 443  :   __m256i all_w23 = _mm256_set1_epi16(*(uint16_t*)(filter + 2));
; 444  : 
; 445  :   int y_offset = -KVZ_CHROMA_FILTER_OFFSET;
; 446  :   int x_offset = -KVZ_CHROMA_FILTER_OFFSET;
; 447  : 
; 448  :   kvz_pixel *top_left = src + src_stride * y_offset + x_offset;

	movsx	edx, WORD PTR src_stride$[rsp]
	vmovd	xmm5, eax
	movsx	eax, WORD PTR [rcx+2]
	mov	esi, edx
	vmovaps	XMMWORD PTR [rsp+32], xmm6

; 449  : 
; 450  :   int y = 0;
; 451  :   int x = 0;
; 452  : 
; 453  :   for (y = 0; y < height + KVZ_EXT_PADDING_CHROMA; y += 4) {

	lea	ecx, DWORD PTR [r8+3]
	vmovd	xmm6, eax
	mov	eax, edx
	vmovaps	XMMWORD PTR [rsp+16], xmm7
	vmovdqu	ymm7, YMMWORD PTR __ymm@0c0b0b0a0a09090804030302020101000c0b0b0a0a0909080403030202010100
	neg	eax
	vmovaps	XMMWORD PTR [rsp], xmm8
	vmovdqu	ymm8, YMMWORD PTR __ymm@0e0d0d0c0c0b0b0a06050504040303020e0d0d0c0c0b0b0a0605050404030302
	cdqe
	add	r9, rax
	mov	QWORD PTR tv982[rsp], r9
	vpbroadcastw ymm5, xmm5
	vpbroadcastw ymm6, xmm6
	test	ecx, ecx
	jle	$LN3@kvz_ipol_4

; 431  : 
; 432  :   __m256i shuf01 = _mm256_setr_epi8(0, 1, 1, 2, 2, 3, 3, 4,

	mov	QWORD PTR [rsp+104], rbx
	lea	eax, DWORD PTR [rdx*4]
	mov	QWORD PTR [rsp+112], rdi
	xor	edi, edi
	mov	QWORD PTR [rsp+64], r13
	mov	QWORD PTR [rsp+56], r14
	mov	r14, QWORD PTR dst$[rsp]
	mov	QWORD PTR [rsp+48], r15
	lea	r15d, DWORD PTR [rcx-1]
	shr	r15d, 2
	movsxd	r13, eax
	inc	r15d
	lea	eax, QWORD PTR [rdi+64]
$LL4@kvz_ipol_4:

; 454  : 
; 455  :     for (x = 0; x + 3 < width; x += 4) {

	xor	ebx, ebx
	cmp	r12d, 3
	jle	$LN2@kvz_ipol_4
	lea	ecx, DWORD PTR [rsi+rsi]
	movsx	r11, dx
	movsxd	r8, ecx
	dec	r9
	lea	rcx, QWORD PTR [rdi+r8]
	add	r9, rcx
	lea	ecx, DWORD PTR [rsi+rsi*2]
	movsxd	r10, ecx
	sub	r10, r8
	sub	r11, r8
$LL7@kvz_ipol_4:

; 456  : 
; 457  :       kvz_pixel *chunk_ptr = top_left + src_stride * y + x;
; 458  :       __m128i r0r1 = _mm_loadl_epi64((__m128i*)(chunk_ptr + 0 * src_stride));
; 459  :       __m128i r2r3 = _mm_loadl_epi64((__m128i*)(chunk_ptr + 2 * src_stride));

	vmovq	xmm0, QWORD PTR [r9]

; 460  :       r0r1 = _mm_insert_epi64(r0r1, *(uint64_t*)(chunk_ptr + 1 * src_stride), 1);
; 461  :       r2r3 = _mm_insert_epi64(r2r3, *(uint64_t*)(chunk_ptr + 3 * src_stride), 1);

	vpinsrq	xmm3, xmm0, QWORD PTR [r10+r9], 1

; 462  : 
; 463  :       __m256i r0r1_r2r3 = _mm256_castsi128_si256(r0r1);
; 464  :       r0r1_r2r3 = _mm256_inserti128_si256(r0r1_r2r3, r2r3, 1);
; 465  : 
; 466  :       __m256i r0_r1_01 = _mm256_shuffle_epi8(r0r1_r2r3, shuf01);
; 467  :       __m256i r0_r1_23 = _mm256_shuffle_epi8(r0r1_r2r3, shuf23);
; 468  : 
; 469  :       __m256i dot01 = _mm256_maddubs_epi16(r0_r1_01, all_w01);
; 470  :       __m256i dot23 = _mm256_maddubs_epi16(r0_r1_23, all_w23);
; 471  : 
; 472  :       __m256i sum = _mm256_add_epi16(dot01, dot23);
; 473  : 
; 474  :       __m128i *dst_r0 = (__m128i*)(dst + (y + 0) * dst_stride + x);

	movsxd	rdx, ebx
	mov	rcx, r9
	sub	rcx, r8
	add	ebx, 4
	vmovq	xmm0, QWORD PTR [rcx]
	vpinsrq	xmm2, xmm0, QWORD PTR [r11+r9], 1
	vinserti128 ymm4, ymm2, xmm3, 1
	vpshufb	ymm0, ymm4, ymm7
	vpshufb	ymm1, ymm4, ymm8
	vpmaddubsw ymm2, ymm1, ymm6
	lea	rcx, QWORD PTR [rax+rdx]
	add	r9, 4
	vpmaddubsw ymm3, ymm0, ymm5
	vpaddw	ymm0, ymm2, ymm3

; 475  :       __m128i *dst_r1 = (__m128i*)(dst + (y + 1) * dst_stride + x);
; 476  :       __m128i *dst_r2 = (__m128i*)(dst + (y + 2) * dst_stride + x);
; 477  :       __m128i *dst_r3 = (__m128i*)(dst + (y + 3) * dst_stride + x);
; 478  :       __m128i sum_r0r1 = _mm256_castsi256_si128(sum);
; 479  :       __m128i sum_r2r3 = _mm256_extracti128_si256(sum, 1);
; 480  :       _mm_storel_epi64(dst_r0, sum_r0r1);

	vmovq	QWORD PTR [r14+rcx*2-128], xmm0
	lea	rcx, QWORD PTR [rax+rdx]

; 481  :       _mm_storeh_pd((double*)dst_r1, _mm_castsi128_pd(sum_r0r1));

	vmovhpd	QWORD PTR [r14+rcx*2-64], xmm0
	lea	rcx, QWORD PTR [rax+rdx]
	vextracti128 xmm1, ymm0, 1

; 482  :       _mm_storel_epi64(dst_r2, sum_r2r3);

	vmovq	QWORD PTR [r14+rcx*2], xmm1
	lea	rcx, QWORD PTR [rax+rdx]

; 483  :       _mm_storeh_pd((double*)dst_r3, _mm_castsi128_pd(sum_r2r3));

	vmovhpd	QWORD PTR [r14+rcx*2+64], xmm1
	lea	ecx, DWORD PTR [rbx+3]
	cmp	ecx, r12d
	jl	SHORT $LL7@kvz_ipol_4
	movzx	edx, WORD PTR src_stride$[rsp]
	mov	r9, QWORD PTR tv982[rsp]
$LN2@kvz_ipol_4:

; 449  : 
; 450  :   int y = 0;
; 451  :   int x = 0;
; 452  : 
; 453  :   for (y = 0; y < height + KVZ_EXT_PADDING_CHROMA; y += 4) {

	sub	rax, -128				; ffffffffffffff80H
	add	rdi, r13
	sub	r15, 1
	jne	$LL4@kvz_ipol_4
	mov	r15, QWORD PTR [rsp+48]
	mov	r14, QWORD PTR [rsp+56]
	mov	r13, QWORD PTR [rsp+64]
	mov	rdi, QWORD PTR [rsp+112]
	mov	rbx, QWORD PTR [rsp+104]
$LN3@kvz_ipol_4:

; 484  :     }
; 485  :   }
; 486  : }

	vzeroupper
	vmovaps	xmm6, XMMWORD PTR [rsp+32]
	vmovaps	xmm7, XMMWORD PTR [rsp+16]
	vmovaps	xmm8, XMMWORD PTR [rsp]
	add	rsp, 72					; 00000048H
	pop	r12
	pop	rsi
	ret	0
kvz_ipol_4tap_hor_px_im_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
filter$ = 64
width$ = 72
height$ = 80
src$ = 88
src_stride$dead$ = 96
dst$ = 104
dst_stride$ = 112
kvz_ipol_4tap_ver_im_px_avx2 PROC

; 495  : {

	mov	QWORD PTR [rsp+32], rsi
	push	rdi
	sub	rsp, 48					; 00000030H

; 496  :   // Interpolation filter shifts
; 497  :   int32_t shift2 = 6;
; 498  : 
; 499  :   // Weighted prediction offset and shift
; 500  :   int32_t wp_shift1 = 14 - KVZ_BIT_DEPTH;
; 501  :   int32_t wp_offset1 = 1 << (wp_shift1 - 1);
; 502  : 
; 503  :   __m128i weights_8b = _mm_set1_epi64x(*(uint64_t*)filter);

	vpbroadcastq xmm0, QWORD PTR [rcx]

; 504  :   __m256i weights_16b = _mm256_cvtepi8_epi16(weights_8b);

	vpmovsxbw ymm1, xmm0
	vmovaps	XMMWORD PTR [rsp+16], xmm7

; 505  :   __m256i all_w01 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(0, 0, 0, 0));
; 506  :   __m256i all_w23 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(1, 1, 1, 1));
; 507  : 
; 508  :   for (int x = 0; x + 3 < width; x += 4) {

	xor	r10d, r10d
	vmovaps	XMMWORD PTR [rsp], xmm8
	mov	edi, r8d
	mov	esi, edx
	vpshufd	ymm7, ymm1, 0
	vpshufd	ymm8, ymm1, 85				; 00000055H
	cmp	edx, 3
	jle	$LN3@kvz_ipol_4
	mov	QWORD PTR [rsp+64], rbx
	lea	rax, QWORD PTR [r9+128]
	mov	QWORD PTR [rsp+72], r14
	movsx	r14d, WORD PTR dst_stride$[rsp]
	mov	QWORD PTR [rsp+80], r15
	mov	r15, QWORD PTR dst$[rsp]
	vmovaps	XMMWORD PTR [rsp+32], xmm6
$LL4@kvz_ipol_4:

; 511  : 
; 512  :     // Initial values
; 513  :     // Broadcasted rows in both lanes
; 514  :     // __m256i r0; // Unused
; 515  :     // __m256i r1; // Unused
; 516  :     __m256i r2 = _mm256_set1_epi64x(*(uint64_t*)(strip_ptr + 0 * src_stride));
; 517  :     __m256i r3 = _mm256_set1_epi64x(*(uint64_t*)(strip_ptr + 1 * src_stride));

	vpbroadcastq ymm2, QWORD PTR [rax-64]
	vpbroadcastq ymm0, QWORD PTR [rax-128]

; 518  :     __m256i r4 = _mm256_set1_epi64x(*(uint64_t*)(strip_ptr + 2 * src_stride));

	vpbroadcastq ymm4, QWORD PTR [rax]

; 519  : 
; 520  :     // Consecutive rows in low and high lanes
; 521  :     // __m256i r0_r1; // Unused
; 522  :     // __m256i r1_r2; // Unused
; 523  :     __m256i r2_r3 = _mm256_blend_epi32(r2, r3, 0xF0);

	vpblendd ymm1, ymm0, ymm2, 240			; 000000f0H

; 524  :     __m256i r3_r4 = _mm256_blend_epi32(r3, r4, 0xF0);

	vpblendd ymm0, ymm2, ymm4, 240			; 000000f0H

; 525  : 
; 526  :     // Paired samples of consecutive rows
; 527  :     __m256i r01_r12;
; 528  :     __m256i r23_r34 = _mm256_unpacklo_epi16(r2_r3, r3_r4);

	vpunpcklwd ymm5, ymm1, ymm0

; 529  : 
; 530  :     for (int y = 0; y < height; y += 2) {

	test	edi, edi
	jle	$LN2@kvz_ipol_4

; 509  : 
; 510  :     int16_t *strip_ptr = src + 0 * src_stride + x;

	vmovdqu	ymm6, YMMWORD PTR __ymm@0000002000000020000000200000002000000020000000200000002000000020
	movsxd	rdx, r10d
	lea	ecx, DWORD PTR [r14+r14]
	movsxd	rbx, ecx
	lea	r11, QWORD PTR [rax+128]
	lea	ecx, DWORD PTR [r14+r10]
	movsxd	r8, ecx
	sub	r8, rdx
	lea	r9, QWORD PTR [rdx+r15]
	lea	edx, DWORD PTR [rdi-1]
	shr	edx, 1
	inc	edx
	npad	8
$LL7@kvz_ipol_4:

; 531  : 
; 532  :       strip_ptr = src + y * src_stride + x;
; 533  : 
; 534  :       // Slide window
; 535  :       r01_r12 = r23_r34;
; 536  :       r2 = r4;
; 537  :       r3 = _mm256_set1_epi64x(*(uint64_t*)(strip_ptr + 3 * src_stride));

	vpbroadcastq ymm0, QWORD PTR [r11-64]
	vmovdqu	ymm2, ymm4

; 538  :       r4 = _mm256_set1_epi64x(*(uint64_t*)(strip_ptr + 4 * src_stride));

	vpbroadcastq ymm4, QWORD PTR [r11]

; 539  :       r2_r3 = _mm256_blend_epi32(r2, r3, 0xF0);
; 540  :       r3_r4 = _mm256_blend_epi32(r3, r4, 0xF0);

	vpblendd ymm1, ymm0, ymm4, 240			; 000000f0H
	vpblendd ymm0, ymm2, ymm0, 240			; 000000f0H
	vmovdqu	ymm3, ymm5

; 541  : 
; 542  :       r23_r34 = _mm256_unpacklo_epi16(r2_r3, r3_r4);

	vpunpcklwd ymm5, ymm0, ymm1

; 543  : 
; 544  :       __m256i dot01 = _mm256_madd_epi16(r01_r12, all_w01);

	vpmaddwd ymm2, ymm3, ymm7

; 545  :       __m256i dot23 = _mm256_madd_epi16(r23_r34, all_w23);

	vpmaddwd ymm0, ymm5, ymm8

; 546  : 
; 547  :       __m256i sum = _mm256_add_epi32(dot01, dot23);

	vpaddd	ymm1, ymm0, ymm2

; 548  :       sum = _mm256_srai_epi32(sum, shift2);

	vpsrad	ymm2, ymm1, 6

; 549  :       sum = _mm256_add_epi32(sum, _mm256_set1_epi32(wp_offset1));

	vpaddd	ymm3, ymm2, ymm6

; 550  :       sum = _mm256_srai_epi32(sum, wp_shift1);

	vpsrad	ymm0, ymm3, 6

; 551  :       sum = _mm256_packs_epi32(sum, sum);

	vpackssdw ymm1, ymm0, ymm0

; 552  :       sum = _mm256_packus_epi16(sum, sum);

	vpackuswb ymm2, ymm1, ymm1

; 553  : 
; 554  :       kvz_pixel *dst_addr0 = &dst[(y + 0) * dst_stride + x];
; 555  :       kvz_pixel *dst_addr1 = &dst[(y + 1) * dst_stride + x];
; 556  :       *(uint32_t*)dst_addr0 = _mm_cvtsi128_si32(_mm256_castsi256_si128(sum));

	vmovd	DWORD PTR [r9], xmm2

; 557  :       *(uint32_t*)dst_addr1 = _mm_cvtsi128_si32(_mm256_extracti128_si256(sum, 1));

	vextracti128 xmm0, ymm2, 1
	vmovd	DWORD PTR [r8+r9], xmm0
	add	r9, rbx
	lea	r11, QWORD PTR [r11+128]
	sub	rdx, 1
	jne	SHORT $LL7@kvz_ipol_4
$LN2@kvz_ipol_4:

; 505  :   __m256i all_w01 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(0, 0, 0, 0));
; 506  :   __m256i all_w23 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(1, 1, 1, 1));
; 507  : 
; 508  :   for (int x = 0; x + 3 < width; x += 4) {

	add	r10d, 4
	add	rax, 8
	lea	ecx, DWORD PTR [r10+3]
	cmp	ecx, esi
	jl	$LL4@kvz_ipol_4
	vmovaps	xmm6, XMMWORD PTR [rsp+32]
	mov	r15, QWORD PTR [rsp+80]
	mov	r14, QWORD PTR [rsp+72]
	mov	rbx, QWORD PTR [rsp+64]
$LN3@kvz_ipol_4:

; 558  :     }
; 559  :   }
; 560  : }

	vzeroupper
	mov	rsi, QWORD PTR [rsp+88]
	vmovaps	xmm7, XMMWORD PTR [rsp+16]
	vmovaps	xmm8, XMMWORD PTR [rsp]
	add	rsp, 48					; 00000030H
	pop	rdi
	ret	0
kvz_ipol_4tap_ver_im_px_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
filter$ = 48
width$ = 56
height$ = 64
src$ = 72
src_stride$dead$ = 80
dst$ = 88
dst_stride$ = 96
kvz_ipol_4tap_ver_im_hi_avx2 PROC

; 569  : {

	mov	QWORD PTR [rsp+32], rsi
	push	rdi
	sub	rsp, 32					; 00000020H

; 570  :   const int shift2 = 6;
; 571  : 
; 572  :   __m128i weights_8b = _mm_set1_epi64x(*(uint64_t *)filter);

	vpbroadcastq xmm0, QWORD PTR [rcx]

; 573  :   __m256i weights_16b = _mm256_cvtepi8_epi16(weights_8b);

	vpmovsxbw ymm1, xmm0
	vmovaps	XMMWORD PTR [rsp+16], xmm6

; 574  :   __m256i all_w01 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(0, 0, 0, 0));
; 575  :   __m256i all_w23 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(1, 1, 1, 1));
; 576  : 
; 577  :   for (int x = 0; x + 3 < width; x += 4) {

	xor	r10d, r10d
	vmovaps	XMMWORD PTR [rsp], xmm7
	mov	edi, r8d
	mov	esi, edx
	vpshufd	ymm6, ymm1, 0
	vpshufd	ymm7, ymm1, 85				; 00000055H
	cmp	edx, 3
	jle	$LN3@kvz_ipol_4
	mov	QWORD PTR [rsp+48], rbx
	lea	rax, QWORD PTR [r9+128]
	mov	QWORD PTR [rsp+56], r14
	movsx	r14d, WORD PTR dst_stride$[rsp]
	mov	QWORD PTR [rsp+64], r15
	mov	r15, QWORD PTR dst$[rsp]
	npad	5
$LL4@kvz_ipol_4:

; 580  : 
; 581  :     // Initial values
; 582  :     // Broadcasted rows in both lanes
; 583  :     // __m256i r0; // Unused
; 584  :     // __m256i r1; // Unused
; 585  :     __m256i r2 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 0 * src_stride));
; 586  :     __m256i r3 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 1 * src_stride));

	vpbroadcastq ymm2, QWORD PTR [rax-64]
	vpbroadcastq ymm0, QWORD PTR [rax-128]

; 587  :     __m256i r4 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 2 * src_stride));

	vpbroadcastq ymm4, QWORD PTR [rax]

; 588  : 
; 589  :     // Consecutive rows in low and high lanes
; 590  :     // __m256i r0_r1; // Unused
; 591  :     // __m256i r1_r2; // Unused
; 592  :     __m256i r2_r3 = _mm256_blend_epi32(r2, r3, 0xF0);

	vpblendd ymm1, ymm0, ymm2, 240			; 000000f0H

; 593  :     __m256i r3_r4 = _mm256_blend_epi32(r3, r4, 0xF0);

	vpblendd ymm0, ymm2, ymm4, 240			; 000000f0H

; 594  : 
; 595  :     // Paired samples of consecutive rows
; 596  :     __m256i r01_r12;
; 597  :     __m256i r23_r34 = _mm256_unpacklo_epi16(r2_r3, r3_r4);

	vpunpcklwd ymm5, ymm1, ymm0

; 598  : 
; 599  :     for (int y = 0; y < height; y += 2) {

	test	edi, edi
	jle	$LN2@kvz_ipol_4

; 578  : 
; 579  :     int16_t *strip_ptr = src + 0 * src_stride + x;

	movsxd	r8, r10d
	lea	ecx, DWORD PTR [r14+r14]
	movsxd	rbx, ecx
	lea	r9, QWORD PTR [rax+128]
	lea	ecx, DWORD PTR [r14+r10]
	add	rbx, rbx
	movsxd	rdx, ecx
	sub	rdx, r8
	lea	r11, QWORD PTR [r15+r8*2]
	lea	r8, QWORD PTR [rdx+rdx]
	lea	edx, DWORD PTR [rdi-1]
	shr	edx, 1
	inc	edx
	npad	10
$LL7@kvz_ipol_4:

; 600  : 
; 601  :       strip_ptr = src + y * src_stride + x;
; 602  : 
; 603  :       // Slide window
; 604  :       r01_r12 = r23_r34;
; 605  :       r2 = r4;
; 606  :       r3 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 3 * src_stride));

	vpbroadcastq ymm0, QWORD PTR [r9-64]
	vmovdqu	ymm2, ymm4

; 607  :       r4 = _mm256_set1_epi64x(*(uint64_t *)(strip_ptr + 4 * src_stride));

	vpbroadcastq ymm4, QWORD PTR [r9]

; 608  :       r2_r3 = _mm256_blend_epi32(r2, r3, 0xF0);
; 609  :       r3_r4 = _mm256_blend_epi32(r3, r4, 0xF0);

	vpblendd ymm1, ymm0, ymm4, 240			; 000000f0H
	vpblendd ymm0, ymm2, ymm0, 240			; 000000f0H
	vmovdqu	ymm3, ymm5

; 610  : 
; 611  :       r23_r34 = _mm256_unpacklo_epi16(r2_r3, r3_r4);

	vpunpcklwd ymm5, ymm0, ymm1

; 612  : 
; 613  :       __m256i dot01 = _mm256_madd_epi16(r01_r12, all_w01);
; 614  :       __m256i dot23 = _mm256_madd_epi16(r23_r34, all_w23);

	vpmaddwd ymm0, ymm5, ymm7
	vpmaddwd ymm2, ymm3, ymm6

; 615  : 
; 616  :       __m256i sum = _mm256_add_epi32(dot01, dot23);

	vpaddd	ymm1, ymm0, ymm2

; 617  :       sum = _mm256_srai_epi32(sum, shift2);

	vpsrad	ymm3, ymm1, 6

; 618  :       sum = _mm256_packs_epi32(sum, sum);

	vpackssdw ymm0, ymm3, ymm3

; 619  : 
; 620  :       int16_t *dst_addr0 = &dst[(y + 0) * dst_stride + x];
; 621  :       int16_t *dst_addr1 = &dst[(y + 1) * dst_stride + x];
; 622  :       _mm_storel_epi64((__m128i *)dst_addr0, _mm256_castsi256_si128(sum));

	vmovq	QWORD PTR [r11], xmm0

; 623  :       _mm_storel_epi64((__m128i *)dst_addr1, _mm256_extracti128_si256(sum, 1));

	vextracti128 xmm0, ymm0, 1
	vmovq	QWORD PTR [r8+r11], xmm0
	add	r11, rbx
	lea	r9, QWORD PTR [r9+128]
	sub	rdx, 1
	jne	SHORT $LL7@kvz_ipol_4
$LN2@kvz_ipol_4:

; 574  :   __m256i all_w01 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(0, 0, 0, 0));
; 575  :   __m256i all_w23 = _mm256_shuffle_epi32(weights_16b, _MM_SHUFFLE(1, 1, 1, 1));
; 576  : 
; 577  :   for (int x = 0; x + 3 < width; x += 4) {

	add	r10d, 4
	add	rax, 8
	lea	ecx, DWORD PTR [r10+3]
	cmp	ecx, esi
	jl	$LL4@kvz_ipol_4
	mov	r15, QWORD PTR [rsp+64]
	mov	r14, QWORD PTR [rsp+56]
	mov	rbx, QWORD PTR [rsp+48]
$LN3@kvz_ipol_4:

; 624  :     }
; 625  :   }
; 626  : }

	vzeroupper
	mov	rsi, QWORD PTR [rsp+72]
	vmovaps	xmm6, XMMWORD PTR [rsp+16]
	vmovaps	xmm7, XMMWORD PTR [rsp]
	add	rsp, 32					; 00000020H
	pop	rdi
	ret	0
kvz_ipol_4tap_ver_im_hi_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
encoder$ = 112
hor_pos2$1$ = 120
src$ = 120
src_stride$ = 128
width$ = 136
height$ = 144
filtered$ = 152
hor_intermediate$ = 160
fme_level$ = 168
hor_first_cols$ = 176
hpel_off_x$ = 184
hpel_off_y$ = 192
kvz_filter_hpel_blocks_hor_ver_luma_avx2 PROC

; 638  : {

	mov	QWORD PTR [rsp+8], rbx
	mov	QWORD PTR [rsp+24], rbp
	mov	QWORD PTR [rsp+32], rsi
	push	rdi
	push	r12
	push	r13
	push	r14
	push	r15
	sub	rsp, 64					; 00000040H

; 639  :   int x, y, first_y;
; 640  : 
; 641  :   // Interpolation filter shifts
; 642  :   int16_t shift1 = KVZ_BIT_DEPTH - 8;
; 643  :   int32_t shift2 = 6;
; 644  : 
; 645  :   // Weighted prediction offset and shift
; 646  :   int32_t wp_shift1 = 14 - KVZ_BIT_DEPTH;
; 647  :   int32_t wp_offset1 = 1 << (wp_shift1 - 1);
; 648  : 
; 649  :   int8_t *fir0 = kvz_g_luma_filter[0];
; 650  :   int8_t *fir2 = kvz_g_luma_filter[2];
; 651  : 
; 652  :   int16_t dst_stride = LCU_WIDTH;
; 653  :   int16_t hor_stride = LCU_WIDTH;
; 654  : 
; 655  :   int16_t *hor_pos0 = hor_intermediate[0];
; 656  :   int16_t *hor_pos2 = hor_intermediate[1];

	mov	r10, QWORD PTR hor_intermediate$[rsp]
	xor	ebp, ebp

; 657  :   int16_t *col_pos0 = hor_first_cols[0];
; 658  :   int16_t *col_pos2 = hor_first_cols[2];

	mov	r12, QWORD PTR hor_first_cols$[rsp]
	add	r10, 9216				; 00002400H

; 659  : 
; 660  :   // Horizontally filtered samples from the top row are
; 661  :   // not needed unless samples for diagonal positions are filtered later.
; 662  :   first_y = fme_level > 1 ? 0 : 1;
; 663  : 
; 664  :   // HORIZONTAL STEP
; 665  :   // Integer pixels
; 666  :   for (y = 0; y < height + KVZ_EXT_PADDING_LUMA + 1; ++y) {

	mov	edi, DWORD PTR height$[rsp]
	mov	ebx, r9d
	add	edi, 8
	movsx	r15d, r8w
	mov	QWORD PTR hor_pos2$1$[rsp], r10
	lea	r14d, QWORD PTR [rbp+7]
	lea	r13, QWORD PTR [r12+288]
	mov	rsi, rdx
	mov	r9d, ebp
	test	edi, edi
	jle	SHORT $LN64@kvz_filter

; 639  :   int x, y, first_y;
; 640  : 
; 641  :   // Interpolation filter shifts
; 642  :   int16_t shift1 = KVZ_BIT_DEPTH - 8;
; 643  :   int32_t shift2 = 6;
; 644  : 
; 645  :   // Weighted prediction offset and shift
; 646  :   int32_t wp_shift1 = 14 - KVZ_BIT_DEPTH;
; 647  :   int32_t wp_offset1 = 1 << (wp_shift1 - 1);
; 648  : 
; 649  :   int8_t *fir0 = kvz_g_luma_filter[0];
; 650  :   int8_t *fir2 = kvz_g_luma_filter[2];
; 651  : 
; 652  :   int16_t dst_stride = LCU_WIDTH;
; 653  :   int16_t hor_stride = LCU_WIDTH;
; 654  : 
; 655  :   int16_t *hor_pos0 = hor_intermediate[0];
; 656  :   int16_t *hor_pos2 = hor_intermediate[1];

	mov	r12, QWORD PTR hor_intermediate$[rsp]
	mov	r10d, ebp
	mov	r8d, r14d
	npad	1
$LL4@kvz_filter:

; 667  :     
; 668  :     for (x = 0; x + 7 < width; x += 8) {

	cmp	ebx, r14d
	jle	SHORT $LN2@kvz_filter
	lea	r11d, DWORD PTR [r9-3]
	mov	edx, r10d
	imul	r11d, r15d
	sub	r11d, r10d
	inc	r11d
	npad	10
$LL7@kvz_filter:

; 669  :       int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 670  :       int xpos = x + 1;
; 671  :       __m128i* out = (__m128i*)&hor_pos0[y * hor_stride + x];
; 672  :       __m128i chunk = _mm_loadl_epi64((__m128i*)&src[src_stride*ypos + xpos]);

	lea	eax, DWORD PTR [r11+rdx]
	movsxd	rcx, eax
	movsxd	rax, edx
	add	edx, 8
	vmovq	xmm0, QWORD PTR [rcx+rsi]

; 673  :       chunk = _mm_cvtepu8_epi16(chunk);

	vpmovzxbw xmm1, xmm0

; 674  :       chunk = _mm_slli_epi16(chunk, 6); // Multiply by 64

	vpsllw	xmm2, xmm1, 6

; 675  :       _mm_storeu_si128(out, chunk); //TODO: >> shift1

	vmovdqu	XMMWORD PTR [r12+rax*2], xmm2
	lea	eax, DWORD PTR [r8+rdx]
	cmp	eax, ebx
	jl	SHORT $LL7@kvz_filter
$LN2@kvz_filter:

; 659  : 
; 660  :   // Horizontally filtered samples from the top row are
; 661  :   // not needed unless samples for diagonal positions are filtered later.
; 662  :   first_y = fme_level > 1 ? 0 : 1;
; 663  : 
; 664  :   // HORIZONTAL STEP
; 665  :   // Integer pixels
; 666  :   for (y = 0; y < height + KVZ_EXT_PADDING_LUMA + 1; ++y) {

	inc	r9d
	add	r10d, 64				; 00000040H
	sub	r8d, 64					; 00000040H
	cmp	r9d, edi
	jl	SHORT $LL4@kvz_filter
	mov	r12, QWORD PTR hor_first_cols$[rsp]
	mov	r10, QWORD PTR hor_pos2$1$[rsp]
$LN64@kvz_filter:

; 676  :     }
; 677  :   }
; 678  : 
; 679  :   // Write the first column in contiguous memory
; 680  :   x = 0;
; 681  :   for (y = 0; y < height + KVZ_EXT_PADDING_LUMA + 1; ++y) {

	movsxd	rdi, edi
	test	rdi, rdi
	jle	SHORT $LN9@kvz_filter

; 682  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 683  :     int32_t first_sample = src[src_stride*ypos + x] << 6 >> shift1;

	mov	rdx, rbp
	imul	r8d, r15d, -3
	npad	10
$LL10@kvz_filter:
	movsxd	rax, r8d
	add	r8d, r15d

; 684  :     col_pos0[y] = first_sample;

	movzx	ecx, BYTE PTR [rax+rsi]
	shl	cx, 6
	mov	WORD PTR [r12+rdx*2], cx
	inc	rdx
	cmp	rdx, rdi
	jl	SHORT $LL10@kvz_filter
$LN9@kvz_filter:

; 685  :   }
; 686  : 
; 687  :   // Half pixels
; 688  :   kvz_ipol_8tap_hor_px_im_avx2(fir2, width, height + 1, src + 1, src_stride, hor_pos2, hor_stride);

	mov	r12d, DWORD PTR height$[rsp]
	lea	r9, QWORD PTR [rsi+1]
	mov	QWORD PTR [rsp+40], r10
	lea	rcx, OFFSET FLAT:kvz_g_luma_filter+16
	mov	edx, ebx
	mov	WORD PTR [rsp+32], r15w
	lea	r8d, DWORD PTR [r12+1]
	call	kvz_ipol_8tap_hor_px_im_avx2

; 689  : 
; 690  :   // Write the first column in contiguous memory
; 691  :   x = 0;
; 692  :   for (y = first_y; y < height + KVZ_EXT_PADDING_LUMA + 1; ++y) {

	movzx	eax, BYTE PTR fme_level$[rsp]
	mov	rdx, rbp
	cmp	al, 1
	setle	dl
	cmp	rdx, rdi
	jge	SHORT $LN12@kvz_filter

; 693  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 694  :     int xpos = x - KVZ_LUMA_FILTER_OFFSET;
; 695  :     col_pos2[y] = kvz_eight_tap_filter_hor_avx2(fir2, &src[src_stride*ypos + xpos]) >> shift1;

	cmp	al, 1
	mov	ecx, ebp
	setle	cl
	add	ecx, -3
	imul	ecx, r15d
	sub	ecx, 3
	npad	5
$LL13@kvz_filter:

; 58   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR kvz_g_luma_filter+16

; 693  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 694  :     int xpos = x - KVZ_LUMA_FILTER_OFFSET;
; 695  :     col_pos2[y] = kvz_eight_tap_filter_hor_avx2(fir2, &src[src_stride*ypos + xpos]) >> shift1;

	movsxd	rax, ecx
	add	ecx, r15d

; 59   :   __m128i row = _mm_loadl_epi64((__m128i*)data);

	vmovq	xmm1, QWORD PTR [rax+rsi]

; 60   :   __m128i acc;
; 61   :   acc = _mm_maddubs_epi16(row, fir);

	vpmaddubsw xmm2, xmm1, xmm0

; 62   :   __m128i temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm2, 4

; 63   :   acc = _mm_add_epi16(acc, temp);

	vpaddw	xmm3, xmm1, xmm2

; 64   :   temp = _mm_srli_si128(acc, 2);

	vpsrldq	xmm0, xmm3, 2

; 65   :   acc = _mm_add_epi16(acc, temp);

	vpaddw	xmm1, xmm0, xmm3

; 66   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm1

; 693  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 694  :     int xpos = x - KVZ_LUMA_FILTER_OFFSET;
; 695  :     col_pos2[y] = kvz_eight_tap_filter_hor_avx2(fir2, &src[src_stride*ypos + xpos]) >> shift1;

	mov	WORD PTR [r13+rdx*2], ax
	inc	rdx
	cmp	rdx, rdi
	jl	SHORT $LL13@kvz_filter
$LN12@kvz_filter:

; 696  :   }
; 697  : 
; 698  :   // VERTICAL STEP
; 699  :   kvz_pixel *out_l = filtered[0];
; 700  :   kvz_pixel *out_r = filtered[1];

	mov	rax, QWORD PTR filtered$[rsp]

; 701  :   kvz_pixel *out_t = filtered[2];
; 702  :   kvz_pixel *out_b = filtered[3];
; 703  : 
; 704  :   // Right
; 705  :   int16_t *im = &hor_pos2[hor_stride];
; 706  :   kvz_pixel *dst = out_r;
; 707  :   kvz_ipol_8tap_ver_im_px_avx2(fir0, width, height, im, hor_stride, dst, dst_stride);

	lea	rcx, OFFSET FLAT:kvz_g_luma_filter
	mov	r9, QWORD PTR hor_pos2$1$[rsp]
	mov	r8d, r12d
	sub	r9, -128				; ffffffffffffff80H
	mov	edx, ebx
	lea	rdi, QWORD PTR [rax+4096]
	lea	r15, QWORD PTR [rax+8192]
	lea	rsi, QWORD PTR [rax+12288]
	mov	eax, 64					; 00000040H
	mov	WORD PTR [rsp+48], ax
	mov	QWORD PTR [rsp+40], rdi
	call	kvz_ipol_8tap_ver_im_px_avx2

; 708  : 
; 709  :   // Left
; 710  :   // Copy from the right filtered block and filter the extra column
; 711  :   for (y = 0; y < height; ++y) {

	test	r12d, r12d
	jle	$LN15@kvz_filter
	lea	r8, QWORD PTR [r13+8]
	mov	r9, r12
	mov	r10d, -256				; ffffffffffffff00H
	npad	8
$LL16@kvz_filter:

; 712  :     x = 0;
; 713  :     *(uint64_t*)&out_l[y * dst_stride + x] = *(uint64_t*)&out_r[y * dst_stride + x] << 8;

	mov	rax, QWORD PTR [rdi]
	shl	rax, 8
	mov	QWORD PTR [rdi-4096], rax

; 714  :     for (x = 8; x < width; x += 8) *(int64_t*)&out_l[y * dst_stride + x] = *(int64_t*)&out_r[y * dst_stride + x - 1];

	cmp	ebx, 8
	jle	SHORT $LN18@kvz_filter

; 712  :     x = 0;
; 713  :     *(uint64_t*)&out_l[y * dst_stride + x] = *(uint64_t*)&out_r[y * dst_stride + x] << 8;

	lea	edx, DWORD PTR [rbx-9]
	shr	edx, 3
	lea	rcx, QWORD PTR [rdi-4088]
	inc	edx
$LL19@kvz_filter:

; 714  :     for (x = 8; x < width; x += 8) *(int64_t*)&out_l[y * dst_stride + x] = *(int64_t*)&out_r[y * dst_stride + x - 1];

	mov	rax, QWORD PTR [rcx+4095]
	mov	QWORD PTR [rcx], rax
	lea	rcx, QWORD PTR [rcx+8]
	sub	rdx, 1
	jne	SHORT $LL19@kvz_filter
$LN18@kvz_filter:

; 715  :     x = 0;
; 716  :     int16_t sample = 64 * col_pos2[y + 1 + KVZ_LUMA_FILTER_OFFSET] >> shift2;

	movsx	eax, WORD PTR [r8]
	shl	eax, 6
	sar	eax, 6

; 717  :     sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, r10w
	je	SHORT $LN33@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN33@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 718  :     out_l[y * dst_stride + x] = sample;

	mov	BYTE PTR [rdi-4096], al
	add	r8, 2
	add	rdi, 64					; 00000040H
	sub	r9, 1
	jne	SHORT $LL16@kvz_filter
$LN15@kvz_filter:

; 719  :   }
; 720  : 
; 721  :   // Top
; 722  :   im = hor_pos0;
; 723  :   dst = out_t;
; 724  :   kvz_ipol_8tap_ver_im_px_avx2(fir2, width, height, im, hor_stride, dst, dst_stride);

	mov	rdi, QWORD PTR hor_intermediate$[rsp]
	lea	rcx, OFFSET FLAT:kvz_g_luma_filter+16
	mov	eax, 64					; 00000040H
	mov	r9, rdi
	mov	WORD PTR [rsp+48], ax
	mov	r8d, r12d
	mov	edx, ebx
	mov	QWORD PTR [rsp+40], r15
	call	kvz_ipol_8tap_ver_im_px_avx2

; 725  : 
; 726  :   // Bottom
; 727  :   // Copy what can be copied from the top filtered values.
; 728  :   // Then filter the last row from horizontal intermediate buffer.
; 729  :   for (y = 0; y < height - 1; ++y) {

	lea	r8d, DWORD PTR [r12-1]
	test	r8d, r8d
	jle	SHORT $LN21@kvz_filter
	npad	4
$LL22@kvz_filter:

; 730  :     for (x = 0; x + 7 < width; x += 8) {

	cmp	ebx, 7
	jle	SHORT $LN20@kvz_filter
	mov	eax, ebp
	shl	eax, 6
	npad	6
$LL25@kvz_filter:

; 731  :       *(int64_t*)&out_b[(y + 0) * dst_stride + x] = *(int64_t*)&out_t[(y + 1) * dst_stride + x];

	movsxd	rcx, eax
	movsxd	rdx, eax
	add	eax, 8
	mov	rcx, QWORD PTR [rcx+r15+64]
	mov	QWORD PTR [rdx+rsi], rcx
	lea	ecx, DWORD PTR [r14+rax]
	cmp	ecx, ebx
	jl	SHORT $LL25@kvz_filter
$LN20@kvz_filter:

; 725  : 
; 726  :   // Bottom
; 727  :   // Copy what can be copied from the top filtered values.
; 728  :   // Then filter the last row from horizontal intermediate buffer.
; 729  :   for (y = 0; y < height - 1; ++y) {

	inc	ebp
	sub	r14d, 64				; 00000040H
	cmp	ebp, r8d
	jl	SHORT $LL22@kvz_filter
$LN21@kvz_filter:

; 732  :     }
; 733  :   }
; 734  : 
; 735  :   for (x = 0; x + 7 < width; x += 8) {

	cmp	ebx, 7
	jle	SHORT $LN27@kvz_filter
	shl	ebp, 6
	mov	r10d, -57				; ffffffffffffffc7H
	sub	r10d, ebp
	lea	r8d, DWORD PTR [rbp+64]
	npad	6
$LL28@kvz_filter:

; 736  :     kvz_eight_tap_filter_ver_16bit_1x8_avx2(fir2, &hor_pos0[(y + 1) * hor_stride + x], hor_stride, &out_b[y * dst_stride + x]);

	lea	eax, DWORD PTR [r8-64]
	movsxd	r9, eax
	lea	rcx, OFFSET FLAT:kvz_g_luma_filter+16
	movsxd	rax, r8d
	add	r9, rsi
	lea	rdx, QWORD PTR [rdi+rax*2]
	call	kvz_eight_tap_filter_ver_16bit_1x8_avx2
	add	r8d, 8
	lea	eax, DWORD PTR [r10+r8]
	cmp	eax, ebx
	jl	SHORT $LL28@kvz_filter
$LN27@kvz_filter:

; 737  :   }
; 738  : }

	lea	r11, QWORD PTR [rsp+64]
	mov	rbx, QWORD PTR [r11+48]
	mov	rbp, QWORD PTR [r11+64]
	mov	rsi, QWORD PTR [r11+72]
	mov	rsp, r11
	pop	r15
	pop	r14
	pop	r13
	pop	r12
	pop	rdi
	ret	0
kvz_filter_hpel_blocks_hor_ver_luma_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
encoder$ = 112
src$ = 120
src_stride$ = 128
width$ = 136
height$ = 144
col_pos2$1$ = 152
filtered$ = 152
hor_intermediate$ = 160
fme_level$ = 168
hor_first_cols$ = 176
hpel_off_x$ = 184
hpel_off_y$ = 192
kvz_filter_hpel_blocks_diag_luma_avx2 PROC

; 750  : {

	mov	QWORD PTR [rsp+8], rbx
	mov	QWORD PTR [rsp+16], rbp
	mov	QWORD PTR [rsp+24], rsi
	push	rdi
	push	r12
	push	r13
	push	r14
	push	r15
	sub	rsp, 64					; 00000040H
	mov	rsi, QWORD PTR filtered$[rsp]

; 751  :   int x, y;
; 752  : 
; 753  :   // Interpolation filter shifts
; 754  :   int32_t shift2 = 6;
; 755  : 
; 756  :   // Weighted prediction offset and shift
; 757  :   int32_t wp_shift1 = 14 - KVZ_BIT_DEPTH;
; 758  :   int32_t wp_offset1 = 1 << (wp_shift1 - 1);
; 759  : 
; 760  :   int8_t *fir2 = kvz_g_luma_filter[2];
; 761  : 
; 762  :   int16_t dst_stride = LCU_WIDTH;
; 763  :   int16_t hor_stride = LCU_WIDTH;
; 764  : 
; 765  :   int16_t *hor_pos2 = hor_intermediate[1];
; 766  :   int16_t *col_pos2 = hor_first_cols[2];
; 767  : 
; 768  :   // VERTICAL STEP
; 769  :   kvz_pixel *out_tl = filtered[0];
; 770  :   kvz_pixel *out_tr = filtered[1];
; 771  :   kvz_pixel *out_bl = filtered[2];
; 772  :   kvz_pixel *out_br = filtered[3];
; 773  : 
; 774  :   // Top-Right
; 775  :   int16_t *im = hor_pos2;
; 776  :   kvz_pixel *dst = out_tr;
; 777  :   kvz_ipol_8tap_ver_im_px_avx2(fir2, width, height, im, hor_stride, dst, dst_stride);

	lea	rcx, OFFSET FLAT:kvz_g_luma_filter+16
	mov	r13, QWORD PTR hor_intermediate$[rsp]
	mov	ebx, r9d
	mov	r12, QWORD PTR hor_first_cols$[rsp]
	mov	eax, 64					; 00000040H
	mov	r15d, DWORD PTR height$[rsp]
	add	r13, 9216				; 00002400H
	mov	WORD PTR [rsp+48], ax
	lea	rdi, QWORD PTR [rsi+4096]
	add	r12, 288				; 00000120H
	mov	QWORD PTR [rsp+40], rdi
	mov	r9, r13
	mov	QWORD PTR col_pos2$1$[rsp], r12
	mov	r8d, r15d
	lea	rbp, QWORD PTR [rsi+8192]
	mov	edx, ebx
	lea	r14, QWORD PTR [rsi+12288]
	call	kvz_ipol_8tap_ver_im_px_avx2

; 778  : 
; 779  :   // Top-left
; 780  :   // Copy from the top-right filtered block and filter the extra column
; 781  :   for (y = 0; y < height; ++y) {

	mov	ecx, -256				; ffffffffffffff00H
	test	r15d, r15d
	jle	$LN3@kvz_filter
	mov	r10, r12
	mov	r9, rsi
	mov	r11d, r15d
	npad	12
$LL4@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR kvz_g_luma_filter+16

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 75   :   __m128i row = _mm_loadu_si128((__m128i*)data);
; 76   :   __m128i acc;
; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r10]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 782  :     x = 0;
; 783  :     int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(fir2, &col_pos2[y]) >> shift2;

	sar	eax, 6

; 784  :     sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, cx
	je	SHORT $LN30@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN30@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 785  :     out_tl[y * dst_stride + x] = sample;

	mov	BYTE PTR [r9], al

; 786  : 
; 787  :     for (x = 1; x < width; ++x) out_tl[y * dst_stride + x] = out_tr[y * dst_stride + x - 1];

	cmp	ebx, 1
	jle	SHORT $LN2@kvz_filter

; 785  :     out_tl[y * dst_stride + x] = sample;

	mov	r8, rdi
	lea	rcx, QWORD PTR [r9+1]
	sub	r8, rsi
	lea	edx, DWORD PTR [rbx-1]
	npad	14
$LL7@kvz_filter:

; 786  : 
; 787  :     for (x = 1; x < width; ++x) out_tl[y * dst_stride + x] = out_tr[y * dst_stride + x - 1];

	movzx	eax, BYTE PTR [r8+rcx-1]
	mov	BYTE PTR [rcx], al
	lea	rcx, QWORD PTR [rcx+1]
	sub	rdx, 1
	jne	SHORT $LL7@kvz_filter
	mov	ecx, -256				; ffffffffffffff00H
$LN2@kvz_filter:

; 778  : 
; 779  :   // Top-left
; 780  :   // Copy from the top-right filtered block and filter the extra column
; 781  :   for (y = 0; y < height; ++y) {

	add	r9, 64					; 00000040H
	add	r10, 2
	sub	r11, 1
	jne	$LL4@kvz_filter
$LN3@kvz_filter:

; 788  :   }
; 789  : 
; 790  :   // Bottom-right
; 791  :   // Copy what can be copied from top-right filtered values. Filter the last row.
; 792  :   for (y = 0; y < height - 1; ++y) {

	xor	r10d, r10d
	dec	r15d
	mov	r11d, r10d
	lea	r8d, QWORD PTR [r10+7]
	test	r15d, r15d
	jle	SHORT $LN9@kvz_filter
	mov	r9d, r8d
	npad	2
$LL10@kvz_filter:

; 793  :     for (x = 0; x + 7 < width; x += 8) {

	cmp	ebx, r8d
	jle	SHORT $LN8@kvz_filter
	mov	edx, r11d
	shl	edx, 6
	npad	5
$LL13@kvz_filter:

; 794  :       memcpy(&out_br[y * dst_stride + x], &out_tr[(y + 1) * dst_stride + x], 8);

	movsxd	rax, edx
	movsxd	rcx, edx
	add	edx, 8
	mov	rax, QWORD PTR [rax+rdi+64]
	mov	QWORD PTR [rcx+r14], rax
	lea	eax, DWORD PTR [r9+rdx]
	cmp	eax, ebx
	jl	SHORT $LL13@kvz_filter
$LN8@kvz_filter:

; 788  :   }
; 789  : 
; 790  :   // Bottom-right
; 791  :   // Copy what can be copied from top-right filtered values. Filter the last row.
; 792  :   for (y = 0; y < height - 1; ++y) {

	inc	r11d
	sub	r9d, 64					; 00000040H
	cmp	r11d, r15d
	jl	SHORT $LL10@kvz_filter
$LN9@kvz_filter:

; 795  :     }
; 796  :   }
; 797  : 
; 798  :   for (x = 0; x + 7 < width; x += 8) {

	cmp	ebx, r8d
	jle	SHORT $LN15@kvz_filter
	shl	r11d, 6
	mov	r12d, -57				; ffffffffffffffc7H
	sub	r12d, r11d
	lea	edi, DWORD PTR [r11+64]
	npad	4
$LL16@kvz_filter:

; 799  :     kvz_eight_tap_filter_ver_16bit_1x8_avx2(fir2, &hor_pos2[(y + 1) * hor_stride + x], hor_stride, &out_br[y * dst_stride + x]);

	lea	eax, DWORD PTR [rdi-64]
	movsxd	r9, eax
	lea	rcx, OFFSET FLAT:kvz_g_luma_filter+16
	movsxd	rax, edi
	add	r9, r14
	lea	rdx, QWORD PTR [rax*2]
	add	rdx, r13
	call	kvz_eight_tap_filter_ver_16bit_1x8_avx2
	add	edi, 8
	lea	eax, DWORD PTR [r12+rdi]
	cmp	eax, ebx
	jl	SHORT $LL16@kvz_filter
	mov	r12, QWORD PTR col_pos2$1$[rsp]
$LN15@kvz_filter:

; 800  :   }
; 801  : 
; 802  :   // Bottom-left
; 803  :   // Copy what can be copied from the top-left filtered values.
; 804  :   // Copy what can be copied from the bottom-right filtered values.
; 805  :   // Finally filter the last pixel from the column array.
; 806  :   for (y = 0; y < height - 1; ++y) {

	test	r15d, r15d
	jle	SHORT $LN18@kvz_filter
	npad	5
$LL19@kvz_filter:

; 807  :     for (x = 0; x + 7 < width; x += 8) {

	cmp	ebx, 7
	jle	SHORT $LN17@kvz_filter
	mov	eax, r10d
	shl	eax, 6
	npad	5
$LL22@kvz_filter:

; 808  :       memcpy(&out_bl[y * dst_stride + x], &out_tl[(y + 1) * dst_stride + x], 8);

	movsxd	rcx, eax
	movsxd	rdx, eax
	add	eax, 8
	mov	rcx, QWORD PTR [rcx+rsi+64]
	mov	QWORD PTR [rdx+rbp], rcx
	lea	ecx, DWORD PTR [r8+rax]
	cmp	ecx, ebx
	jl	SHORT $LL22@kvz_filter
$LN17@kvz_filter:

; 800  :   }
; 801  : 
; 802  :   // Bottom-left
; 803  :   // Copy what can be copied from the top-left filtered values.
; 804  :   // Copy what can be copied from the bottom-right filtered values.
; 805  :   // Finally filter the last pixel from the column array.
; 806  :   for (y = 0; y < height - 1; ++y) {

	inc	r10d
	sub	r8d, 64					; 00000040H
	cmp	r10d, r15d
	jl	SHORT $LL19@kvz_filter
$LN18@kvz_filter:

; 809  :     }
; 810  :   }
; 811  : 
; 812  :   for (x = 1; x < width; ++x) out_bl[y * dst_stride + x] = out_br[y * dst_stride + x - 1];

	cmp	ebx, 1
	jle	SHORT $LN24@kvz_filter
	mov	eax, r10d
	lea	edx, DWORD PTR [rbx-1]
	shl	eax, 6
	inc	eax
	movsxd	rcx, eax
	add	rcx, rbp
	npad	4
$LL25@kvz_filter:
	movzx	eax, BYTE PTR [rcx+4095]
	mov	BYTE PTR [rcx], al
	lea	rcx, QWORD PTR [rcx+1]
	sub	rdx, 1
	jne	SHORT $LL25@kvz_filter
$LN24@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR kvz_g_luma_filter+16

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 813  :   x = 0;
; 814  :   int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(fir2, &col_pos2[(y + 1)]) >> shift2;

	movsxd	rax, r10d

; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r12+rax*2+2]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 813  :   x = 0;
; 814  :   int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(fir2, &col_pos2[(y + 1)]) >> shift2;

	sar	eax, 6

; 815  :   sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	movsx	ecx, ax
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	mov	eax, -256				; ffffffffffffff00H
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 815  :   sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	add	ecx, 32					; 00000020H
	sar	ecx, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	cx, ax
	je	SHORT $LN36@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	movsx	ecx, cx
	neg	ecx
	sar	ecx, 15
$LN36@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 817  : }

	mov	rbx, QWORD PTR [rsp+112]
	mov	rsi, QWORD PTR [rsp+128]
	shl	r10d, 6
	movsxd	rax, r10d
	mov	BYTE PTR [rax+rbp], cl
	mov	rbp, QWORD PTR [rsp+120]
	add	rsp, 64					; 00000040H
	pop	r15
	pop	r14
	pop	r13
	pop	r12
	pop	rdi
	ret	0
kvz_filter_hpel_blocks_diag_luma_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
out_t$1$ = 64
col_pos_r$1$ = 64
tv3168 = 72
hor_pos_l$1$ = 80
ver_fir_t$1$ = 88
out_b$1$ = 96
ver_fir_b$1$ = 104
encoder$ = 176
hor_pos_r$1$ = 184
src$ = 184
src_stride$ = 192
width$ = 200
height$ = 208
tv3214 = 216
filtered$ = 216
hor_intermediate$ = 224
fme_level$ = 232
sample_off_y$1$ = 240
tv3205 = 240
hor_first_cols$ = 240
hpel_off_x$ = 248
hpel_off_y$ = 256
kvz_filter_qpel_blocks_hor_ver_luma_avx2 PROC

; 829  : {

	mov	QWORD PTR [rsp+8], rbx
	mov	DWORD PTR [rsp+32], r9d
	push	rbp
	push	rsi
	push	rdi
	push	r12
	push	r13
	push	r14
	push	r15
	sub	rsp, 112				; 00000070H

; 830  :   int x, y;
; 831  : 
; 832  :   // Interpolation filter shifts
; 833  :   int16_t shift1 = KVZ_BIT_DEPTH - 8;
; 834  :   int32_t shift2 = 6;
; 835  : 
; 836  :   // Weighted prediction offset and shift
; 837  :   int32_t wp_shift1 = 14 - KVZ_BIT_DEPTH;
; 838  :   int32_t wp_offset1 = 1 << (wp_shift1 - 1);
; 839  : 
; 840  :   int8_t *fir0 = kvz_g_luma_filter[0];
; 841  :   int8_t *fir2 = kvz_g_luma_filter[2];
; 842  :   int8_t *fir1 = kvz_g_luma_filter[1];
; 843  :   int8_t *fir3 = kvz_g_luma_filter[3];
; 844  : 
; 845  :   // Horiziontal positions. Positions 0 and 2 have already been calculated in filtered.
; 846  :   int16_t *hor_pos0 = hor_intermediate[0];
; 847  :   int16_t *hor_pos2 = hor_intermediate[1];

	mov	r11, QWORD PTR hor_intermediate$[rsp]
	mov	r10d, r9d

; 848  :   int16_t *hor_pos_l = hor_intermediate[3];
; 849  :   int16_t *hor_pos_r = hor_intermediate[4];
; 850  :   int8_t *hor_fir_l = hpel_off_x != 0 ? fir1 : fir3;

	movzx	r9d, BYTE PTR hpel_off_x$[rsp]
	mov	rbx, rdx
	test	r9b, r9b
	movsx	r15d, r8w
	lea	r8, OFFSET FLAT:kvz_g_luma_filter+24
	mov	r12, r8
	lea	rdx, QWORD PTR [r11+27648]
	lea	rax, QWORD PTR [r11+36864]

; 851  :   int8_t *hor_fir_r = hpel_off_x != 0 ? fir3 : fir1;
; 852  :   int16_t *col_pos_l = hor_first_cols[1];
; 853  :   int16_t *col_pos_r = hor_first_cols[3];
; 854  : 
; 855  :   int16_t dst_stride = LCU_WIDTH;
; 856  :   int16_t hor_stride = LCU_WIDTH;
; 857  : 
; 858  :   int16_t *hor_hpel_pos = hpel_off_x != 0 ? hor_pos2 : hor_pos0;
; 859  :   int16_t *col_pos_hor = hpel_off_x != 0 ? hor_first_cols[2] : hor_first_cols[0];
; 860  : 
; 861  :   // Specify if integer pixels are filtered from left or/and top integer samples
; 862  :   int off_x_fir_l = hpel_off_x < 1 ? 0 : 1;
; 863  :   int off_x_fir_r = hpel_off_x < 0 ? 0 : 1;
; 864  :   int off_y_fir_t = hpel_off_y < 1 ? 0 : 1;
; 865  :   int off_y_fir_b = hpel_off_y < 0 ? 0 : 1;
; 866  : 
; 867  :   // HORIZONTAL STEP
; 868  :   // Left QPEL
; 869  :   int sample_off_y = hpel_off_y < 0 ? 0 : 1;
; 870  :   kvz_ipol_8tap_hor_px_im_avx2(hor_fir_l, width, height + 1, src + 1, src_stride, hor_pos_l, hor_stride);

	mov	QWORD PTR [rsp+40], rdx
	mov	QWORD PTR hor_pos_r$1$[rsp], rax
	lea	rcx, QWORD PTR [r11+9216]
	cmovne	r11, rcx
	mov	QWORD PTR hor_pos_l$1$[rsp], rdx
	lea	rax, OFFSET FLAT:kvz_g_luma_filter+8
	mov	QWORD PTR hor_intermediate$[rsp], r11
	cmovne	r12, rax
	mov	WORD PTR [rsp+32], r15w
	mov	rsi, rax
	lea	r9, QWORD PTR [rbx+1]
	mov	rax, QWORD PTR hor_first_cols$[rsp]
	cmovne	rsi, r8
	mov	edx, r10d
	lea	r8, QWORD PTR [rax+432]
	lea	rcx, QWORD PTR [rax+288]
	mov	QWORD PTR col_pos_r$1$[rsp], r8
	mov	r8d, DWORD PTR height$[rsp]
	lea	r13, QWORD PTR [rax+144]
	cmove	rcx, rax
	movzx	eax, BYTE PTR hpel_off_y$[rsp]
	not	al
	mov	QWORD PTR tv3168[rsp], rcx
	movzx	eax, al
	mov	rcx, r12
	shr	eax, 7
	inc	r8d
	mov	DWORD PTR sample_off_y$1$[rsp], eax
	call	kvz_ipol_8tap_hor_px_im_avx2

; 871  : 
; 872  :   // Write the first column in contiguous memory
; 873  :   x = 0;
; 874  :   for (y = 0; y < height + KVZ_EXT_PADDING_LUMA + 1; ++y) {

	mov	r11d, DWORD PTR height$[rsp]
	xor	ebp, ebp
	lea	eax, DWORD PTR [r11+8]
	movsxd	rdi, eax
	test	eax, eax
	jle	$LN97@kvz_filter

; 875  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 876  :     int xpos = x - KVZ_LUMA_FILTER_OFFSET;
; 877  :     col_pos_l[y] = kvz_eight_tap_filter_hor_avx2(hor_fir_l, &src[src_stride*ypos + xpos]) >> shift1;

	mov	r14d, -1
	mov	ecx, ebp
	mov	eax, r14d
	sub	eax, r15d
	lea	edx, DWORD PTR [rax+rax*2]
$LL4@kvz_filter:

; 58   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [r12]

; 875  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 876  :     int xpos = x - KVZ_LUMA_FILTER_OFFSET;
; 877  :     col_pos_l[y] = kvz_eight_tap_filter_hor_avx2(hor_fir_l, &src[src_stride*ypos + xpos]) >> shift1;

	movsxd	rax, edx
	add	edx, r15d

; 59   :   __m128i row = _mm_loadl_epi64((__m128i*)data);

	vmovq	xmm1, QWORD PTR [rax+rbx]

; 60   :   __m128i acc;
; 61   :   acc = _mm_maddubs_epi16(row, fir);

	vpmaddubsw xmm2, xmm1, xmm0

; 62   :   __m128i temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm2, 4

; 63   :   acc = _mm_add_epi16(acc, temp);

	vpaddw	xmm3, xmm1, xmm2

; 64   :   temp = _mm_srli_si128(acc, 2);

	vpsrldq	xmm0, xmm3, 2

; 65   :   acc = _mm_add_epi16(acc, temp);

	vpaddw	xmm1, xmm0, xmm3

; 66   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm1

; 875  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 876  :     int xpos = x - KVZ_LUMA_FILTER_OFFSET;
; 877  :     col_pos_l[y] = kvz_eight_tap_filter_hor_avx2(hor_fir_l, &src[src_stride*ypos + xpos]) >> shift1;

	mov	WORD PTR [r13+rcx*2], ax
	inc	rcx
	cmp	rcx, rdi
	jl	SHORT $LL4@kvz_filter

; 886  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 887  :     int xpos = x - KVZ_LUMA_FILTER_OFFSET;
; 888  :     col_pos_r[y] = kvz_eight_tap_filter_hor_avx2(hor_fir_r, &src[src_stride*ypos + xpos]) >> shift1;

	mov	rax, QWORD PTR hor_pos_r$1$[rsp]
	lea	r9, QWORD PTR [rbx+1]
	mov	edx, DWORD PTR width$[rsp]
	lea	r8d, DWORD PTR [r11+1]
	mov	QWORD PTR [rsp+40], rax
	mov	rcx, rsi
	mov	WORD PTR [rsp+32], r15w
	call	kvz_ipol_8tap_hor_px_im_avx2
	sub	r14d, r15d
	mov	r8d, r15d
	mov	r15, QWORD PTR col_pos_r$1$[rsp]
	mov	rcx, rbp
	lea	edx, DWORD PTR [r14+r14*2]
	npad	8
$LL7@kvz_filter:

; 58   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [rsi]

; 886  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 887  :     int xpos = x - KVZ_LUMA_FILTER_OFFSET;
; 888  :     col_pos_r[y] = kvz_eight_tap_filter_hor_avx2(hor_fir_r, &src[src_stride*ypos + xpos]) >> shift1;

	movsxd	rax, edx
	add	edx, r8d

; 59   :   __m128i row = _mm_loadl_epi64((__m128i*)data);

	vmovq	xmm1, QWORD PTR [rax+rbx]

; 60   :   __m128i acc;
; 61   :   acc = _mm_maddubs_epi16(row, fir);

	vpmaddubsw xmm2, xmm1, xmm0

; 62   :   __m128i temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm2, 4

; 63   :   acc = _mm_add_epi16(acc, temp);

	vpaddw	xmm3, xmm1, xmm2

; 64   :   temp = _mm_srli_si128(acc, 2);

	vpsrldq	xmm0, xmm3, 2

; 65   :   acc = _mm_add_epi16(acc, temp);

	vpaddw	xmm1, xmm0, xmm3

; 66   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm1

; 886  :     int ypos = y - KVZ_LUMA_FILTER_OFFSET;
; 887  :     int xpos = x - KVZ_LUMA_FILTER_OFFSET;
; 888  :     col_pos_r[y] = kvz_eight_tap_filter_hor_avx2(hor_fir_r, &src[src_stride*ypos + xpos]) >> shift1;

	mov	WORD PTR [r15+rcx*2], ax
	inc	rcx
	cmp	rcx, rdi
	jl	SHORT $LL7@kvz_filter

; 882  : 
; 883  :   // Write the first column in contiguous memory
; 884  :   x = 0;
; 885  :   for (y = 0; y < height + KVZ_EXT_PADDING_LUMA + 1; ++y) {

	mov	r14d, DWORD PTR height$[rsp]
	jmp	SHORT $LN6@kvz_filter
$LN97@kvz_filter:

; 878  :   }
; 879  : 
; 880  :   // Right QPEL
; 881  :   kvz_ipol_8tap_hor_px_im_avx2(hor_fir_r, width, height + 1, src + 1, src_stride, hor_pos_r, hor_stride);

	mov	rax, QWORD PTR hor_pos_r$1$[rsp]
	lea	r9, QWORD PTR [rbx+1]
	mov	edx, DWORD PTR width$[rsp]
	lea	r8d, DWORD PTR [r11+1]
	mov	QWORD PTR [rsp+40], rax
	mov	rcx, rsi
	mov	WORD PTR [rsp+32], r15w
	mov	r14d, r11d
	call	kvz_ipol_8tap_hor_px_im_avx2
	mov	r15, QWORD PTR col_pos_r$1$[rsp]
$LN6@kvz_filter:

; 889  :   }
; 890  : 
; 891  :   // VERTICAL STEP
; 892  :   kvz_pixel *out_l = filtered[0];
; 893  :   kvz_pixel *out_r = filtered[1];

	mov	rdi, QWORD PTR filtered$[rsp]

; 894  :   kvz_pixel *out_t = filtered[2];
; 895  :   kvz_pixel *out_b = filtered[3];
; 896  : 
; 897  :   int8_t *ver_fir_l = hpel_off_y != 0 ? fir2 : fir0;
; 898  :   int8_t *ver_fir_r = hpel_off_y != 0 ? fir2 : fir0;
; 899  :   int8_t *ver_fir_t = hpel_off_y != 0 ? fir1 : fir3;

	lea	r8, OFFSET FLAT:kvz_g_luma_filter+24

; 900  :   int8_t *ver_fir_b = hpel_off_y != 0 ? fir3 : fir1;
; 901  : 
; 902  :   // Left QPEL (1/4 or 3/4 x positions) 
; 903  :   // Filter block and then filter column and align if neccessary
; 904  :   int16_t *im = &hor_pos_l[sample_off_y * hor_stride];

	movsxd	rbx, DWORD PTR sample_off_y$1$[rsp]
	lea	rdx, OFFSET FLAT:kvz_g_luma_filter+8
	mov	r9, QWORD PTR hor_pos_l$1$[rsp]
	lea	rsi, OFFSET FLAT:kvz_g_luma_filter
	lea	rax, QWORD PTR [rdi+8192]
	mov	QWORD PTR out_t$1$[rsp], rax
	lea	rcx, QWORD PTR [rdi+12288]
	movzx	eax, BYTE PTR hpel_off_y$[rsp]
	lea	r12, QWORD PTR [rdi+4096]
	test	al, al
	mov	QWORD PTR out_b$1$[rsp], rcx
	mov	eax, ebx
	lea	rcx, OFFSET FLAT:kvz_g_luma_filter+16
	cmovne	rsi, rcx
	mov	rcx, r8
	cmovne	rcx, rdx
	cmovne	rdx, r8
	mov	QWORD PTR ver_fir_t$1$[rsp], rcx

; 905  :   kvz_pixel *dst = out_l;
; 906  :   kvz_ipol_8tap_ver_im_px_avx2(ver_fir_l, width, height, im, hor_stride, dst, dst_stride);

	mov	r8d, r14d
	mov	QWORD PTR ver_fir_b$1$[rsp], rdx
	mov	edx, 64					; 00000040H
	mov	WORD PTR [rsp+48], dx
	mov	edx, DWORD PTR width$[rsp]
	shl	eax, 6
	mov	QWORD PTR [rsp+40], rdi
	lea	rcx, QWORD PTR [rax+rax]
	mov	QWORD PTR tv3205[rsp], rcx
	add	r9, rcx
	mov	rcx, rsi
	call	kvz_ipol_8tap_ver_im_px_avx2

; 907  : 
; 908  :   if (!off_x_fir_l) {

	cmp	BYTE PTR hpel_off_x$[rsp], 1
	mov	QWORD PTR tv3214[rsp], rbx
	jge	$LN9@kvz_filter

; 909  :     for (y = 0; y < height; ++y) {

	test	r14d, r14d
	jle	$LN9@kvz_filter

; 910  :       for (x = width - 8; x >= 8; x -= 8) {

	mov	r9d, DWORD PTR width$[rsp]
	lea	r11, QWORD PTR [rbx*2]
	add	r9d, -8
	mov	ebx, r14d
	add	r11, r13
	mov	r10d, ebp
	mov	r13d, -256				; ffffffffffffff00H
	mov	r8, rdi
$LL10@kvz_filter:
	cmp	r9d, 8
	jl	SHORT $LN12@kvz_filter
	lea	eax, DWORD PTR [r10+r9]
	mov	edx, r9d
	movsxd	rcx, eax
	add	rcx, rdi
	shr	rdx, 3
	npad	9
$LL13@kvz_filter:

; 911  :         uint64_t chunk = *(uint64_t*)&out_l[y * dst_stride + x - 1];
; 912  :         *(uint64_t*)&out_l[y * dst_stride + x] = chunk;

	mov	rax, QWORD PTR [rcx-1]
	mov	QWORD PTR [rcx], rax
	lea	rcx, QWORD PTR [rcx-8]
	sub	rdx, 1
	jne	SHORT $LL13@kvz_filter
$LN12@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [rsi]

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r11]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 913  :       }
; 914  : 
; 915  :       x = 0;
; 916  :       int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(ver_fir_l, &col_pos_l[y + sample_off_y]) >> shift2;

	sar	eax, 6

; 917  :       sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, r13w
	je	SHORT $LN46@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN46@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 920  :       uint64_t chunk = (rest << 8) | first;

	mov	rcx, QWORD PTR [r8]
	add	r10d, 64				; 00000040H
	shl	rcx, 8
	add	r11, 2
	movzx	eax, al
	or	rcx, rax

; 921  :       *(uint64_t*)&out_l[y * dst_stride + x] = chunk;

	mov	QWORD PTR [r8], rcx
	add	r8, 64					; 00000040H
	sub	rbx, 1
	jne	$LL10@kvz_filter
	mov	rbx, QWORD PTR tv3214[rsp]
$LN9@kvz_filter:

; 922  :     }
; 923  :   }
; 924  : 
; 925  :   // Right QPEL (3/4 or 1/4 x positions)
; 926  :   // Filter block and then filter column and align if neccessary
; 927  :   im = &hor_pos_r[sample_off_y * hor_stride];

	mov	r9, QWORD PTR tv3205[rsp]

; 928  :   dst = out_r;
; 929  :   kvz_ipol_8tap_ver_im_px_avx2(ver_fir_r, width, height, im, hor_stride, dst, dst_stride);

	mov	eax, 64					; 00000040H
	mov	edi, DWORD PTR width$[rsp]
	mov	r8d, r14d
	add	r9, QWORD PTR hor_pos_r$1$[rsp]
	mov	edx, edi
	mov	WORD PTR [rsp+48], ax
	mov	rcx, rsi
	mov	QWORD PTR [rsp+40], r12
	call	kvz_ipol_8tap_ver_im_px_avx2

; 930  : 
; 931  :   if (!off_x_fir_r) {

	movzx	r13d, BYTE PTR hpel_off_x$[rsp]
	test	r13b, r13b
	jns	$LN15@kvz_filter

; 932  :     for (y = 0; y < height; ++y) {

	test	r14d, r14d
	jle	$LN15@kvz_filter

; 933  :       for (x = width - 8; x >= 8; x -= 8) {

	lea	r9d, DWORD PTR [rdi-8]
	mov	r10d, ebp
	lea	r11, QWORD PTR [r15+rbx*2]
	mov	edi, -256				; ffffffffffffff00H
	mov	ebx, r14d
	mov	r8, r12
	npad	3
$LL16@kvz_filter:
	cmp	r9d, 8
	jl	SHORT $LN18@kvz_filter
	lea	eax, DWORD PTR [r10+r9]
	mov	edx, r9d
	movsxd	rcx, eax
	add	rcx, r12
	shr	rdx, 3
	npad	9
$LL19@kvz_filter:

; 934  :         uint64_t chunk = *(uint64_t*)&out_r[y * dst_stride + x - 1];
; 935  :         *(uint64_t*)&out_r[y * dst_stride + x] = chunk;

	mov	rax, QWORD PTR [rcx-1]
	mov	QWORD PTR [rcx], rax
	lea	rcx, QWORD PTR [rcx-8]
	sub	rdx, 1
	jne	SHORT $LL19@kvz_filter
$LN18@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [rsi]

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r11]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 936  :       }
; 937  : 
; 938  :       x = 0;
; 939  :       int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(ver_fir_r, &col_pos_r[y + sample_off_y]) >> shift2;

	sar	eax, 6

; 940  :       sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, di
	je	SHORT $LN52@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN52@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 943  :       uint64_t chunk = (rest << 8) | first;

	mov	rcx, QWORD PTR [r8]
	add	r10d, 64				; 00000040H
	shl	rcx, 8
	add	r11, 2
	movzx	eax, al
	or	rcx, rax

; 944  :       *(uint64_t*)&out_r[y * dst_stride + x] = chunk;

	mov	QWORD PTR [r8], rcx
	add	r8, 64					; 00000040H
	sub	rbx, 1
	jne	$LL16@kvz_filter
	mov	edi, DWORD PTR width$[rsp]
$LN15@kvz_filter:

; 945  :     }
; 946  :   }
; 947  : 
; 948  :   
; 949  :   // Top QPEL (1/4 or 3/4 y positions)
; 950  :   // Filter block and then filter column and align if neccessary
; 951  :   int sample_off_x = (hpel_off_x > -1 ? 1 : 0);
; 952  : 
; 953  :   im = &hor_hpel_pos[off_y_fir_t * hor_stride];

	movzx	ebx, BYTE PTR hpel_off_y$[rsp]
	mov	eax, 128				; 00000080H
	mov	r12, QWORD PTR hor_intermediate$[rsp]
	not	r13b

; 954  :   dst = out_t;
; 955  :   kvz_ipol_8tap_ver_im_px_avx2(ver_fir_t, width, height, im, hor_stride, dst, dst_stride);

	mov	r15, QWORD PTR ver_fir_t$1$[rsp]
	mov	r9, rbp
	mov	rsi, QWORD PTR out_t$1$[rsp]
	mov	r8d, r14d
	shr	r13b, 7
	mov	edx, edi
	cmp	bl, 1
	mov	rcx, r15
	cmovge	r9, rax
	mov	eax, 64					; 00000040H
	mov	WORD PTR [rsp+48], ax
	add	r9, r12
	mov	QWORD PTR [rsp+40], rsi
	call	kvz_ipol_8tap_ver_im_px_avx2

; 956  : 
; 957  :   if (!sample_off_x) {

	test	r13b, r13b
	jne	$LN21@kvz_filter

; 958  :     for (y = 0; y < height; ++y) {

	test	r14d, r14d
	jle	$LN21@kvz_filter

; 959  :       for (x = width - 8; x >= 8; x -= 8) {

	cmp	bl, 1
	lea	r10d, DWORD PTR [rdi-8]
	mov	r9, rbp
	mov	ebx, r14d
	mov	eax, 2
	mov	r11d, ebp
	cmovge	r9, rax
	mov	r8, rsi
	add	r9, QWORD PTR tv3168[rsp]
	mov	r12d, -256				; ffffffffffffff00H
	npad	1
$LL22@kvz_filter:
	cmp	r10d, 8
	jl	SHORT $LN24@kvz_filter
	lea	eax, DWORD PTR [r11+r10]
	mov	edx, r10d
	movsxd	rcx, eax
	add	rcx, rsi
	shr	rdx, 3
	npad	9
$LL25@kvz_filter:

; 960  :         uint64_t chunk = *(uint64_t*)&out_t[y * dst_stride + x - 1];
; 961  :         *(uint64_t*)&out_t[y * dst_stride + x] = chunk;

	mov	rax, QWORD PTR [rcx-1]
	mov	QWORD PTR [rcx], rax
	lea	rcx, QWORD PTR [rcx-8]
	sub	rdx, 1
	jne	SHORT $LL25@kvz_filter
$LN24@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [r15]

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r9]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 962  :       }
; 963  : 
; 964  :       x = 0;
; 965  :       int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(ver_fir_t, &col_pos_hor[y + off_y_fir_t]) >> shift2;

	sar	eax, 6

; 966  :       sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, r12w
	je	SHORT $LN58@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN58@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 969  :       uint64_t chunk = (rest << 8) | first;

	mov	rcx, QWORD PTR [r8]
	add	r11d, 64				; 00000040H
	shl	rcx, 8
	add	r9, 2
	movzx	eax, al
	or	rcx, rax

; 970  :       *(uint64_t*)&out_t[y * dst_stride + x] = chunk;

	mov	QWORD PTR [r8], rcx
	add	r8, 64					; 00000040H
	sub	rbx, 1
	jne	$LL22@kvz_filter
	mov	r12, QWORD PTR hor_intermediate$[rsp]
$LN21@kvz_filter:

; 971  :     }
; 972  :   }
; 973  : 
; 974  :   // Bottom QPEL (3/4 or 1/4 y positions)
; 975  :   // Filter block and then filter column and align if neccessary
; 976  : 
; 977  :   im = &hor_hpel_pos[off_y_fir_b * hor_stride];

	mov	r9, QWORD PTR tv3205[rsp]

; 978  :   dst = out_b;
; 979  :   kvz_ipol_8tap_ver_im_px_avx2(ver_fir_b, width, height, im, hor_stride, dst, dst_stride);

	mov	eax, 64					; 00000040H
	mov	rsi, QWORD PTR ver_fir_b$1$[rsp]
	add	r9, r12
	mov	rbx, QWORD PTR out_b$1$[rsp]
	mov	rcx, rsi
	mov	WORD PTR [rsp+48], ax
	mov	r8d, r14d
	mov	edx, edi
	mov	QWORD PTR [rsp+40], rbx
	call	kvz_ipol_8tap_ver_im_px_avx2

; 980  : 
; 981  :   if (!sample_off_x) {

	test	r13b, r13b
	jne	$LN27@kvz_filter

; 982  :     for (y = 0; y < height; ++y) {

	test	r14d, r14d
	jle	$LN27@kvz_filter

; 983  :       for (x = width - 8; x >= 8; x -= 8) {

	lea	r9d, DWORD PTR [rdi-8]
	mov	r11d, r14d
	mov	rdi, QWORD PTR tv3214[rsp]
	mov	r10d, ebp
	mov	r14, QWORD PTR tv3168[rsp]
	mov	r8, rbx
$LL28@kvz_filter:
	cmp	r9d, 8
	jl	SHORT $LN30@kvz_filter
	lea	eax, DWORD PTR [r9+r10]
	mov	edx, r9d
	cdqe
	add	rax, rbx
	shr	rdx, 3
	npad	3
$LL31@kvz_filter:

; 984  :         uint64_t chunk = *(uint64_t*)&out_b[y * dst_stride + x - 1];
; 985  :         *(uint64_t*)&out_b[y * dst_stride + x] = chunk;

	mov	rcx, QWORD PTR [rax-1]
	mov	QWORD PTR [rax], rcx
	lea	rax, QWORD PTR [rax-8]
	sub	rdx, 1
	jne	SHORT $LL31@kvz_filter
$LN30@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [rsi]

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 986  :       }
; 987  : 
; 988  :       x = 0;
; 989  :       int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(ver_fir_b, &col_pos_hor[y + off_y_fir_b]) >> shift2;

	lea	rax, QWORD PTR [rdi+rbp]
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	mov	ecx, -256				; ffffffffffffff00H
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r14+rax*2]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 986  :       }
; 987  : 
; 988  :       x = 0;
; 989  :       int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(ver_fir_b, &col_pos_hor[y + off_y_fir_b]) >> shift2;

	sar	eax, 6

; 990  :       sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, cx
	je	SHORT $LN64@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN64@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 993  :       uint64_t chunk = (rest << 8) | first;

	mov	rcx, QWORD PTR [r8]
	add	r10d, 64				; 00000040H
	shl	rcx, 8
	inc	rbp
	movzx	eax, al
	or	rcx, rax

; 994  :       *(uint64_t*)&out_b[y * dst_stride + x] = chunk;

	mov	QWORD PTR [r8], rcx
	add	r8, 64					; 00000040H
	sub	r11, 1
	jne	$LL28@kvz_filter
$LN27@kvz_filter:

; 995  :     }
; 996  :   }
; 997  : }

	mov	rbx, QWORD PTR [rsp+176]
	add	rsp, 112				; 00000070H
	pop	r15
	pop	r14
	pop	r13
	pop	r12
	pop	rdi
	pop	rsi
	pop	rbp
	ret	0
kvz_filter_qpel_blocks_hor_ver_luma_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
hor_pos_r$1$ = 64
col_pos_r$1$ = 72
hor_pos_l$1$ = 80
ver_fir_b$1$ = 88
out_br$1$ = 96
encoder$ = 160
src$ = 168
src_stride$ = 176
width$ = 184
height$ = 192
out_bl$1$ = 200
filtered$ = 200
off_y_fir_b$1$ = 208
hor_intermediate$ = 208
fme_level$ = 216
col_pos_l$1$ = 224
hor_first_cols$ = 224
hpel_off_x$ = 232
tv3187 = 240
hpel_off_y$ = 240
kvz_filter_qpel_blocks_diag_luma_avx2 PROC

; 1009 : {

	mov	QWORD PTR [rsp+8], rbx
	mov	QWORD PTR [rsp+16], rbp
	mov	QWORD PTR [rsp+24], rsi
	mov	DWORD PTR [rsp+32], r9d
	push	rdi
	push	r12
	push	r13
	push	r14
	push	r15
	sub	rsp, 112				; 00000070H

; 1010 :   int x, y;
; 1011 : 
; 1012 :   // Interpolation filter shifts
; 1013 :   int32_t shift2 = 6;
; 1014 : 
; 1015 :   // Weighted prediction offset and shift
; 1016 :   int32_t wp_shift1 = 14 - KVZ_BIT_DEPTH;
; 1017 :   int32_t wp_offset1 = 1 << (wp_shift1 - 1);
; 1018 : 
; 1019 :   int8_t *fir1 = kvz_g_luma_filter[1];
; 1020 :   int8_t *fir3 = kvz_g_luma_filter[3];
; 1021 : 
; 1022 :   int16_t *hor_pos_l = hor_intermediate[3];
; 1023 :   int16_t *hor_pos_r = hor_intermediate[4];
; 1024 : 
; 1025 :   int16_t *col_pos_l = hor_first_cols[1];
; 1026 :   int16_t *col_pos_r = hor_first_cols[3];
; 1027 : 
; 1028 :   int16_t dst_stride = LCU_WIDTH;
; 1029 :   int16_t hor_stride = LCU_WIDTH;
; 1030 : 
; 1031 :   // VERTICAL STEP
; 1032 :   kvz_pixel *out_tl = filtered[0];
; 1033 :   kvz_pixel *out_tr = filtered[1];

	mov	rsi, QWORD PTR filtered$[rsp]
	mov	r10d, r9d
	movzx	ebx, BYTE PTR hpel_off_y$[rsp]
	mov	rax, QWORD PTR hor_intermediate$[rsp]

; 1034 :   kvz_pixel *out_bl = filtered[2];
; 1035 :   kvz_pixel *out_br = filtered[3];
; 1036 : 
; 1037 :   int8_t *ver_fir_t = hpel_off_y != 0 ? fir1 : fir3;
; 1038 :   int8_t *ver_fir_b = hpel_off_y != 0 ? fir3 : fir1;
; 1039 : 
; 1040 :   // Specify if integer pixels are filtered from left or/and top integer samples
; 1041 :   int off_x_fir_l = hpel_off_x < 1 ? 0 : 1;
; 1042 :   int off_x_fir_r = hpel_off_x < 0 ? 0 : 1;
; 1043 :   int off_y_fir_t = hpel_off_y < 1 ? 0 : 1;
; 1044 :   int off_y_fir_b = hpel_off_y < 0 ? 0 : 1;
; 1045 : 
; 1046 :   // Top-left QPEL
; 1047 :   // Filter block and then filter column and align if neccessary
; 1048 :   int16_t *im = &hor_pos_l[off_y_fir_t * hor_stride];
; 1049 :   kvz_pixel *dst = out_tl;
; 1050 :   kvz_ipol_8tap_ver_im_px_avx2(ver_fir_t, width, height, im, hor_stride, dst, dst_stride);

	mov	ebp, DWORD PTR height$[rsp]
	mov	r8d, ebp
	lea	r13, QWORD PTR [rsi+4096]
	lea	rdx, QWORD PTR [rax+27648]
	add	rax, 36864				; 00009000H
	mov	QWORD PTR hor_pos_r$1$[rsp], rax
	mov	rax, QWORD PTR hor_first_cols$[rsp]
	mov	QWORD PTR hor_pos_l$1$[rsp], rdx
	lea	rcx, QWORD PTR [rax+144]
	add	rax, 432				; 000001b0H
	mov	QWORD PTR col_pos_r$1$[rsp], rax
	test	bl, bl
	mov	QWORD PTR col_pos_l$1$[rsp], rcx
	lea	rax, QWORD PTR [rsi+8192]
	mov	QWORD PTR out_bl$1$[rsp], rax
	lea	rcx, QWORD PTR [rsi+12288]
	mov	QWORD PTR out_br$1$[rsp], rcx
	lea	rax, OFFSET FLAT:kvz_g_luma_filter+8
	lea	rcx, OFFSET FLAT:kvz_g_luma_filter+24
	mov	r12, rcx
	cmovne	r12, rax
	cmovne	rax, rcx
	mov	QWORD PTR ver_fir_b$1$[rsp], rax
	xor	edi, edi
	movzx	eax, BYTE PTR hpel_off_x$[rsp]
	mov	r15d, edi
	not	al
	mov	rcx, r12
	shr	al, 7
	mov	BYTE PTR tv3187[rsp], al
	movzx	eax, bl
	not	al
	movzx	eax, al
	shr	eax, 7
	mov	DWORD PTR off_y_fir_b$1$[rsp], eax
	cmp	bl, 1
	mov	eax, 128				; 00000080H
	cmovge	r15d, eax
	mov	eax, 64					; 00000040H
	mov	WORD PTR [rsp+48], ax
	mov	QWORD PTR [rsp+40], rsi
	lea	r9, QWORD PTR [r15+rdx]
	mov	edx, r10d
	call	kvz_ipol_8tap_ver_im_px_avx2
	cmp	bl, 1
	mov	r14d, edi
	setge	r14b

; 1051 : 
; 1052 :   if (!off_x_fir_l) {

	cmp	BYTE PTR hpel_off_x$[rsp], 1
	jge	$LN3@kvz_filter

; 1053 :     for (y = 0; y < height; ++y) {

	test	ebp, ebp
	jle	$LN3@kvz_filter

; 1054 :       for (x = width - 8; x >= 8; x -= 8) {

	mov	rax, QWORD PTR col_pos_l$1$[rsp]
	mov	ebx, ebp
	mov	r9d, DWORD PTR width$[rsp]
	mov	r10d, edi
	add	r9d, -8
	mov	r8, rsi
	mov	ebp, -256				; ffffffffffffff00H
	lea	r11, QWORD PTR [rax+r14*2]
	npad	5
$LL4@kvz_filter:
	cmp	r9d, 8
	jl	SHORT $LN6@kvz_filter
	lea	eax, DWORD PTR [r10+r9]
	mov	edx, r9d
	movsxd	rcx, eax
	add	rcx, rsi
	shr	rdx, 3
	npad	9
$LL7@kvz_filter:

; 1055 :         uint64_t chunk = *(uint64_t*)&out_tl[y * dst_stride + x - 1];
; 1056 :         *(uint64_t*)&out_tl[y * dst_stride + x] = chunk;

	mov	rax, QWORD PTR [rcx-1]
	mov	QWORD PTR [rcx], rax
	lea	rcx, QWORD PTR [rcx-8]
	sub	rdx, 1
	jne	SHORT $LL7@kvz_filter
$LN6@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [r12]

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 75   :   __m128i row = _mm_loadu_si128((__m128i*)data);
; 76   :   __m128i acc;
; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r11]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 1057 :       }
; 1058 : 
; 1059 :       x = 0;
; 1060 :       int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(ver_fir_t, &col_pos_l[y + off_y_fir_t]) >> shift2;

	sar	eax, 6

; 1061 :       sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, bp
	je	SHORT $LN34@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN34@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 1064 :       uint64_t chunk = (rest << 8) | first;

	mov	rcx, QWORD PTR [r8]
	add	r10d, 64				; 00000040H
	shl	rcx, 8
	add	r11, 2
	movzx	eax, al
	or	rcx, rax

; 1065 :       *(uint64_t*)&out_tl[y * dst_stride + x] = chunk;

	mov	QWORD PTR [r8], rcx
	add	r8, 64					; 00000040H
	sub	rbx, 1
	jne	$LL4@kvz_filter
	mov	ebp, DWORD PTR height$[rsp]
$LN3@kvz_filter:

; 1066 :     }
; 1067 :   }
; 1068 : 
; 1069 :   // Top-right QPEL
; 1070 :   // Filter block and then filter column and align if neccessary
; 1071 : 
; 1072 :   im = &hor_pos_r[off_y_fir_t * hor_stride];

	mov	r9, QWORD PTR hor_pos_r$1$[rsp]

; 1073 :   dst = out_tr;
; 1074 :   kvz_ipol_8tap_ver_im_px_avx2(ver_fir_t, width, height, im, hor_stride, dst, dst_stride);

	mov	esi, 64					; 00000040H
	add	r9, r15
	mov	WORD PTR [rsp+48], si
	mov	r15d, DWORD PTR width$[rsp]
	mov	r8d, ebp
	mov	edx, r15d
	mov	QWORD PTR [rsp+40], r13
	mov	rcx, r12
	call	kvz_ipol_8tap_ver_im_px_avx2

; 1075 : 
; 1076 :   if (!off_x_fir_r) {

	cmp	BYTE PTR tv3187[rsp], dil
	jne	$LN9@kvz_filter

; 1077 :     for (y = 0; y < height; ++y) {

	test	ebp, ebp
	jle	$LN9@kvz_filter

; 1078 :       for (x = width - 8; x >= 8; x -= 8) {

	mov	rax, QWORD PTR col_pos_r$1$[rsp]
	lea	r9d, DWORD PTR [r15-8]
	mov	r10d, edi
	mov	ebx, ebp
	mov	r8, r13
	mov	r15d, -256				; ffffffffffffff00H
	lea	r11, QWORD PTR [rax+r14*2]
$LL10@kvz_filter:
	cmp	r9d, 8
	jl	SHORT $LN12@kvz_filter
	lea	eax, DWORD PTR [r10+r9]
	mov	edx, r9d
	movsxd	rcx, eax
	add	rcx, r13
	shr	rdx, 3
	npad	2
$LL13@kvz_filter:

; 1079 :         uint64_t chunk = *(uint64_t*)&out_tr[y * dst_stride + x - 1];
; 1080 :         *(uint64_t*)&out_tr[y * dst_stride + x] = chunk;

	mov	rax, QWORD PTR [rcx-1]
	mov	QWORD PTR [rcx], rax
	lea	rcx, QWORD PTR [rcx-8]
	sub	rdx, 1
	jne	SHORT $LL13@kvz_filter
$LN12@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [r12]

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 75   :   __m128i row = _mm_loadu_si128((__m128i*)data);
; 76   :   __m128i acc;
; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r11]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 1081 :       }
; 1082 : 
; 1083 :       x = 0;
; 1084 :       int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(ver_fir_t, &col_pos_r[y + off_y_fir_t]) >> shift2;

	sar	eax, 6

; 1085 :       sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, r15w
	je	SHORT $LN40@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN40@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 1088 :       uint64_t chunk = (rest << 8) | first;

	mov	rcx, QWORD PTR [r8]
	add	r10d, esi
	shl	rcx, 8
	add	r11, 2
	movzx	eax, al
	or	rcx, rax

; 1089 :       *(uint64_t*)&out_tr[y * dst_stride + x] = chunk;

	mov	QWORD PTR [r8], rcx
	add	r8, rsi
	sub	rbx, 1
	jne	$LL10@kvz_filter
	mov	r15d, DWORD PTR width$[rsp]
$LN9@kvz_filter:

; 1090 :     }
; 1091 :   }
; 1092 : 
; 1093 :   // Bottom-left QPEL
; 1094 :   // Filter block and then filter column and align if neccessary
; 1095 :   im = &hor_pos_l[off_y_fir_b * hor_stride];

	movsxd	rbx, DWORD PTR off_y_fir_b$1$[rsp]

; 1096 :   dst = out_bl;
; 1097 :   kvz_ipol_8tap_ver_im_px_avx2(ver_fir_b, width, height, im, hor_stride, dst, dst_stride);

	mov	r8d, ebp
	mov	r9, QWORD PTR hor_pos_l$1$[rsp]
	mov	eax, ebx
	mov	r12, QWORD PTR ver_fir_b$1$[rsp]
	mov	edx, r15d
	mov	r13, QWORD PTR out_bl$1$[rsp]
	mov	rcx, r12
	shl	eax, 6
	mov	WORD PTR [rsp+48], si
	mov	QWORD PTR [rsp+40], r13
	lea	r14, QWORD PTR [rax+rax]
	add	r9, r14
	call	kvz_ipol_8tap_ver_im_px_avx2

; 1098 : 
; 1099 :   if (!off_x_fir_l) {

	cmp	BYTE PTR hpel_off_x$[rsp], 1
	mov	rsi, rbx
	jge	$LN15@kvz_filter

; 1100 :     for (y = 0; y < height; ++y) {

	test	ebp, ebp
	jle	$LN15@kvz_filter

; 1101 :       for (x = width - 8; x >= 8; x -= 8) {

	mov	rax, QWORD PTR col_pos_l$1$[rsp]
	lea	r9d, DWORD PTR [r15-8]
	mov	r10d, edi
	mov	r8, r13
	mov	r15d, -256				; ffffffffffffff00H
	lea	r11, QWORD PTR [rax+rbx*2]
	mov	ebx, ebp
	npad	2
$LL16@kvz_filter:
	cmp	r9d, 8
	jl	SHORT $LN18@kvz_filter
	lea	eax, DWORD PTR [r10+r9]
	mov	edx, r9d
	movsxd	rcx, eax
	add	rcx, r13
	shr	rdx, 3
	npad	9
$LL19@kvz_filter:

; 1102 :         uint64_t chunk = *(uint64_t*)&out_bl[y * dst_stride + x - 1];
; 1103 :         *(uint64_t*)&out_bl[y * dst_stride + x] = chunk;

	mov	rax, QWORD PTR [rcx-1]
	mov	QWORD PTR [rcx], rax
	lea	rcx, QWORD PTR [rcx-8]
	sub	rdx, 1
	jne	SHORT $LL19@kvz_filter
$LN18@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [r12]

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 75   :   __m128i row = _mm_loadu_si128((__m128i*)data);
; 76   :   __m128i acc;
; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r11]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 1104 :       }
; 1105 : 
; 1106 :       x = 0;
; 1107 :       int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(ver_fir_b, &col_pos_l[y + off_y_fir_b]) >> shift2;

	sar	eax, 6

; 1108 :       sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, r15w
	je	SHORT $LN46@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN46@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 1111 :       uint64_t chunk = (rest << 8) | first;

	mov	rcx, QWORD PTR [r8]
	add	r10d, 64				; 00000040H
	shl	rcx, 8
	add	r11, 2
	movzx	eax, al
	or	rcx, rax

; 1112 :       *(uint64_t*)&out_bl[y * dst_stride + x] = chunk;

	mov	QWORD PTR [r8], rcx
	add	r8, 64					; 00000040H
	sub	rbx, 1
	jne	$LL16@kvz_filter
	mov	r15d, DWORD PTR width$[rsp]
$LN15@kvz_filter:

; 1113 :     }
; 1114 :   }
; 1115 : 
; 1116 :   // Bottom-right QPEL
; 1117 :   // Filter block and then filter column and align if neccessary
; 1118 :   im = &hor_pos_r[off_y_fir_b * hor_stride];

	mov	r9, QWORD PTR hor_pos_r$1$[rsp]

; 1119 :   dst = out_br;
; 1120 :   kvz_ipol_8tap_ver_im_px_avx2(ver_fir_b, width, height, im, hor_stride, dst, dst_stride);

	mov	eax, 64					; 00000040H
	mov	rbx, QWORD PTR out_br$1$[rsp]
	add	r9, r14
	mov	WORD PTR [rsp+48], ax
	mov	r8d, ebp
	mov	edx, r15d
	mov	QWORD PTR [rsp+40], rbx
	mov	rcx, r12
	call	kvz_ipol_8tap_ver_im_px_avx2

; 1121 : 
; 1122 :   if (!off_x_fir_r) {

	cmp	BYTE PTR tv3187[rsp], dil
	jne	$LN21@kvz_filter

; 1123 :     for (y = 0; y < height; ++y) {

	test	ebp, ebp
	jle	$LN21@kvz_filter

; 1124 :       for (x = width - 8; x >= 8; x -= 8) {

	mov	rax, QWORD PTR col_pos_r$1$[rsp]
	lea	r9d, DWORD PTR [r15-8]
	mov	r8, rbx
	mov	r11d, ebp
	lea	r10, QWORD PTR [rax+rsi*2]
	npad	2
$LL22@kvz_filter:
	cmp	r9d, 8
	jl	SHORT $LN24@kvz_filter
	lea	eax, DWORD PTR [rdi+r9]
	mov	edx, r9d
	cdqe
	add	rax, rbx
	shr	rdx, 3
	npad	10
$LL25@kvz_filter:

; 1125 :         uint64_t chunk = *(uint64_t*)&out_br[y * dst_stride + x - 1];
; 1126 :         *(uint64_t*)&out_br[y * dst_stride + x] = chunk;

	mov	rcx, QWORD PTR [rax-1]
	mov	QWORD PTR [rax], rcx
	lea	rax, QWORD PTR [rax-8]
	sub	rdx, 1
	jne	SHORT $LL25@kvz_filter
$LN24@kvz_filter:

; 73   :   __m128i fir = _mm_loadl_epi64((__m128i*)filter);

	vmovq	xmm0, QWORD PTR [r12]

; 74   :   fir = _mm_cvtepi8_epi16(fir);

	vpmovsxbw xmm1, xmm0

; 75   :   __m128i row = _mm_loadu_si128((__m128i*)data);
; 76   :   __m128i acc;
; 77   :   acc = _mm_madd_epi16(fir, row);

	vpmaddwd xmm2, xmm1, XMMWORD PTR [r10]

; 78   :   __m128i temp = _mm_srli_si128(acc, 8);

	vpsrldq	xmm0, xmm2, 8

; 79   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm3, xmm0, xmm2

; 80   :   temp = _mm_srli_si128(acc, 4);

	vpsrldq	xmm1, xmm3, 4

; 81   :   acc = _mm_add_epi32(acc, temp);

	vpaddd	xmm0, xmm1, xmm3

; 82   :   int32_t filtered = _mm_cvtsi128_si32(acc);

	vmovd	eax, xmm0

; 1127 :       }
; 1128 : 
; 1129 :       x = 0;
; 1130 :       int16_t sample = kvz_eight_tap_filter_hor_16bit_avx2(ver_fir_b, &col_pos_r[y + off_y_fir_b]) >> shift2;

	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	mov	ecx, -256				; ffffffffffffff00H
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 1131 :       sample = kvz_fast_clip_16bit_to_pixel((sample + wp_offset1) >> wp_shift1);

	cwde
	add	eax, 32					; 00000020H
	sar	eax, 6
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\generic\picture-generic.c

; 47   :   if (value & ~PIXEL_MAX) {

	test	ax, cx
	je	SHORT $LN52@kvz_filter

; 48   :     int16_t temp = (-value) >> 15;

	cwde
	neg	eax
	sar	eax, 15
$LN52@kvz_filter:
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c

; 1134 :       uint64_t chunk = (rest << 8) | first;

	mov	rcx, QWORD PTR [r8]
	add	edi, 64					; 00000040H
	shl	rcx, 8
	add	r10, 2
	movzx	eax, al
	or	rcx, rax

; 1135 :       *(uint64_t*)&out_br[y * dst_stride + x] = chunk;

	mov	QWORD PTR [r8], rcx
	add	r8, 64					; 00000040H
	sub	r11, 1
	jne	$LL22@kvz_filter
$LN21@kvz_filter:

; 1136 :     }
; 1137 :   }
; 1138 : }

	lea	r11, QWORD PTR [rsp+112]
	mov	rbx, QWORD PTR [r11+48]
	mov	rbp, QWORD PTR [r11+56]
	mov	rsi, QWORD PTR [r11+64]
	mov	rsp, r11
	pop	r15
	pop	r14
	pop	r13
	pop	r12
	pop	rdi
	ret	0
kvz_filter_qpel_blocks_diag_luma_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
hor_intermediate$ = 0
encoder$ = 9360
src$ = 9368
src_stride$ = 9376
width$ = 9384
height$ = 9392
dst$ = 9400
dst_stride$ = 9408
hor_flag$ = 9416
ver_flag$ = 9424
mv$ = 9432
kvz_sample_quarterpel_luma_avx2 PROC

; 1150 : {

	mov	QWORD PTR [rsp+8], rsi
	mov	QWORD PTR [rsp+16], rdi
	push	rbp
	mov	eax, 9344				; 00002480H
	call	__chkstk
	sub	rsp, rax
	lea	rbp, QWORD PTR [rsp+128]
	and	rbp, -64				; ffffffffffffffc0H

; 1151 :   // TODO: horizontal and vertical only filtering
; 1152 :   int8_t *hor_fir = kvz_g_luma_filter[mv[0] & 3];
; 1153 :   int8_t *ver_fir = kvz_g_luma_filter[mv[1] & 3];

	mov	rcx, QWORD PTR mv$[rsp]
	mov	esi, r9d
	lea	r9, OFFSET FLAT:kvz_g_luma_filter
	movsx	rax, WORD PTR [rcx+2]
	and	eax, 3
	lea	rdi, QWORD PTR [r9+rax*8]
	movsx	rax, WORD PTR [rcx]
	and	eax, 3
	lea	rcx, QWORD PTR [r9+rax*8]

; 1154 : 
; 1155 :   // Buffer for intermediate values with one extra row 
; 1156 :   // because the loop writes two rows each iteration.
; 1157 :   ALIGNED(64) int16_t hor_intermediate[KVZ_IPOL_MAX_IM_SIZE_LUMA_SIMD];
; 1158 :   int16_t hor_stride = LCU_WIDTH;
; 1159 : 
; 1160 :   kvz_ipol_8tap_hor_px_im_avx2(hor_fir, width, height, src, src_stride, hor_intermediate, hor_stride);

	mov	r9, rdx
	lea	rax, QWORD PTR hor_intermediate$[rbp]
	mov	edx, esi
	mov	QWORD PTR [rsp+40], rax
	mov	WORD PTR [rsp+32], r8w
	mov	r8d, DWORD PTR height$[rsp]
	call	kvz_ipol_8tap_hor_px_im_avx2

; 1161 :   kvz_ipol_8tap_ver_im_px_avx2(ver_fir, width, height, hor_intermediate, hor_stride, dst, dst_stride);

	movzx	eax, WORD PTR dst_stride$[rsp]
	lea	r9, QWORD PTR hor_intermediate$[rbp]
	mov	r8d, DWORD PTR height$[rsp]
	mov	edx, esi
	mov	WORD PTR [rsp+48], ax
	mov	rcx, rdi
	mov	rax, QWORD PTR dst$[rsp]
	mov	QWORD PTR [rsp+40], rax
	call	kvz_ipol_8tap_ver_im_px_avx2

; 1162 : }

	lea	r11, QWORD PTR [rsp+9344]
	mov	rsi, QWORD PTR [r11+16]
	mov	rdi, QWORD PTR [r11+24]
	mov	rsp, r11
	pop	rbp
	ret	0
kvz_sample_quarterpel_luma_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
hor_intermediate$ = 0
encoder$ = 9360
src$ = 9368
src_stride$ = 9376
width$ = 9384
height$ = 9392
dst$ = 9400
dst_stride$ = 9408
hor_flag$ = 9416
ver_flag$ = 9424
mv$ = 9432
kvz_sample_quarterpel_luma_hi_avx2 PROC

; 1175 : {

	mov	QWORD PTR [rsp+8], rsi
	mov	QWORD PTR [rsp+16], rdi
	push	rbp
	mov	eax, 9344				; 00002480H
	call	__chkstk
	sub	rsp, rax
	lea	rbp, QWORD PTR [rsp+128]
	and	rbp, -64				; ffffffffffffffc0H

; 1176 :   // TODO: horizontal and vertical only filtering
; 1177 :   int8_t *hor_fir = kvz_g_luma_filter[mv[0] & 3];
; 1178 :   int8_t *ver_fir = kvz_g_luma_filter[mv[1] & 3];

	mov	rcx, QWORD PTR mv$[rsp]
	mov	esi, r9d
	lea	r9, OFFSET FLAT:kvz_g_luma_filter
	movsx	rax, WORD PTR [rcx+2]
	and	eax, 3
	lea	rdi, QWORD PTR [r9+rax*8]
	movsx	rax, WORD PTR [rcx]
	and	eax, 3
	lea	rcx, QWORD PTR [r9+rax*8]

; 1179 :   
; 1180 :   // Buffer for intermediate values with one extra row 
; 1181 :   // because the loop writes two rows each iteration.
; 1182 :   ALIGNED(64) int16_t hor_intermediate[KVZ_IPOL_MAX_IM_SIZE_LUMA_SIMD];
; 1183 :   int16_t hor_stride = LCU_WIDTH;
; 1184 : 
; 1185 :   kvz_ipol_8tap_hor_px_im_avx2(hor_fir, width, height, src, src_stride, hor_intermediate, hor_stride);

	mov	r9, rdx
	lea	rax, QWORD PTR hor_intermediate$[rbp]
	mov	edx, esi
	mov	QWORD PTR [rsp+40], rax
	mov	WORD PTR [rsp+32], r8w
	mov	r8d, DWORD PTR height$[rsp]
	call	kvz_ipol_8tap_hor_px_im_avx2

; 1186 :   kvz_ipol_8tap_ver_im_hi_avx2(ver_fir, width, height, hor_intermediate, hor_stride, dst, dst_stride);

	movzx	eax, WORD PTR dst_stride$[rsp]
	lea	r9, QWORD PTR hor_intermediate$[rbp]
	mov	r8d, DWORD PTR height$[rsp]
	mov	edx, esi
	mov	WORD PTR [rsp+48], ax
	mov	rcx, rdi
	mov	rax, QWORD PTR dst$[rsp]
	mov	QWORD PTR [rsp+40], rax
	call	kvz_ipol_8tap_ver_im_hi_avx2

; 1187 : }

	lea	r11, QWORD PTR [rsp+9344]
	mov	rsi, QWORD PTR [r11+16]
	mov	rdi, QWORD PTR [r11+24]
	mov	rsp, r11
	pop	rbp
	ret	0
kvz_sample_quarterpel_luma_hi_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
hor_intermediate$ = 0
encoder$ = 2592
src$ = 2600
src_stride$ = 2608
width$ = 2616
height$ = 2624
dst$ = 2632
dst_stride$ = 2640
hor_flag$ = 2648
ver_flag$ = 2656
mv$ = 2664
kvz_sample_octpel_chroma_avx2 PROC

; 1200 : {

	mov	QWORD PTR [rsp+8], rsi
	mov	QWORD PTR [rsp+16], rdi
	push	rbp
	sub	rsp, 2576				; 00000a10H
	lea	rbp, QWORD PTR [rsp+144]
	and	rbp, -64				; ffffffffffffffc0H

; 1201 :   // TODO: Optimizations for rest of the blocks (for example 2x8).
; 1202 :   if (width % 4 != 0) {

	mov	eax, r9d
	mov	esi, r9d
	and	eax, -2147483645			; ffffffff80000003H
	jge	SHORT $LN4@kvz_sample
	dec	eax
	or	eax, -4
	inc	eax
$LN4@kvz_sample:
	test	eax, eax
	je	SHORT $LN2@kvz_sample

; 1203 :     kvz_sample_octpel_chroma_generic(encoder, src, src_stride, width, height, dst, dst_stride, hor_flag, ver_flag, mv);

	mov	rax, QWORD PTR mv$[rsp]
	mov	QWORD PTR [rsp+72], rax
	movzx	eax, BYTE PTR ver_flag$[rsp]
	mov	BYTE PTR [rsp+64], al
	movzx	eax, BYTE PTR hor_flag$[rsp]
	mov	BYTE PTR [rsp+56], al
	movzx	eax, WORD PTR dst_stride$[rsp]
	mov	WORD PTR [rsp+48], ax
	mov	rax, QWORD PTR dst$[rsp]
	mov	QWORD PTR [rsp+40], rax
	mov	eax, DWORD PTR height$[rsp]
	mov	DWORD PTR [rsp+32], eax
	call	kvz_sample_octpel_chroma_generic

; 1204 :     return;

	jmp	SHORT $LN1@kvz_sample
$LN2@kvz_sample:

; 1205 :   }
; 1206 :   int8_t *hor_fir = kvz_g_chroma_filter[mv[0] & 7];
; 1207 :   int8_t *ver_fir = kvz_g_chroma_filter[mv[1] & 7];

	mov	rcx, QWORD PTR mv$[rsp]
	lea	r9, OFFSET FLAT:kvz_g_chroma_filter
	movsx	rax, WORD PTR [rcx+2]
	and	eax, 7
	lea	rdi, QWORD PTR [r9+rax*4]
	movsx	rax, WORD PTR [rcx]
	and	eax, 7
	lea	rcx, QWORD PTR [r9+rax*4]

; 1208 : 
; 1209 :   // Buffer for intermediate values with 3 extra rows 
; 1210 :   // because the loop writes four rows each iteration.
; 1211 :   ALIGNED(64) int16_t hor_intermediate[KVZ_IPOL_MAX_IM_SIZE_CHROMA_SIMD];
; 1212 :   int16_t hor_stride = LCU_WIDTH_C;
; 1213 : 
; 1214 :   kvz_ipol_4tap_hor_px_im_avx2(hor_fir, width, height, src, src_stride, hor_intermediate, hor_stride);

	mov	r9, rdx
	lea	rax, QWORD PTR hor_intermediate$[rbp]
	mov	edx, esi
	mov	QWORD PTR [rsp+40], rax
	mov	WORD PTR [rsp+32], r8w
	mov	r8d, DWORD PTR height$[rsp]
	call	kvz_ipol_4tap_hor_px_im_avx2

; 1215 :   kvz_ipol_4tap_ver_im_px_avx2(ver_fir, width, height, hor_intermediate, hor_stride, dst, dst_stride);

	movzx	eax, WORD PTR dst_stride$[rsp]
	lea	r9, QWORD PTR hor_intermediate$[rbp]
	mov	r8d, DWORD PTR height$[rsp]
	mov	edx, esi
	mov	WORD PTR [rsp+48], ax
	mov	rcx, rdi
	mov	rax, QWORD PTR dst$[rsp]
	mov	QWORD PTR [rsp+40], rax
	call	kvz_ipol_4tap_ver_im_px_avx2
$LN1@kvz_sample:

; 1216 : }

	lea	r11, QWORD PTR [rsp+2576]
	mov	rsi, QWORD PTR [r11+16]
	mov	rdi, QWORD PTR [r11+24]
	mov	rsp, r11
	pop	rbp
	ret	0
kvz_sample_octpel_chroma_avx2 ENDP
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File F:\open_codec_learn_2021\kvazaar-master\src\strategies\avx2\ipol-avx2.c
_TEXT	SEGMENT
hor_intermediate$ = 0
encoder$ = 2592
src$ = 2600
src_stride$ = 2608
width$ = 2616
height$ = 2624
dst$ = 2632
dst_stride$ = 2640
hor_flag$ = 2648
ver_flag$ = 2656
mv$ = 2664
kvz_sample_octpel_chroma_hi_avx2 PROC

; 1228 : {

	mov	QWORD PTR [rsp+8], rsi
	mov	QWORD PTR [rsp+16], rdi
	push	rbp
	sub	rsp, 2576				; 00000a10H
	lea	rbp, QWORD PTR [rsp+144]
	and	rbp, -64				; ffffffffffffffc0H

; 1229 :   // TODO: Optimizations for rest of the blocks (for example 2x8).
; 1230 :   if (width % 4 != 0) {

	mov	eax, r9d
	mov	esi, r9d
	and	eax, -2147483645			; ffffffff80000003H
	jge	SHORT $LN4@kvz_sample
	dec	eax
	or	eax, -4
	inc	eax
$LN4@kvz_sample:
	test	eax, eax
	je	SHORT $LN2@kvz_sample

; 1231 :     kvz_sample_octpel_chroma_hi_generic(encoder, src, src_stride, width, height, dst, dst_stride, hor_flag, ver_flag, mv);

	mov	rax, QWORD PTR mv$[rsp]
	mov	QWORD PTR [rsp+72], rax
	movzx	eax, BYTE PTR ver_flag$[rsp]
	mov	BYTE PTR [rsp+64], al
	movzx	eax, BYTE PTR hor_flag$[rsp]
	mov	BYTE PTR [rsp+56], al
	movzx	eax, WORD PTR dst_stride$[rsp]
	mov	WORD PTR [rsp+48], ax
	mov	rax, QWORD PTR dst$[rsp]
	mov	QWORD PTR [rsp+40], rax
	mov	eax, DWORD PTR height$[rsp]
	mov	DWORD PTR [rsp+32], eax
	call	kvz_sample_octpel_chroma_hi_generic

; 1232 :     return;

	jmp	SHORT $LN1@kvz_sample
$LN2@kvz_sample:

; 1233 :   }
; 1234 :   int8_t *hor_fir = kvz_g_chroma_filter[mv[0] & 7];
; 1235 :   int8_t *ver_fir = kvz_g_chroma_filter[mv[1] & 7];

	mov	rcx, QWORD PTR mv$[rsp]
	lea	r9, OFFSET FLAT:kvz_g_chroma_filter
	movsx	rax, WORD PTR [rcx+2]
	and	eax, 7
	lea	rdi, QWORD PTR [r9+rax*4]
	movsx	rax, WORD PTR [rcx]
	and	eax, 7
	lea	rcx, QWORD PTR [r9+rax*4]

; 1236 : 
; 1237 :   // Buffer for intermediate values with 3 extra rows 
; 1238 :   // because the loop writes four rows each iteration.
; 1239 :   ALIGNED(64) int16_t hor_intermediate[KVZ_IPOL_MAX_IM_SIZE_CHROMA_SIMD];
; 1240 :   int16_t hor_stride = LCU_WIDTH_C;
; 1241 : 
; 1242 :   kvz_ipol_4tap_hor_px_im_avx2(hor_fir, width, height, src, src_stride, hor_intermediate, hor_stride);

	mov	r9, rdx
	lea	rax, QWORD PTR hor_intermediate$[rbp]
	mov	edx, esi
	mov	QWORD PTR [rsp+40], rax
	mov	WORD PTR [rsp+32], r8w
	mov	r8d, DWORD PTR height$[rsp]
	call	kvz_ipol_4tap_hor_px_im_avx2

; 1243 :   kvz_ipol_4tap_ver_im_hi_avx2(ver_fir, width, height, hor_intermediate, hor_stride, dst, dst_stride);

	movzx	eax, WORD PTR dst_stride$[rsp]
	lea	r9, QWORD PTR hor_intermediate$[rbp]
	mov	r8d, DWORD PTR height$[rsp]
	mov	edx, esi
	mov	WORD PTR [rsp+48], ax
	mov	rcx, rdi
	mov	rax, QWORD PTR dst$[rsp]
	mov	QWORD PTR [rsp+40], rax
	call	kvz_ipol_4tap_ver_im_hi_avx2
$LN1@kvz_sample:

; 1244 : }

	lea	r11, QWORD PTR [rsp+2576]
	mov	rsi, QWORD PTR [r11+16]
	mov	rdi, QWORD PTR [r11+24]
	mov	rsp, r11
	pop	rbp
	ret	0
kvz_sample_octpel_chroma_hi_avx2 ENDP
_TEXT	ENDS
END
